{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1493ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current location: /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(\"current location:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = current_path+'/history_ddpg/'\n",
    "task = 'Ant-v3'\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8981725b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-18 19:18:29.844802: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.26it/s, env_step=5000, len=20, loss/actor=-33.469, loss/critic=4.120, n/ep=0, n/st=1, rew=1.60]\n",
      "Epoch #1: test_reward: -147.805633 ± 349.904895, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.47it/s, env_step=10000, len=109, loss/actor=-74.401, loss/critic=7.795, n/ep=0, n/st=1, rew=40.66]\n",
      "Epoch #2: test_reward: -66.811787 ± 221.106807, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.07it/s, env_step=15000, len=63, loss/actor=-105.115, loss/critic=10.457, n/ep=0, n/st=1, rew=-32.77]\n",
      "Epoch #3: test_reward: -82.466095 ± 229.461660, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.70it/s, env_step=20000, len=134, loss/actor=-136.774, loss/critic=20.123, n/ep=0, n/st=1, rew=23.17]\n",
      "Epoch #4: test_reward: -77.638532 ± 178.919287, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.86it/s, env_step=25000, len=1000, loss/actor=-167.732, loss/critic=22.419, n/ep=0, n/st=1, rew=-728.03]\n",
      "Epoch #5: test_reward: -101.224774 ± 211.231422, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #6: 5001it [00:43, 115.62it/s, env_step=30000, len=1000, loss/actor=-202.272, loss/critic=49.890, n/ep=0, n/st=1, rew=-834.02]\n",
      "Epoch #6: test_reward: -87.033999 ± 250.300073, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #7: 5001it [00:42, 117.06it/s, env_step=35000, len=43, loss/actor=-240.542, loss/critic=50.250, n/ep=0, n/st=1, rew=-33.04]\n",
      "Epoch #7: test_reward: -268.256430 ± 452.894395, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #8: 5001it [00:43, 114.34it/s, env_step=40000, len=18, loss/actor=-278.440, loss/critic=99.903, n/ep=0, n/st=1, rew=-39.82]\n",
      "Epoch #8: test_reward: -146.970026 ± 251.009111, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #9: 5001it [00:43, 115.47it/s, env_step=45000, len=91, loss/actor=-323.081, loss/critic=125.647, n/ep=0, n/st=1, rew=-54.51]\n",
      "Epoch #9: test_reward: -190.369172 ± 392.288074, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #10: 5001it [00:43, 115.88it/s, env_step=50000, len=42, loss/actor=-382.293, loss/critic=232.813, n/ep=0, n/st=1, rew=-29.54]\n",
      "Epoch #10: test_reward: -77.778604 ± 124.039747, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '460.04s',\n",
      " 'test_episode': 110,\n",
      " 'test_speed': '1118.63 step/s',\n",
      " 'test_step': 25697,\n",
      " 'test_time': '22.97s',\n",
      " 'train_episode': 233,\n",
      " 'train_speed': '114.40 step/s',\n",
      " 'train_step': 50000,\n",
      " 'train_time/collector': '78.61s',\n",
      " 'train_time/model': '358.45s'}\n",
      "Final reward: -315.1095357543685, length: 223.7\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cec1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0318_191829-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-18 19:38:51.341212: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.12it/s, env_step=5000, len=1000, loss/actor=-31.702, loss/critic=4.575, n/ep=0, n/st=1, rew=-354.36]\n",
      "Epoch #1: test_reward: -136.946218 ± 290.030606, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.16it/s, env_step=10000, len=13, loss/actor=-86.565, loss/critic=14.267, n/ep=0, n/st=1, rew=3.67]\n",
      "Epoch #2: test_reward: -179.164174 ± 349.872324, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.99it/s, env_step=15000, len=1000, loss/actor=-133.312, loss/critic=20.106, n/ep=0, n/st=1, rew=-717.21]\n",
      "Epoch #3: test_reward: -90.589345 ± 162.179281, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.47it/s, env_step=20000, len=1000, loss/actor=-176.529, loss/critic=31.386, n/ep=0, n/st=1, rew=-427.96]\n",
      "Epoch #4: test_reward: -92.706111 ± 196.297651, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.85it/s, env_step=25000, len=53, loss/actor=-212.415, loss/critic=41.228, n/ep=0, n/st=1, rew=-54.96]\n",
      "Epoch #5: test_reward: -277.225027 ± 365.649929, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #6: 5001it [00:43, 115.00it/s, env_step=30000, len=29, loss/actor=-246.334, loss/critic=52.561, n/ep=0, n/st=1, rew=-20.01]\n",
      "Epoch #6: test_reward: -676.498495 ± 438.630413, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #7: 5001it [00:43, 114.38it/s, env_step=35000, len=22, loss/actor=-279.811, loss/critic=87.790, n/ep=0, n/st=1, rew=1.11]\n",
      "Epoch #7: test_reward: -136.336815 ± 373.714981, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #8: 5001it [00:43, 114.88it/s, env_step=40000, len=69, loss/actor=-321.426, loss/critic=96.679, n/ep=0, n/st=1, rew=-16.29]\n",
      "Epoch #8: test_reward: -464.612213 ± 647.417402, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #9: 5001it [00:43, 114.96it/s, env_step=45000, len=1000, loss/actor=-378.491, loss/critic=185.083, n/ep=0, n/st=1, rew=-1415.67]\n",
      "Epoch #9: test_reward: -251.119339 ± 501.628859, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #10: 5001it [00:43, 115.03it/s, env_step=50000, len=1000, loss/actor=-462.193, loss/critic=303.088, n/ep=0, n/st=1, rew=-1513.78]\n",
      "Epoch #10: test_reward: -324.735499 ± 571.345074, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '462.04s',\n",
      " 'test_episode': 110,\n",
      " 'test_speed': '1379.45 step/s',\n",
      " 'test_step': 38725,\n",
      " 'test_time': '28.07s',\n",
      " 'train_episode': 183,\n",
      " 'train_speed': '115.22 step/s',\n",
      " 'train_step': 50000,\n",
      " 'train_time/collector': '77.16s',\n",
      " 'train_time/model': '356.81s'}\n",
      "Final reward: -794.2668913391443, length: 512.8\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "!python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4b4eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e19e99e7728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlatest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Ant-v3/ddpg/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Ant-v3/ddpg/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlatest_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/policy.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f641c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
