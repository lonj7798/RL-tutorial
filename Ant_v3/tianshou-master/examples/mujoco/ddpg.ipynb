{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85279acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current location: /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(\"current location:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b025eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = current_path+'/history_ddpg/'\n",
    "task = 'Ant-v3'\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00eafd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"mujoco_ddpg.py\", line 165, in <module>\n",
      "    test_ddpg()\n",
      "  File \"mujoco_ddpg.py\", line 121, in test_ddpg\n",
      "    test_collector = Collector(policy, test_envs)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py\", line 71, in __init__\n",
      "    self._assign_buffer(buffer)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py\", line 81, in _assign_buffer\n",
      "    buffer = VectorReplayBuffer(self.env_num, self.env_num)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/buffer/vecbuf.py\", line 35, in __init__\n",
      "    super().__init__(buffer_list)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/buffer/manager.py\", line 39, in __init__\n",
      "    self._compile()\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/buffer/manager.py\", line 46, in _compile\n",
      "    _prev_index(index, offset, done, last, lens)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py\", line 372, in _compile_for_args\n",
      "    return_val = self.compile(tuple(argtypes))\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py\", line 909, in compile\n",
      "    cres = self._compiler.compile(args, return_type)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py\", line 79, in compile\n",
      "    status, retval = self._compile_cached(args, return_type)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py\", line 93, in _compile_cached\n",
      "    retval = self._compile_core(args, return_type)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py\", line 106, in _compile_core\n",
      "    cres = compiler.compile_extra(self.targetdescr.typing_context,\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler.py\", line 606, in compile_extra\n",
      "    return pipeline.compile_extra(func)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler.py\", line 353, in compile_extra\n",
      "    return self._compile_bytecode()\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler.py\", line 415, in _compile_bytecode\n",
      "    return self._compile_core()\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler.py\", line 386, in _compile_core\n",
      "    pm.run(self.state)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler_machinery.py\", line 330, in run\n",
      "    self._runPass(idx, pass_inst, state)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler_lock.py\", line 35, in _acquire_compile_lock\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler_machinery.py\", line 289, in _runPass\n",
      "    mutated |= check(pss.run_pass, internal_state)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/compiler_machinery.py\", line 262, in check\n",
      "    mangled = func(compiler_state)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typed_passes.py\", line 104, in run_pass\n",
      "    typemap, return_type, calltypes, errs = type_inference_stage(\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typed_passes.py\", line 82, in type_inference_stage\n",
      "    errs = infer.propagate(raise_errors=raise_errors)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typeinfer.py\", line 1063, in propagate\n",
      "    errors = self.constraints.propagate(self)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typeinfer.py\", line 154, in propagate\n",
      "    constraint(typeinfer)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typeinfer.py\", line 689, in __call__\n",
      "    self.resolve(typeinfer, typeinfer.typevars, fnty=fnty)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typeinfer.py\", line 586, in resolve\n",
      "    sig = typeinfer.resolve_call(fnty, pos_args, kw_args)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typeinfer.py\", line 1538, in resolve_call\n",
      "    return self.context.resolve_function_type(fnty, pos_args, kw_args)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/context.py\", line 194, in resolve_function_type\n",
      "    res = self._resolve_user_function_type(func, args, kws)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/context.py\", line 246, in _resolve_user_function_type\n",
      "    return func.get_call_type(self, args, kws)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/types/functions.py\", line 301, in get_call_type\n",
      "    sig = temp.apply(nolitargs, nolitkws)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/templates.py\", line 345, in apply\n",
      "    sig = generic(args, kws)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/npydecl.py\", line 181, in generic\n",
      "    sig = super(NumpyRulesArrayOperator, self).generic(args, kws)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/npydecl.py\", line 129, in generic\n",
      "    ret_tys = [types.Array(dtype=ret_ty, ndim=ndims, layout=layout)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/typing/npydecl.py\", line 129, in <listcomp>\n",
      "    ret_tys = [types.Array(dtype=ret_ty, ndim=ndims, layout=layout)\n",
      "  File \"/home/jaewon/anaconda3/lib/python3.8/site-packages/numba/core/types/abstract.py\", line 60, in __call__\n",
      "    def __call__(cls, *args, **kwargs):\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a344d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TXT file to save the result\n",
    "\n",
    "file_log = history_path+\"/Ant-v3/history_ddpg.txt\"\n",
    "f = open(file_log, 'w')\n",
    "f.write(f'Final Reward, Lenght\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c44edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_003551-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 00:47:46.876664: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.48it/s, env_step=5000, len=160, loss/actor=-34.787, loss/critic=6.198, n/ep=0, n/st=1, rew=-86.06]\n",
      "Epoch #1: test_reward: -478.291404 ± 524.235122, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.10it/s, env_step=10000, len=96, loss/actor=-91.943, loss/critic=13.163, n/ep=0, n/st=1, rew=27.77]\n",
      "Epoch #2: test_reward: -310.400846 ± 470.760070, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.88it/s, env_step=15000, len=47, loss/actor=-136.494, loss/critic=20.018, n/ep=0, n/st=1, rew=-11.74]\n",
      "Epoch #3: test_reward: -545.542172 ± 419.955032, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.49it/s, env_step=20000, len=31, loss/actor=-170.607, loss/critic=20.827, n/ep=0, n/st=1, rew=1.51]\n",
      "Epoch #4: test_reward: -174.944582 ± 295.766652, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.83it/s, env_step=25000, len=301, loss/actor=-205.628, loss/critic=42.510, n/ep=0, n/st=1, rew=-143.51]\n",
      "Epoch #5: test_reward: -294.123131 ± 415.809778, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.50s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1688.58 step/s',\n",
      " 'test_step': 30805,\n",
      " 'test_time': '18.24s',\n",
      " 'train_episode': 115,\n",
      " 'train_speed': '112.48 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.69s',\n",
      " 'train_time/model': '182.57s'}\n",
      "Final reward: -221.32988051510273, length: 239.3\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20de55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005433-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 00:55:55.743644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.75it/s, env_step=5000, len=49, loss/actor=-32.164, loss/critic=4.676, n/ep=0, n/st=1, rew=30.41]\n",
      "Epoch #1: test_reward: -236.420549 ± 420.792631, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.38it/s, env_step=10000, len=84, loss/actor=-73.840, loss/critic=7.354, n/ep=0, n/st=1, rew=-6.78]\n",
      "Epoch #2: test_reward: 1.487024 ± 55.166079, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.38it/s, env_step=15000, len=13, loss/actor=-109.288, loss/critic=12.794, n/ep=0, n/st=1, rew=-15.49]\n",
      "Epoch #3: test_reward: -175.959955 ± 367.418947, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.31it/s, env_step=20000, len=1000, loss/actor=-134.280, loss/critic=16.344, n/ep=0, n/st=1, rew=-534.25]\n",
      "Epoch #4: test_reward: -174.322781 ± 288.733765, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.82it/s, env_step=25000, len=132, loss/actor=-154.993, loss/critic=23.607, n/ep=0, n/st=1, rew=-57.36]\n",
      "Epoch #5: test_reward: -10.823639 ± 25.958319, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.33s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1707.65 step/s',\n",
      " 'test_step': 22241,\n",
      " 'test_time': '13.02s',\n",
      " 'train_episode': 95,\n",
      " 'train_speed': '115.05 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.99s',\n",
      " 'train_time/model': '178.31s'}\n",
      "Final reward: -296.435505713864, length: 525.6\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00317ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:01:38.331205: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.62it/s, env_step=5000, len=62, loss/actor=-28.224, loss/critic=3.255, n/ep=0, n/st=1, rew=13.45]\n",
      "Epoch #1: test_reward: -237.653582 ± 544.476326, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.61it/s, env_step=10000, len=178, loss/actor=-62.727, loss/critic=6.111, n/ep=0, n/st=1, rew=0.10]\n",
      "Epoch #2: test_reward: -237.238641 ± 397.841010, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.19it/s, env_step=15000, len=63, loss/actor=-88.849, loss/critic=9.964, n/ep=0, n/st=1, rew=-10.06]\n",
      "Epoch #3: test_reward: -53.855355 ± 149.320718, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.27it/s, env_step=20000, len=52, loss/actor=-114.416, loss/critic=10.521, n/ep=0, n/st=1, rew=-4.03]\n",
      "Epoch #4: test_reward: -130.995237 ± 195.063068, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.75it/s, env_step=25000, len=16, loss/actor=-138.629, loss/critic=20.467, n/ep=0, n/st=1, rew=6.99]\n",
      "Epoch #5: test_reward: -166.810495 ± 306.868861, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.03s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1538.29 step/s',\n",
      " 'test_step': 25127,\n",
      " 'test_time': '16.33s',\n",
      " 'train_episode': 100,\n",
      " 'train_speed': '113.80 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.89s',\n",
      " 'train_time/model': '180.80s'}\n",
      "Final reward: -169.54873841544327, length: 263.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:06:03.023166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.65it/s, env_step=5000, len=124, loss/actor=-31.651, loss/critic=3.755, n/ep=0, n/st=1, rew=70.14]\n",
      "Epoch #1: test_reward: -91.369758 ± 286.755948, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.39it/s, env_step=10000, len=279, loss/actor=-75.815, loss/critic=7.306, n/ep=0, n/st=1, rew=-68.91]\n",
      "Epoch #2: test_reward: -220.832542 ± 264.597406, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.79it/s, env_step=15000, len=154, loss/actor=-114.702, loss/critic=13.844, n/ep=0, n/st=1, rew=-70.24]\n",
      "Epoch #3: test_reward: -389.208723 ± 355.702228, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.82it/s, env_step=20000, len=1000, loss/actor=-148.019, loss/critic=24.509, n/ep=0, n/st=1, rew=-699.53]\n",
      "Epoch #4: test_reward: -203.640087 ± 316.102664, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.55it/s, env_step=25000, len=39, loss/actor=-179.825, loss/critic=28.304, n/ep=0, n/st=1, rew=-32.50]\n",
      "Epoch #5: test_reward: -197.953990 ± 289.059859, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.42s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1675.38 step/s',\n",
      " 'test_step': 31272,\n",
      " 'test_time': '18.67s',\n",
      " 'train_episode': 64,\n",
      " 'train_speed': '115.34 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.13s',\n",
      " 'train_time/model': '177.62s'}\n",
      "Final reward: -50.18440312654094, length: 149.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:10:27.256845: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.24it/s, env_step=5000, len=1000, loss/actor=-30.603, loss/critic=3.453, n/ep=0, n/st=1, rew=114.70]\n",
      "Epoch #1: test_reward: -607.358295 ± 634.730609, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.57it/s, env_step=10000, len=78, loss/actor=-71.205, loss/critic=7.860, n/ep=0, n/st=1, rew=39.47]\n",
      "Epoch #2: test_reward: -95.977395 ± 192.546516, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.39it/s, env_step=15000, len=26, loss/actor=-102.144, loss/critic=10.859, n/ep=0, n/st=1, rew=11.36]\n",
      "Epoch #3: test_reward: -259.309714 ± 220.970970, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.19it/s, env_step=20000, len=261, loss/actor=-122.401, loss/critic=11.302, n/ep=0, n/st=1, rew=2.08]\n",
      "Epoch #4: test_reward: -130.710114 ± 257.483419, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.91it/s, env_step=25000, len=51, loss/actor=-139.875, loss/critic=14.723, n/ep=0, n/st=1, rew=-27.01]\n",
      "Epoch #5: test_reward: -122.448231 ± 196.130619, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.84s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1678.11 step/s',\n",
      " 'test_step': 29644,\n",
      " 'test_time': '17.67s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '114.59 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.72s',\n",
      " 'train_time/model': '178.46s'}\n",
      "Final reward: -107.96852652178299, length: 208.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:14:51.843476: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.45it/s, env_step=5000, len=1000, loss/actor=-30.889, loss/critic=5.423, n/ep=0, n/st=1, rew=-559.51]\n",
      "Epoch #1: test_reward: 31.349946 ± 29.367916, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.02it/s, env_step=10000, len=1000, loss/actor=-74.088, loss/critic=8.854, n/ep=0, n/st=1, rew=-916.67]\n",
      "Epoch #2: test_reward: -76.580136 ± 200.421496, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.00it/s, env_step=15000, len=15, loss/actor=-110.197, loss/critic=13.732, n/ep=0, n/st=1, rew=-7.54]\n",
      "Epoch #3: test_reward: -86.868472 ± 249.021335, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.19it/s, env_step=20000, len=30, loss/actor=-140.285, loss/critic=20.992, n/ep=0, n/st=1, rew=-25.50]\n",
      "Epoch #4: test_reward: -126.031124 ± 231.725843, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.72it/s, env_step=25000, len=174, loss/actor=-171.328, loss/critic=25.748, n/ep=0, n/st=1, rew=-82.60]\n",
      "Epoch #5: test_reward: -18.183171 ± 27.783503, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.76s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1312.64 step/s',\n",
      " 'test_step': 17010,\n",
      " 'test_time': '12.96s',\n",
      " 'train_episode': 91,\n",
      " 'train_speed': '114.79 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.35s',\n",
      " 'train_time/model': '178.45s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -99.45049018586003, length: 152.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:19:11.914365: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.66it/s, env_step=5000, len=1000, loss/actor=-32.921, loss/critic=4.338, n/ep=0, n/st=1, rew=502.93]\n",
      "Epoch #1: test_reward: -211.466800 ± 407.870525, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.21it/s, env_step=10000, len=10, loss/actor=-79.322, loss/critic=12.823, n/ep=0, n/st=1, rew=-13.38]\n",
      "Epoch #2: test_reward: -1.262770 ± 9.689394, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.94it/s, env_step=15000, len=120, loss/actor=-117.349, loss/critic=13.493, n/ep=0, n/st=1, rew=-59.86]\n",
      "Epoch #3: test_reward: -256.282707 ± 305.608604, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.62it/s, env_step=20000, len=885, loss/actor=-153.432, loss/critic=20.915, n/ep=0, n/st=1, rew=-751.41]\n",
      "Epoch #4: test_reward: -139.316574 ± 274.853590, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.89it/s, env_step=25000, len=14, loss/actor=-190.398, loss/critic=41.221, n/ep=0, n/st=1, rew=-15.43]\n",
      "Epoch #5: test_reward: -21.043983 ± 28.037460, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.13s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1609.09 step/s',\n",
      " 'test_step': 19792,\n",
      " 'test_time': '12.30s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '114.77 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.69s',\n",
      " 'train_time/model': '179.14s'}\n",
      "Final reward: -212.00682288007715, length: 246.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:23:30.599114: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.27it/s, env_step=5000, len=601, loss/actor=-31.356, loss/critic=3.825, n/ep=0, n/st=1, rew=159.36]\n",
      "Epoch #1: test_reward: -813.753150 ± 986.752814, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.95it/s, env_step=10000, len=106, loss/actor=-70.192, loss/critic=7.141, n/ep=0, n/st=1, rew=11.88]\n",
      "Epoch #2: test_reward: -316.335252 ± 390.420601, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.42it/s, env_step=15000, len=1000, loss/actor=-101.181, loss/critic=8.533, n/ep=0, n/st=1, rew=-663.46]\n",
      "Epoch #3: test_reward: -73.152822 ± 145.091570, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.85it/s, env_step=20000, len=1000, loss/actor=-127.868, loss/critic=13.952, n/ep=0, n/st=1, rew=-561.27]\n",
      "Epoch #4: test_reward: -79.021213 ± 169.899918, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.57it/s, env_step=25000, len=146, loss/actor=-154.841, loss/critic=23.302, n/ep=0, n/st=1, rew=-16.55]\n",
      "Epoch #5: test_reward: -173.334325 ± 247.210306, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.02s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1555.41 step/s',\n",
      " 'test_step': 26091,\n",
      " 'test_time': '16.77s',\n",
      " 'train_episode': 86,\n",
      " 'train_speed': '116.14 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.36s',\n",
      " 'train_time/model': '176.89s'}\n",
      "Final reward: -190.25020695623851, length: 360.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:27:51.603404: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.63it/s, env_step=5000, len=61, loss/actor=-31.306, loss/critic=4.722, n/ep=0, n/st=1, rew=39.00]\n",
      "Epoch #1: test_reward: -151.334964 ± 364.242326, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.47it/s, env_step=10000, len=77, loss/actor=-74.854, loss/critic=8.831, n/ep=0, n/st=1, rew=-7.70]\n",
      "Epoch #2: test_reward: -211.407310 ± 413.755798, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.10it/s, env_step=15000, len=74, loss/actor=-115.989, loss/critic=14.919, n/ep=0, n/st=1, rew=-15.87]\n",
      "Epoch #3: test_reward: -110.746599 ± 198.915260, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.42it/s, env_step=20000, len=55, loss/actor=-155.503, loss/critic=28.589, n/ep=0, n/st=1, rew=15.35]\n",
      "Epoch #4: test_reward: -192.112027 ± 312.699433, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 120.05it/s, env_step=25000, len=33, loss/actor=-190.116, loss/critic=35.013, n/ep=0, n/st=1, rew=-26.34]\n",
      "Epoch #5: test_reward: -260.656349 ± 338.023483, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.97s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1487.32 step/s',\n",
      " 'test_step': 23787,\n",
      " 'test_time': '15.99s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '116.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.35s',\n",
      " 'train_time/model': '175.63s'}\n",
      "Final reward: -336.10102018215645, length: 469.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:32:11.068864: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.24it/s, env_step=5000, len=37, loss/actor=-31.809, loss/critic=4.141, n/ep=0, n/st=1, rew=38.32]\n",
      "Epoch #1: test_reward: -299.967111 ± 408.453714, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.75it/s, env_step=10000, len=40, loss/actor=-72.588, loss/critic=7.810, n/ep=0, n/st=1, rew=2.18]\n",
      "Epoch #2: test_reward: -174.817440 ± 424.207343, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.55it/s, env_step=15000, len=1000, loss/actor=-109.585, loss/critic=13.580, n/ep=0, n/st=1, rew=-589.18]\n",
      "Epoch #3: test_reward: -115.953159 ± 204.445370, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.73it/s, env_step=20000, len=81, loss/actor=-142.682, loss/critic=22.289, n/ep=0, n/st=1, rew=17.56]\n",
      "Epoch #4: test_reward: -176.734324 ± 283.144268, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.16it/s, env_step=25000, len=164, loss/actor=-169.633, loss/critic=27.505, n/ep=0, n/st=1, rew=-59.37]\n",
      "Epoch #5: test_reward: -310.951194 ± 344.409097, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1631.25 step/s',\n",
      " 'test_step': 28797,\n",
      " 'test_time': '17.65s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '114.02 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.72s',\n",
      " 'train_time/model': '180.55s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -99.56375346919165, length: 159.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:36:36.259587: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.43it/s, env_step=5000, len=25, loss/actor=-33.278, loss/critic=5.187, n/ep=0, n/st=1, rew=4.56]\n",
      "Epoch #1: test_reward: -502.997897 ± 639.551908, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.28it/s, env_step=10000, len=418, loss/actor=-78.020, loss/critic=11.345, n/ep=0, n/st=1, rew=-134.47]\n",
      "Epoch #2: test_reward: -219.068316 ± 313.484601, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.30it/s, env_step=15000, len=62, loss/actor=-114.894, loss/critic=15.392, n/ep=0, n/st=1, rew=-11.80]\n",
      "Epoch #3: test_reward: -223.865670 ± 321.305497, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.79it/s, env_step=20000, len=38, loss/actor=-151.211, loss/critic=32.503, n/ep=0, n/st=1, rew=-31.50]\n",
      "Epoch #4: test_reward: -125.592738 ± 265.618711, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.12it/s, env_step=25000, len=51, loss/actor=-180.941, loss/critic=38.747, n/ep=0, n/st=1, rew=16.59]\n",
      "Epoch #5: test_reward: -325.252154 ± 439.361305, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '241.47s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1533.49 step/s',\n",
      " 'test_step': 26480,\n",
      " 'test_time': '17.27s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '111.50 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.78s',\n",
      " 'train_time/model': '184.42s'}\n",
      "Final reward: -223.8498387423886, length: 246.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:41:06.552088: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.18it/s, env_step=5000, len=69, loss/actor=-33.994, loss/critic=5.666, n/ep=0, n/st=1, rew=-57.74]\n",
      "Epoch #1: test_reward: -423.287948 ± 724.454110, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.29it/s, env_step=10000, len=46, loss/actor=-88.474, loss/critic=14.146, n/ep=0, n/st=1, rew=5.30]\n",
      "Epoch #2: test_reward: -121.100569 ± 279.778609, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.95it/s, env_step=15000, len=19, loss/actor=-143.562, loss/critic=28.613, n/ep=0, n/st=1, rew=-16.04]\n",
      "Epoch #3: test_reward: -119.100571 ± 242.156595, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.38it/s, env_step=20000, len=1000, loss/actor=-193.830, loss/critic=32.663, n/ep=0, n/st=1, rew=-953.70]\n",
      "Epoch #4: test_reward: -129.445093 ± 269.113542, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 119.06it/s, env_step=25000, len=42, loss/actor=-233.605, loss/critic=43.284, n/ep=0, n/st=1, rew=6.66]\n",
      "Epoch #5: test_reward: -230.409405 ± 426.384047, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.27s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1434.58 step/s',\n",
      " 'test_step': 22744,\n",
      " 'test_time': '15.85s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '113.42 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.19s',\n",
      " 'train_time/model': '181.22s'}\n",
      "Final reward: -226.906324446192, length: 230.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:45:31.191349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 107.78it/s, env_step=5000, len=16, loss/actor=-32.644, loss/critic=3.855, n/ep=0, n/st=1, rew=4.70]\n",
      "Epoch #1: test_reward: -254.363520 ± 409.627664, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.12it/s, env_step=10000, len=41, loss/actor=-69.904, loss/critic=5.863, n/ep=0, n/st=1, rew=23.24]\n",
      "Epoch #2: test_reward: -180.683898 ± 375.185473, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.52it/s, env_step=15000, len=102, loss/actor=-94.816, loss/critic=8.211, n/ep=0, n/st=1, rew=13.26]\n",
      "Epoch #3: test_reward: -34.331424 ± 145.010460, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.99it/s, env_step=20000, len=78, loss/actor=-117.410, loss/critic=14.299, n/ep=0, n/st=1, rew=4.69]\n",
      "Epoch #4: test_reward: -134.327629 ± 226.691734, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.95it/s, env_step=25000, len=19, loss/actor=-138.715, loss/critic=19.446, n/ep=0, n/st=1, rew=-10.25]\n",
      "Epoch #5: test_reward: -84.524141 ± 122.158804, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.79s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1509.14 step/s',\n",
      " 'test_step': 24542,\n",
      " 'test_time': '16.26s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '112.34 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.12s',\n",
      " 'train_time/model': '183.41s'}\n",
      "Final reward: -77.81813130278867, length: 241.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_005555-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:49:58.695800: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.73it/s, env_step=5000, len=115, loss/actor=-31.122, loss/critic=4.983, n/ep=0, n/st=1, rew=51.60]\n",
      "Epoch #1: test_reward: -205.272023 ± 473.850206, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.67it/s, env_step=10000, len=35, loss/actor=-81.100, loss/critic=11.539, n/ep=0, n/st=1, rew=-15.89]\n",
      "Epoch #2: test_reward: -17.682043 ± 60.883141, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.56it/s, env_step=15000, len=34, loss/actor=-119.132, loss/critic=17.382, n/ep=0, n/st=1, rew=-4.03]\n",
      "Epoch #3: test_reward: -161.890670 ± 326.442053, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.05it/s, env_step=20000, len=17, loss/actor=-144.167, loss/critic=24.938, n/ep=0, n/st=1, rew=-0.82]\n",
      "Epoch #4: test_reward: -221.767496 ± 324.599476, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.81it/s, env_step=25000, len=56, loss/actor=-162.741, loss/critic=21.168, n/ep=0, n/st=1, rew=-42.64]\n",
      "Epoch #5: test_reward: -156.362992 ± 253.937169, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.13s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1527.74 step/s',\n",
      " 'test_step': 22823,\n",
      " 'test_time': '14.94s',\n",
      " 'train_episode': 123,\n",
      " 'train_speed': '115.11 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.41s',\n",
      " 'train_time/model': '178.78s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -50.73012329586728, length: 166.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:54:19.526433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.39it/s, env_step=5000, len=97, loss/actor=-32.565, loss/critic=4.146, n/ep=0, n/st=1, rew=37.95]\n",
      "Epoch #1: test_reward: -135.238484 ± 313.136266, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.21it/s, env_step=10000, len=137, loss/actor=-79.411, loss/critic=8.857, n/ep=0, n/st=1, rew=-61.52]\n",
      "Epoch #2: test_reward: -167.106736 ± 287.155228, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.03it/s, env_step=15000, len=45, loss/actor=-121.331, loss/critic=15.561, n/ep=0, n/st=1, rew=-17.37]\n",
      "Epoch #3: test_reward: -89.614942 ± 258.780163, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.49it/s, env_step=20000, len=138, loss/actor=-150.501, loss/critic=23.889, n/ep=0, n/st=1, rew=-16.81]\n",
      "Epoch #4: test_reward: -153.145442 ± 279.168678, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.88it/s, env_step=25000, len=19, loss/actor=-173.206, loss/critic=23.903, n/ep=0, n/st=1, rew=11.19]\n",
      "Epoch #5: test_reward: -561.076868 ± 576.869696, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.84s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1553.23 step/s',\n",
      " 'test_step': 25672,\n",
      " 'test_time': '16.53s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '114.51 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.46s',\n",
      " 'train_time/model': '178.85s'}\n",
      "Final reward: -62.149355815231765, length: 135.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 01:58:42.756857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.07it/s, env_step=5000, len=1000, loss/actor=-33.656, loss/critic=5.015, n/ep=0, n/st=1, rew=-520.89]\n",
      "Epoch #1: test_reward: -145.131758 ± 400.322969, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.56it/s, env_step=10000, len=32, loss/actor=-85.559, loss/critic=10.772, n/ep=0, n/st=1, rew=-1.03]\n",
      "Epoch #2: test_reward: -322.075452 ± 471.956271, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.49it/s, env_step=15000, len=21, loss/actor=-134.418, loss/critic=20.059, n/ep=0, n/st=1, rew=-18.93]\n",
      "Epoch #3: test_reward: -271.473951 ± 396.487431, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.46it/s, env_step=20000, len=14, loss/actor=-174.876, loss/critic=28.515, n/ep=0, n/st=1, rew=-10.70]\n",
      "Epoch #4: test_reward: -233.662775 ± 306.820573, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.79it/s, env_step=25000, len=1000, loss/actor=-213.371, loss/critic=41.207, n/ep=0, n/st=1, rew=-1029.15]\n",
      "Epoch #5: test_reward: -243.834908 ± 372.930673, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.04s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1486.58 step/s',\n",
      " 'test_step': 24558,\n",
      " 'test_time': '16.52s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '114.40 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.92s',\n",
      " 'train_time/model': '179.60s'}\n",
      "Final reward: -238.62832756238703, length: 252.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:03:06.601482: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.28it/s, env_step=5000, len=25, loss/actor=-32.745, loss/critic=5.101, n/ep=0, n/st=1, rew=-8.14]\n",
      "Epoch #1: test_reward: -82.888068 ± 356.102195, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.22it/s, env_step=10000, len=38, loss/actor=-79.858, loss/critic=9.653, n/ep=0, n/st=1, rew=25.56]\n",
      "Epoch #2: test_reward: -2.326372 ± 22.446845, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.03it/s, env_step=15000, len=1000, loss/actor=-123.324, loss/critic=16.567, n/ep=0, n/st=1, rew=-872.04]\n",
      "Epoch #3: test_reward: -3.861845 ± 26.930791, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:41, 120.18it/s, env_step=20000, len=39, loss/actor=-160.075, loss/critic=27.277, n/ep=0, n/st=1, rew=-16.49]\n",
      "Epoch #4: test_reward: -236.639906 ± 457.559702, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 121.21it/s, env_step=25000, len=18, loss/actor=-197.824, loss/critic=28.884, n/ep=0, n/st=1, rew=-3.80]\n",
      "Epoch #5: test_reward: -288.214589 ± 407.412960, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '225.29s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1538.03 step/s',\n",
      " 'test_step': 18590,\n",
      " 'test_time': '12.09s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '117.26 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.43s',\n",
      " 'train_time/model': '174.77s'}\n",
      "Final reward: -213.58680948273985, length: 269.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:07:20.502586: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.64it/s, env_step=5000, len=25, loss/actor=-29.787, loss/critic=3.910, n/ep=0, n/st=1, rew=8.50]\n",
      "Epoch #1: test_reward: -481.060037 ± 334.330762, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.46it/s, env_step=10000, len=45, loss/actor=-74.935, loss/critic=8.159, n/ep=0, n/st=1, rew=-10.29]\n",
      "Epoch #2: test_reward: -275.795836 ± 436.289912, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.44it/s, env_step=15000, len=19, loss/actor=-116.455, loss/critic=14.501, n/ep=0, n/st=1, rew=-1.25]\n",
      "Epoch #3: test_reward: -344.928271 ± 431.848831, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.16it/s, env_step=20000, len=90, loss/actor=-150.923, loss/critic=24.209, n/ep=0, n/st=1, rew=-24.95]\n",
      "Epoch #4: test_reward: -177.733440 ± 350.085841, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.42it/s, env_step=25000, len=1000, loss/actor=-186.341, loss/critic=30.396, n/ep=0, n/st=1, rew=-740.79]\n",
      "Epoch #5: test_reward: -256.024636 ± 359.308877, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.73s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1707.78 step/s',\n",
      " 'test_step': 31458,\n",
      " 'test_time': '18.42s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '112.96 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.05s',\n",
      " 'train_time/model': '182.26s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -114.14255094473235, length: 265.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:11:48.935248: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.88it/s, env_step=5000, len=128, loss/actor=-33.151, loss/critic=6.482, n/ep=0, n/st=1, rew=-71.06]\n",
      "Epoch #1: test_reward: -103.690815 ± 313.074926, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.91it/s, env_step=10000, len=53, loss/actor=-87.527, loss/critic=12.560, n/ep=0, n/st=1, rew=-19.89]\n",
      "Epoch #2: test_reward: -114.951700 ± 322.493823, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.29it/s, env_step=15000, len=19, loss/actor=-144.239, loss/critic=27.498, n/ep=0, n/st=1, rew=-13.77]\n",
      "Epoch #3: test_reward: -317.216610 ± 463.231233, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.13it/s, env_step=20000, len=55, loss/actor=-188.605, loss/critic=44.354, n/ep=0, n/st=1, rew=-40.23]\n",
      "Epoch #4: test_reward: -128.164626 ± 314.490313, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.79it/s, env_step=25000, len=1000, loss/actor=-229.333, loss/critic=51.189, n/ep=0, n/st=1, rew=-1235.85]\n",
      "Epoch #5: test_reward: -417.495992 ± 564.752194, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.56s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1362.24 step/s',\n",
      " 'test_step': 20929,\n",
      " 'test_time': '15.36s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '112.51 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.05s',\n",
      " 'train_time/model': '183.15s'}\n",
      "Final reward: -433.65669475512993, length: 331.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:16:15.398621: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.75it/s, env_step=5000, len=78, loss/actor=-32.367, loss/critic=4.353, n/ep=0, n/st=1, rew=50.49]\n",
      "Epoch #1: test_reward: 16.998340 ± 58.684719, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.37it/s, env_step=10000, len=125, loss/actor=-76.382, loss/critic=8.508, n/ep=0, n/st=1, rew=86.24]\n",
      "Epoch #2: test_reward: -153.149536 ± 299.703678, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.48it/s, env_step=15000, len=168, loss/actor=-111.136, loss/critic=12.892, n/ep=0, n/st=1, rew=49.98]\n",
      "Epoch #3: test_reward: -67.661762 ± 196.638854, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.43it/s, env_step=20000, len=95, loss/actor=-138.479, loss/critic=21.920, n/ep=0, n/st=1, rew=5.73]\n",
      "Epoch #4: test_reward: -70.955641 ± 202.465796, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 111.05it/s, env_step=25000, len=13, loss/actor=-160.523, loss/critic=24.844, n/ep=0, n/st=1, rew=1.58]\n",
      "Epoch #5: test_reward: -139.220825 ± 261.566652, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.62s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1384.73 step/s',\n",
      " 'test_step': 19842,\n",
      " 'test_time': '14.33s',\n",
      " 'train_episode': 112,\n",
      " 'train_speed': '111.96 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.20s',\n",
      " 'train_time/model': '184.09s'}\n",
      "Final reward: -10.874010270730395, length: 90.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:20:40.616468: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.24it/s, env_step=5000, len=69, loss/actor=-28.355, loss/critic=3.137, n/ep=0, n/st=1, rew=5.47]\n",
      "Epoch #1: test_reward: 58.844852 ± 258.255461, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.34it/s, env_step=10000, len=116, loss/actor=-70.370, loss/critic=5.589, n/ep=0, n/st=1, rew=61.78]\n",
      "Epoch #2: test_reward: -33.610870 ± 140.214242, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.55it/s, env_step=15000, len=1000, loss/actor=-107.158, loss/critic=9.581, n/ep=0, n/st=1, rew=-491.35]\n",
      "Epoch #3: test_reward: -133.200488 ± 198.410581, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.53it/s, env_step=20000, len=98, loss/actor=-138.513, loss/critic=16.097, n/ep=0, n/st=1, rew=-12.63]\n",
      "Epoch #4: test_reward: -169.862312 ± 246.244134, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.55it/s, env_step=25000, len=41, loss/actor=-165.646, loss/critic=20.248, n/ep=0, n/st=1, rew=-55.32]\n",
      "Epoch #5: test_reward: -363.529250 ± 357.604518, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.91s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1587.59 step/s',\n",
      " 'test_step': 28158,\n",
      " 'test_time': '17.74s',\n",
      " 'train_episode': 69,\n",
      " 'train_speed': '113.55 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.87s',\n",
      " 'train_time/model': '181.30s'}\n",
      "Final reward: -200.0809122932763, length: 356.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:25:07.565507: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.76it/s, env_step=5000, len=414, loss/actor=-30.279, loss/critic=4.117, n/ep=0, n/st=1, rew=62.20]\n",
      "Epoch #1: test_reward: -118.999304 ± 251.675731, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.33it/s, env_step=10000, len=28, loss/actor=-72.999, loss/critic=8.408, n/ep=0, n/st=1, rew=-4.50]\n",
      "Epoch #2: test_reward: -138.065145 ± 319.947685, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.89it/s, env_step=15000, len=64, loss/actor=-105.020, loss/critic=9.652, n/ep=0, n/st=1, rew=-52.20]\n",
      "Epoch #3: test_reward: -76.172577 ± 151.975444, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.43it/s, env_step=20000, len=35, loss/actor=-134.394, loss/critic=22.538, n/ep=0, n/st=1, rew=-16.21]\n",
      "Epoch #4: test_reward: -80.828194 ± 89.725867, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.10it/s, env_step=25000, len=70, loss/actor=-159.730, loss/critic=21.985, n/ep=0, n/st=1, rew=-18.47]\n",
      "Epoch #5: test_reward: -34.843015 ± 41.485306, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.95s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1528.29 step/s',\n",
      " 'test_step': 22502,\n",
      " 'test_time': '14.72s',\n",
      " 'train_episode': 76,\n",
      " 'train_speed': '114.04 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.62s',\n",
      " 'train_time/model': '180.61s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -125.39082966202636, length: 185.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:29:30.277152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.21it/s, env_step=5000, len=115, loss/actor=-31.296, loss/critic=4.159, n/ep=0, n/st=1, rew=65.05]\n",
      "Epoch #1: test_reward: -370.532782 ± 404.340859, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.77it/s, env_step=10000, len=1000, loss/actor=-75.047, loss/critic=6.701, n/ep=0, n/st=1, rew=-624.51]\n",
      "Epoch #2: test_reward: -148.155780 ± 253.949128, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.85it/s, env_step=15000, len=1000, loss/actor=-114.254, loss/critic=14.668, n/ep=0, n/st=1, rew=-694.18]\n",
      "Epoch #3: test_reward: -379.814420 ± 366.100540, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.87it/s, env_step=20000, len=1000, loss/actor=-149.516, loss/critic=18.680, n/ep=0, n/st=1, rew=-673.45]\n",
      "Epoch #4: test_reward: -218.107966 ± 320.881381, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.25it/s, env_step=25000, len=1000, loss/actor=-184.376, loss/critic=32.576, n/ep=0, n/st=1, rew=-906.58]\n",
      "Epoch #5: test_reward: -320.048807 ± 392.115775, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.80s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1660.88 step/s',\n",
      " 'test_step': 30200,\n",
      " 'test_time': '18.18s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '113.32 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.43s',\n",
      " 'train_time/model': '181.19s'}\n",
      "Final reward: -149.76413114072142, length: 236.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:33:57.531783: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.63it/s, env_step=5000, len=1000, loss/actor=-32.647, loss/critic=4.803, n/ep=0, n/st=1, rew=480.68]\n",
      "Epoch #1: test_reward: 12.546783 ± 24.210322, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.19it/s, env_step=10000, len=31, loss/actor=-76.716, loss/critic=8.275, n/ep=0, n/st=1, rew=17.89]\n",
      "Epoch #2: test_reward: -301.823386 ± 379.398756, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.72it/s, env_step=15000, len=541, loss/actor=-112.007, loss/critic=9.997, n/ep=0, n/st=1, rew=-50.11]\n",
      "Epoch #3: test_reward: -178.301490 ± 247.992202, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.24it/s, env_step=20000, len=33, loss/actor=-136.478, loss/critic=12.776, n/ep=0, n/st=1, rew=-18.76]\n",
      "Epoch #4: test_reward: -202.310586 ± 270.462281, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.37it/s, env_step=25000, len=82, loss/actor=-158.532, loss/critic=26.255, n/ep=0, n/st=1, rew=-48.24]\n",
      "Epoch #5: test_reward: -152.327727 ± 251.892503, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.02s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1664.84 step/s',\n",
      " 'test_step': 24824,\n",
      " 'test_time': '14.91s',\n",
      " 'train_episode': 72,\n",
      " 'train_speed': '112.56 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.12s',\n",
      " 'train_time/model': '182.99s'}\n",
      "Final reward: -251.7017609067194, length: 431.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:38:23.961600: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.21it/s, env_step=5000, len=14, loss/actor=-33.836, loss/critic=6.365, n/ep=0, n/st=1, rew=-2.28]\n",
      "Epoch #1: test_reward: 81.113904 ± 231.550449, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.14it/s, env_step=10000, len=145, loss/actor=-98.798, loss/critic=16.438, n/ep=0, n/st=1, rew=-99.31]\n",
      "Epoch #2: test_reward: -178.648456 ± 350.481668, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.04it/s, env_step=15000, len=26, loss/actor=-169.797, loss/critic=37.113, n/ep=0, n/st=1, rew=17.66]\n",
      "Epoch #3: test_reward: -404.992574 ± 457.947391, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.17it/s, env_step=20000, len=23, loss/actor=-245.370, loss/critic=64.429, n/ep=0, n/st=1, rew=-18.40]\n",
      "Epoch #4: test_reward: -252.096654 ± 336.894321, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 120.02it/s, env_step=25000, len=17, loss/actor=-351.688, loss/critic=220.557, n/ep=0, n/st=1, rew=0.25]\n",
      "Epoch #5: test_reward: -95.119463 ± 81.431638, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.13s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1664.24 step/s',\n",
      " 'test_step': 27253,\n",
      " 'test_time': '16.38s',\n",
      " 'train_episode': 116,\n",
      " 'train_speed': '113.77 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.90s',\n",
      " 'train_time/model': '180.85s'}\n",
      "Final reward: -198.88932188699846, length: 212.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:42:49.076057: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.38it/s, env_step=5000, len=136, loss/actor=-32.534, loss/critic=5.090, n/ep=0, n/st=1, rew=69.16]\n",
      "Epoch #1: test_reward: 135.360144 ± 202.299966, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.63it/s, env_step=10000, len=1000, loss/actor=-76.961, loss/critic=8.283, n/ep=0, n/st=1, rew=-821.73]\n",
      "Epoch #2: test_reward: -331.742531 ± 419.510113, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.66it/s, env_step=15000, len=189, loss/actor=-115.129, loss/critic=11.849, n/ep=0, n/st=1, rew=-90.59]\n",
      "Epoch #3: test_reward: -97.984213 ± 225.807402, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.14it/s, env_step=20000, len=30, loss/actor=-146.821, loss/critic=17.784, n/ep=0, n/st=1, rew=1.61]\n",
      "Epoch #4: test_reward: -156.657432 ± 232.473843, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.57it/s, env_step=25000, len=220, loss/actor=-175.530, loss/critic=27.199, n/ep=0, n/st=1, rew=-58.20]\n",
      "Epoch #5: test_reward: -194.005043 ± 252.148208, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.58s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1509.78 step/s',\n",
      " 'test_step': 25373,\n",
      " 'test_time': '16.81s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '113.75 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.08s',\n",
      " 'train_time/model': '180.70s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -87.86890551403594, length: 139.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:47:14.104757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.39it/s, env_step=5000, len=182, loss/actor=-30.678, loss/critic=4.294, n/ep=0, n/st=1, rew=-69.74]\n",
      "Epoch #1: test_reward: -52.782681 ± 379.030695, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.57it/s, env_step=10000, len=71, loss/actor=-76.853, loss/critic=12.159, n/ep=0, n/st=1, rew=41.49]\n",
      "Epoch #2: test_reward: -69.247933 ± 209.897347, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.59it/s, env_step=15000, len=1000, loss/actor=-128.612, loss/critic=21.664, n/ep=0, n/st=1, rew=-790.68]\n",
      "Epoch #3: test_reward: -197.711906 ± 364.163083, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.56it/s, env_step=20000, len=1000, loss/actor=-183.851, loss/critic=40.920, n/ep=0, n/st=1, rew=-1153.68]\n",
      "Epoch #4: test_reward: -67.379228 ± 127.309609, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.69it/s, env_step=25000, len=281, loss/actor=-239.806, loss/critic=61.955, n/ep=0, n/st=1, rew=-118.12]\n",
      "Epoch #5: test_reward: -152.331460 ± 193.322539, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.00s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1534.08 step/s',\n",
      " 'test_step': 24221,\n",
      " 'test_time': '15.79s',\n",
      " 'train_episode': 94,\n",
      " 'train_speed': '111.50 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.46s',\n",
      " 'train_time/model': '184.75s'}\n",
      "Final reward: -260.58464037525493, length: 266.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:51:42.962547: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.04it/s, env_step=5000, len=1000, loss/actor=-32.123, loss/critic=4.243, n/ep=0, n/st=1, rew=-454.79]\n",
      "Epoch #1: test_reward: 3.591450 ± 15.705982, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.00it/s, env_step=10000, len=110, loss/actor=-73.957, loss/critic=9.448, n/ep=0, n/st=1, rew=-131.81]\n",
      "Epoch #2: test_reward: -72.312691 ± 183.168512, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.65it/s, env_step=15000, len=28, loss/actor=-112.119, loss/critic=13.469, n/ep=0, n/st=1, rew=-28.48]\n",
      "Epoch #3: test_reward: -408.285719 ± 752.624060, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.31it/s, env_step=20000, len=43, loss/actor=-152.008, loss/critic=44.905, n/ep=0, n/st=1, rew=-30.55]\n",
      "Epoch #4: test_reward: -135.925986 ± 369.400226, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.29it/s, env_step=25000, len=36, loss/actor=-197.260, loss/critic=71.369, n/ep=0, n/st=1, rew=-18.77]\n",
      "Epoch #5: test_reward: -143.338654 ± 339.265278, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.05s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1326.81 step/s',\n",
      " 'test_step': 17340,\n",
      " 'test_time': '13.07s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '114.16 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.82s',\n",
      " 'train_time/model': '180.17s'}\n",
      "Final reward: -177.40474375219748, length: 136.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 02:56:03.215362: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 108.62it/s, env_step=5000, len=21, loss/actor=-31.575, loss/critic=4.100, n/ep=0, n/st=1, rew=-12.30]\n",
      "Epoch #1: test_reward: 16.117295 ± 13.319471, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:41, 119.70it/s, env_step=10000, len=830, loss/actor=-66.979, loss/critic=6.413, n/ep=0, n/st=1, rew=-273.51]\n",
      "Epoch #2: test_reward: -29.261292 ± 107.725171, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.06it/s, env_step=15000, len=76, loss/actor=-102.994, loss/critic=10.933, n/ep=0, n/st=1, rew=32.89]\n",
      "Epoch #3: test_reward: -233.038205 ± 299.193343, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:46, 107.79it/s, env_step=20000, len=62, loss/actor=-128.564, loss/critic=13.949, n/ep=0, n/st=1, rew=-27.22]\n",
      "Epoch #4: test_reward: -29.975285 ± 78.855510, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.86it/s, env_step=25000, len=37, loss/actor=-149.613, loss/critic=18.857, n/ep=0, n/st=1, rew=17.89]\n",
      "Epoch #5: test_reward: -172.679207 ± 242.046888, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.96s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1663.31 step/s',\n",
      " 'test_step': 21408,\n",
      " 'test_time': '12.87s',\n",
      " 'train_episode': 83,\n",
      " 'train_speed': '111.56 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.20s',\n",
      " 'train_time/model': '184.89s'}\n",
      "Final reward: -142.61092370946017, length: 280.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:00:29.462464: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.46it/s, env_step=5000, len=1000, loss/actor=-35.227, loss/critic=5.582, n/ep=0, n/st=1, rew=-910.83]\n",
      "Epoch #1: test_reward: -127.283152 ± 340.019542, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.93it/s, env_step=10000, len=65, loss/actor=-88.876, loss/critic=12.786, n/ep=0, n/st=1, rew=8.14]\n",
      "Epoch #2: test_reward: 11.018613 ± 44.049354, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.84it/s, env_step=15000, len=73, loss/actor=-132.315, loss/critic=25.716, n/ep=0, n/st=1, rew=10.61]\n",
      "Epoch #3: test_reward: -96.298585 ± 252.980325, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.50it/s, env_step=20000, len=313, loss/actor=-167.962, loss/critic=24.894, n/ep=0, n/st=1, rew=-76.45]\n",
      "Epoch #4: test_reward: -58.857854 ± 57.231997, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.20it/s, env_step=25000, len=83, loss/actor=-197.141, loss/critic=36.305, n/ep=0, n/st=1, rew=-51.20]\n",
      "Epoch #5: test_reward: -223.292879 ± 348.978939, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.30s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1442.56 step/s',\n",
      " 'test_step': 17815,\n",
      " 'test_time': '12.35s',\n",
      " 'train_episode': 108,\n",
      " 'train_speed': '113.66 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.51s',\n",
      " 'train_time/model': '180.44s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -27.874301319446733, length: 82.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:04:48.871989: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 108.41it/s, env_step=5000, len=54, loss/actor=-31.258, loss/critic=4.453, n/ep=0, n/st=1, rew=-5.50]\n",
      "Epoch #1: test_reward: -169.260418 ± 320.038974, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.42it/s, env_step=10000, len=213, loss/actor=-72.093, loss/critic=7.911, n/ep=0, n/st=1, rew=21.37]\n",
      "Epoch #2: test_reward: -126.234692 ± 280.961214, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.94it/s, env_step=15000, len=1000, loss/actor=-105.765, loss/critic=10.590, n/ep=0, n/st=1, rew=-728.13]\n",
      "Epoch #3: test_reward: -81.795071 ± 166.700307, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.85it/s, env_step=20000, len=18, loss/actor=-138.274, loss/critic=27.911, n/ep=0, n/st=1, rew=-4.03]\n",
      "Epoch #4: test_reward: -232.454940 ± 380.461990, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.96it/s, env_step=25000, len=59, loss/actor=-165.511, loss/critic=40.382, n/ep=0, n/st=1, rew=-35.36]\n",
      "Epoch #5: test_reward: -226.891086 ± 360.924827, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.25s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1472.40 step/s',\n",
      " 'test_step': 22804,\n",
      " 'test_time': '15.49s',\n",
      " 'train_episode': 96,\n",
      " 'train_speed': '111.23 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.33s',\n",
      " 'train_time/model': '185.43s'}\n",
      "Final reward: -107.58432765087855, length: 156.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:09:17.740293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.10it/s, env_step=5000, len=125, loss/actor=-33.594, loss/critic=5.465, n/ep=0, n/st=1, rew=-14.72]\n",
      "Epoch #1: test_reward: -73.505503 ± 265.461310, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.77it/s, env_step=10000, len=29, loss/actor=-86.222, loss/critic=10.677, n/ep=0, n/st=1, rew=1.43]\n",
      "Epoch #2: test_reward: -184.382687 ± 350.737387, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.24it/s, env_step=15000, len=73, loss/actor=-127.662, loss/critic=15.061, n/ep=0, n/st=1, rew=34.82]\n",
      "Epoch #3: test_reward: -177.522402 ± 284.636388, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.47it/s, env_step=20000, len=114, loss/actor=-159.121, loss/critic=18.435, n/ep=0, n/st=1, rew=-17.87]\n",
      "Epoch #4: test_reward: -114.637428 ± 192.710456, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.74it/s, env_step=25000, len=20, loss/actor=-189.208, loss/critic=28.184, n/ep=0, n/st=1, rew=17.01]\n",
      "Epoch #5: test_reward: -28.860764 ± 72.057593, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.69s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1471.33 step/s',\n",
      " 'test_step': 23629,\n",
      " 'test_time': '16.06s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '115.40 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.76s',\n",
      " 'train_time/model': '177.88s'}\n",
      "Final reward: -346.8954082251401, length: 346.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:13:39.395533: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.83it/s, env_step=5000, len=62, loss/actor=-33.924, loss/critic=7.233, n/ep=0, n/st=1, rew=-34.93]\n",
      "Epoch #1: test_reward: -324.437561 ± 465.972030, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.82it/s, env_step=10000, len=1000, loss/actor=-89.161, loss/critic=10.822, n/ep=0, n/st=1, rew=-801.30]\n",
      "Epoch #2: test_reward: -16.407123 ± 21.249393, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.36it/s, env_step=15000, len=1000, loss/actor=-135.132, loss/critic=15.953, n/ep=0, n/st=1, rew=-916.63]\n",
      "Epoch #3: test_reward: -213.707579 ± 329.450077, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.01it/s, env_step=20000, len=40, loss/actor=-167.752, loss/critic=21.345, n/ep=0, n/st=1, rew=-33.60]\n",
      "Epoch #4: test_reward: -153.234408 ± 248.670441, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.67it/s, env_step=25000, len=166, loss/actor=-194.085, loss/critic=40.683, n/ep=0, n/st=1, rew=-103.42]\n",
      "Epoch #5: test_reward: -221.325878 ± 306.303767, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.32s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1690.80 step/s',\n",
      " 'test_step': 26539,\n",
      " 'test_time': '15.70s',\n",
      " 'train_episode': 91,\n",
      " 'train_speed': '112.81 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.86s',\n",
      " 'train_time/model': '182.76s'}\n",
      "Final reward: -371.6678471335582, length: 547.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:18:06.343729: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.80it/s, env_step=5000, len=1000, loss/actor=-31.297, loss/critic=4.291, n/ep=0, n/st=1, rew=-597.34]\n",
      "Epoch #1: test_reward: -82.035511 ± 268.963823, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.15it/s, env_step=10000, len=56, loss/actor=-74.868, loss/critic=7.686, n/ep=0, n/st=1, rew=0.07]\n",
      "Epoch #2: test_reward: -211.642636 ± 312.793011, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.43it/s, env_step=15000, len=27, loss/actor=-109.343, loss/critic=12.753, n/ep=0, n/st=1, rew=-1.14]\n",
      "Epoch #3: test_reward: -84.204721 ± 246.319458, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 108.88it/s, env_step=20000, len=60, loss/actor=-136.063, loss/critic=20.922, n/ep=0, n/st=1, rew=-52.99]\n",
      "Epoch #4: test_reward: -52.570089 ± 88.754821, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.39it/s, env_step=25000, len=33, loss/actor=-159.877, loss/critic=25.707, n/ep=0, n/st=1, rew=-15.62]\n",
      "Epoch #5: test_reward: -99.009261 ± 207.614460, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.98s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1424.30 step/s',\n",
      " 'test_step': 19544,\n",
      " 'test_time': '13.72s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '110.98 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.23s',\n",
      " 'train_time/model': '186.02s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -256.6645889006482, length: 344.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:22:34.175811: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.38it/s, env_step=5000, len=68, loss/actor=-32.996, loss/critic=5.713, n/ep=0, n/st=1, rew=10.93]\n",
      "Epoch #1: test_reward: -234.796567 ± 492.914355, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.20it/s, env_step=10000, len=15, loss/actor=-81.045, loss/critic=9.336, n/ep=0, n/st=1, rew=9.23]\n",
      "Epoch #2: test_reward: -309.923590 ± 354.949051, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.88it/s, env_step=15000, len=49, loss/actor=-121.364, loss/critic=15.279, n/ep=0, n/st=1, rew=25.81]\n",
      "Epoch #3: test_reward: -90.790837 ± 203.470898, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.14it/s, env_step=20000, len=52, loss/actor=-158.116, loss/critic=24.914, n/ep=0, n/st=1, rew=0.77]\n",
      "Epoch #4: test_reward: -200.352859 ± 428.399328, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.98it/s, env_step=25000, len=156, loss/actor=-190.772, loss/critic=31.736, n/ep=0, n/st=1, rew=-41.97]\n",
      "Epoch #5: test_reward: -91.075742 ± 165.332087, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.85s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1498.79 step/s',\n",
      " 'test_step': 24495,\n",
      " 'test_time': '16.34s',\n",
      " 'train_episode': 95,\n",
      " 'train_speed': '113.38 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.86s',\n",
      " 'train_time/model': '181.64s'}\n",
      "Final reward: -119.05979044231076, length: 229.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:26:59.959331: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.89it/s, env_step=5000, len=278, loss/actor=-33.516, loss/critic=5.659, n/ep=0, n/st=1, rew=234.68]\n",
      "Epoch #1: test_reward: 253.803205 ± 278.362014, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.18it/s, env_step=10000, len=48, loss/actor=-81.798, loss/critic=10.829, n/ep=0, n/st=1, rew=-13.71]\n",
      "Epoch #2: test_reward: 13.418143 ± 101.514325, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.74it/s, env_step=15000, len=133, loss/actor=-121.210, loss/critic=19.079, n/ep=0, n/st=1, rew=-46.96]\n",
      "Epoch #3: test_reward: -256.561723 ± 510.435901, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.97it/s, env_step=20000, len=67, loss/actor=-144.358, loss/critic=16.870, n/ep=0, n/st=1, rew=-15.76]\n",
      "Epoch #4: test_reward: -335.306450 ± 398.809593, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.08it/s, env_step=25000, len=13, loss/actor=-164.348, loss/critic=21.482, n/ep=0, n/st=1, rew=-15.13]\n",
      "Epoch #5: test_reward: -158.118945 ± 261.677048, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.41s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1606.40 step/s',\n",
      " 'test_step': 27555,\n",
      " 'test_time': '17.15s',\n",
      " 'train_episode': 76,\n",
      " 'train_speed': '112.48 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.23s',\n",
      " 'train_time/model': '183.03s'}\n",
      "Final reward: -306.370554292408, length: 439.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:31:28.826791: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.19it/s, env_step=5000, len=65, loss/actor=-35.515, loss/critic=6.660, n/ep=0, n/st=1, rew=44.37]\n",
      "Epoch #1: test_reward: -270.961848 ± 583.646423, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.68it/s, env_step=10000, len=23, loss/actor=-83.441, loss/critic=10.854, n/ep=0, n/st=1, rew=12.96]\n",
      "Epoch #2: test_reward: -331.530344 ± 489.221921, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.18it/s, env_step=15000, len=9, loss/actor=-126.122, loss/critic=22.067, n/ep=0, n/st=1, rew=1.99]\n",
      "Epoch #3: test_reward: -150.886513 ± 289.316919, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.62it/s, env_step=20000, len=83, loss/actor=-168.802, loss/critic=29.474, n/ep=0, n/st=1, rew=-59.81]\n",
      "Epoch #4: test_reward: -267.897849 ± 371.296069, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.80it/s, env_step=25000, len=1000, loss/actor=-205.608, loss/critic=47.514, n/ep=0, n/st=1, rew=-1027.36]\n",
      "Epoch #5: test_reward: -132.977170 ± 330.820563, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1449.18 step/s',\n",
      " 'test_step': 22941,\n",
      " 'test_time': '15.83s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '114.39 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.21s',\n",
      " 'train_time/model': '179.34s'}\n",
      "Final reward: -340.1662602337973, length: 341.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:35:52.199317: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.47it/s, env_step=5000, len=182, loss/actor=-33.447, loss/critic=5.223, n/ep=0, n/st=1, rew=113.78]\n",
      "Epoch #1: test_reward: -221.372567 ± 651.100175, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.09it/s, env_step=10000, len=40, loss/actor=-80.235, loss/critic=9.167, n/ep=0, n/st=1, rew=8.42]\n",
      "Epoch #2: test_reward: -128.723734 ± 279.010666, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.05it/s, env_step=15000, len=56, loss/actor=-123.570, loss/critic=16.333, n/ep=0, n/st=1, rew=20.38]\n",
      "Epoch #3: test_reward: -236.882107 ± 382.457696, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.49it/s, env_step=20000, len=61, loss/actor=-158.487, loss/critic=18.796, n/ep=0, n/st=1, rew=-38.11]\n",
      "Epoch #4: test_reward: -227.116632 ± 329.976280, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.28it/s, env_step=25000, len=72, loss/actor=-184.999, loss/critic=29.815, n/ep=0, n/st=1, rew=-49.59]\n",
      "Epoch #5: test_reward: -250.454781 ± 343.608704, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.36s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1483.62 step/s',\n",
      " 'test_step': 24246,\n",
      " 'test_time': '16.34s',\n",
      " 'train_episode': 72,\n",
      " 'train_speed': '112.60 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.20s',\n",
      " 'train_time/model': '182.81s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -162.73324577077938, length: 239.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:40:19.296142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.45it/s, env_step=5000, len=24, loss/actor=-34.717, loss/critic=6.243, n/ep=0, n/st=1, rew=5.76]\n",
      "Epoch #1: test_reward: -119.625702 ± 415.827458, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.57it/s, env_step=10000, len=56, loss/actor=-86.238, loss/critic=13.666, n/ep=0, n/st=1, rew=-35.90]\n",
      "Epoch #2: test_reward: -301.710691 ± 427.000264, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.62it/s, env_step=15000, len=11, loss/actor=-136.222, loss/critic=29.059, n/ep=0, n/st=1, rew=1.88]\n",
      "Epoch #3: test_reward: -144.941078 ± 317.888115, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.76it/s, env_step=20000, len=146, loss/actor=-178.903, loss/critic=34.803, n/ep=0, n/st=1, rew=-47.15]\n",
      "Epoch #4: test_reward: -239.149162 ± 442.136995, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.66it/s, env_step=25000, len=26, loss/actor=-223.164, loss/critic=47.636, n/ep=0, n/st=1, rew=-4.59]\n",
      "Epoch #5: test_reward: -500.424092 ± 727.232280, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.81s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1439.23 step/s',\n",
      " 'test_step': 23010,\n",
      " 'test_time': '15.99s',\n",
      " 'train_episode': 124,\n",
      " 'train_speed': '113.73 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.91s',\n",
      " 'train_time/model': '180.91s'}\n",
      "Final reward: -12.843785063162064, length: 40.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:44:41.793140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 119.96it/s, env_step=5000, len=72, loss/actor=-31.197, loss/critic=4.949, n/ep=0, n/st=1, rew=25.57]\n",
      "Epoch #1: test_reward: -372.846618 ± 465.094035, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.59it/s, env_step=10000, len=65, loss/actor=-75.778, loss/critic=8.446, n/ep=0, n/st=1, rew=10.97]\n",
      "Epoch #2: test_reward: 7.717354 ± 21.443712, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.54it/s, env_step=15000, len=29, loss/actor=-115.176, loss/critic=17.456, n/ep=0, n/st=1, rew=-7.69]\n",
      "Epoch #3: test_reward: -12.246778 ± 36.980933, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.79it/s, env_step=20000, len=1000, loss/actor=-149.197, loss/critic=22.342, n/ep=0, n/st=1, rew=-561.64]\n",
      "Epoch #4: test_reward: -143.493977 ± 219.974508, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.02it/s, env_step=25000, len=28, loss/actor=-182.599, loss/critic=33.000, n/ep=0, n/st=1, rew=-9.91]\n",
      "Epoch #5: test_reward: -572.738776 ± 699.223330, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.91s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1730.77 step/s',\n",
      " 'test_step': 24183,\n",
      " 'test_time': '13.97s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '115.24 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.40s',\n",
      " 'train_time/model': '178.54s'}\n",
      "Final reward: -184.1932041623116, length: 252.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:49:01.480268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.61it/s, env_step=5000, len=41, loss/actor=-32.513, loss/critic=4.554, n/ep=0, n/st=1, rew=42.19]\n",
      "Epoch #1: test_reward: -240.461786 ± 506.252979, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.41it/s, env_step=10000, len=1000, loss/actor=-72.286, loss/critic=6.382, n/ep=0, n/st=1, rew=-498.20]\n",
      "Epoch #2: test_reward: -51.568617 ± 141.904413, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.99it/s, env_step=15000, len=1000, loss/actor=-109.612, loss/critic=10.433, n/ep=0, n/st=1, rew=-494.24]\n",
      "Epoch #3: test_reward: -62.058513 ± 137.561937, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 111.05it/s, env_step=20000, len=88, loss/actor=-143.267, loss/critic=21.766, n/ep=0, n/st=1, rew=-46.56]\n",
      "Epoch #4: test_reward: -177.060918 ± 240.762817, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 111.02it/s, env_step=25000, len=230, loss/actor=-172.646, loss/critic=34.029, n/ep=0, n/st=1, rew=-148.54]\n",
      "Epoch #5: test_reward: -361.922937 ± 540.330594, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.47s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1474.61 step/s',\n",
      " 'test_step': 23811,\n",
      " 'test_time': '16.15s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '111.95 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '184.06s'}\n",
      "Final reward: -192.17333266464328, length: 168.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:53:29.577347: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.56it/s, env_step=5000, len=370, loss/actor=-29.446, loss/critic=3.835, n/ep=0, n/st=1, rew=239.58]\n",
      "Epoch #1: test_reward: -149.545883 ± 254.185074, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.98it/s, env_step=10000, len=292, loss/actor=-72.186, loss/critic=9.094, n/ep=0, n/st=1, rew=6.04]\n",
      "Epoch #2: test_reward: -247.210523 ± 376.404283, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.10it/s, env_step=15000, len=63, loss/actor=-109.221, loss/critic=11.911, n/ep=0, n/st=1, rew=-17.36]\n",
      "Epoch #3: test_reward: -199.906386 ± 270.797427, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.68it/s, env_step=20000, len=1000, loss/actor=-141.455, loss/critic=19.606, n/ep=0, n/st=1, rew=-479.15]\n",
      "Epoch #4: test_reward: -143.785354 ± 234.692623, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.35it/s, env_step=25000, len=65, loss/actor=-171.607, loss/critic=36.381, n/ep=0, n/st=1, rew=-38.86]\n",
      "Epoch #5: test_reward: -296.820791 ± 441.513438, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.32s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1524.38 step/s',\n",
      " 'test_step': 26215,\n",
      " 'test_time': '17.20s',\n",
      " 'train_episode': 106,\n",
      " 'train_speed': '113.06 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.29s',\n",
      " 'train_time/model': '181.83s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -50.075539688375706, length: 82.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 03:57:55.082378: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.81it/s, env_step=5000, len=57, loss/actor=-31.120, loss/critic=4.520, n/ep=0, n/st=1, rew=30.51]\n",
      "Epoch #1: test_reward: -308.738450 ± 576.666377, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:41, 120.25it/s, env_step=10000, len=29, loss/actor=-72.651, loss/critic=7.057, n/ep=0, n/st=1, rew=-2.31]\n",
      "Epoch #2: test_reward: -103.618741 ± 283.386747, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.09it/s, env_step=15000, len=29, loss/actor=-106.679, loss/critic=10.929, n/ep=0, n/st=1, rew=15.72]\n",
      "Epoch #3: test_reward: -107.723645 ± 254.023774, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.76it/s, env_step=20000, len=115, loss/actor=-134.490, loss/critic=15.863, n/ep=0, n/st=1, rew=-18.95]\n",
      "Epoch #4: test_reward: -117.050705 ± 236.988237, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:47, 105.82it/s, env_step=25000, len=112, loss/actor=-153.641, loss/critic=14.428, n/ep=0, n/st=1, rew=-1.05]\n",
      "Epoch #5: test_reward: 8.176726 ± 19.640820, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.88s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1501.37 step/s',\n",
      " 'test_step': 20951,\n",
      " 'test_time': '13.95s',\n",
      " 'train_episode': 124,\n",
      " 'train_speed': '111.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.46s',\n",
      " 'train_time/model': '184.47s'}\n",
      "Final reward: -64.41634234644665, length: 242.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:02:21.848029: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 107.49it/s, env_step=5000, len=69, loss/actor=-33.510, loss/critic=5.200, n/ep=0, n/st=1, rew=-6.70]\n",
      "Epoch #1: test_reward: -96.434183 ± 192.324452, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.33it/s, env_step=10000, len=19, loss/actor=-76.699, loss/critic=9.917, n/ep=0, n/st=1, rew=-8.55]\n",
      "Epoch #2: test_reward: -129.220150 ± 274.365174, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.42it/s, env_step=15000, len=17, loss/actor=-115.008, loss/critic=21.202, n/ep=0, n/st=1, rew=2.55]\n",
      "Epoch #3: test_reward: -35.197914 ± 105.269192, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.15it/s, env_step=20000, len=233, loss/actor=-150.504, loss/critic=26.221, n/ep=0, n/st=1, rew=-96.07]\n",
      "Epoch #4: test_reward: -283.832287 ± 375.109661, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 116.02it/s, env_step=25000, len=24, loss/actor=-187.245, loss/critic=39.702, n/ep=0, n/st=1, rew=-33.88]\n",
      "Epoch #5: test_reward: -457.895705 ± 559.827729, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.79s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1553.56 step/s',\n",
      " 'test_step': 24014,\n",
      " 'test_time': '15.46s',\n",
      " 'train_episode': 131,\n",
      " 'train_speed': '111.94 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.59s',\n",
      " 'train_time/model': '183.74s'}\n",
      "Final reward: -309.75771832863666, length: 349.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:06:49.727498: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.44it/s, env_step=5000, len=32, loss/actor=-31.526, loss/critic=4.195, n/ep=0, n/st=1, rew=17.26]\n",
      "Epoch #1: test_reward: -375.831047 ± 545.279965, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.60it/s, env_step=10000, len=100, loss/actor=-71.363, loss/critic=7.317, n/ep=0, n/st=1, rew=20.98]\n",
      "Epoch #2: test_reward: -8.404157 ± 27.217777, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.48it/s, env_step=15000, len=119, loss/actor=-107.399, loss/critic=12.309, n/ep=0, n/st=1, rew=-148.79]\n",
      "Epoch #3: test_reward: -152.701874 ± 291.440780, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.73it/s, env_step=20000, len=42, loss/actor=-139.035, loss/critic=14.553, n/ep=0, n/st=1, rew=18.42]\n",
      "Epoch #4: test_reward: -188.328001 ± 313.965114, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 119.54it/s, env_step=25000, len=69, loss/actor=-167.806, loss/critic=21.946, n/ep=0, n/st=1, rew=4.89]\n",
      "Epoch #5: test_reward: -329.965803 ± 338.350839, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.09s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1711.67 step/s',\n",
      " 'test_step': 27259,\n",
      " 'test_time': '15.93s',\n",
      " 'train_episode': 110,\n",
      " 'train_speed': '117.28 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.22s',\n",
      " 'train_time/model': '174.94s'}\n",
      "Final reward: -267.5825376670873, length: 434.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:11:08.155116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.26it/s, env_step=5000, len=15, loss/actor=-35.078, loss/critic=6.171, n/ep=0, n/st=1, rew=0.82]\n",
      "Epoch #1: test_reward: -274.104631 ± 466.828772, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.77it/s, env_step=10000, len=30, loss/actor=-96.145, loss/critic=15.827, n/ep=0, n/st=1, rew=5.44]\n",
      "Epoch #2: test_reward: -42.155465 ± 112.607141, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.65it/s, env_step=15000, len=1000, loss/actor=-150.185, loss/critic=22.341, n/ep=0, n/st=1, rew=-902.98]\n",
      "Epoch #3: test_reward: -236.573733 ± 342.242353, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.99it/s, env_step=20000, len=663, loss/actor=-199.869, loss/critic=33.536, n/ep=0, n/st=1, rew=-589.69]\n",
      "Epoch #4: test_reward: -186.530645 ± 347.004575, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.21it/s, env_step=25000, len=19, loss/actor=-238.913, loss/critic=44.299, n/ep=0, n/st=1, rew=-1.56]\n",
      "Epoch #5: test_reward: -521.508259 ± 497.724579, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.48s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1651.80 step/s',\n",
      " 'test_step': 26174,\n",
      " 'test_time': '15.85s',\n",
      " 'train_episode': 77,\n",
      " 'train_speed': '111.29 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.37s',\n",
      " 'train_time/model': '185.27s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -239.84426299514598, length: 277.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:15:37.561226: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.55it/s, env_step=5000, len=1000, loss/actor=-32.593, loss/critic=4.946, n/ep=0, n/st=1, rew=-605.70]\n",
      "Epoch #1: test_reward: -228.235127 ± 469.668639, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.67it/s, env_step=10000, len=64, loss/actor=-82.542, loss/critic=10.357, n/ep=0, n/st=1, rew=5.89]\n",
      "Epoch #2: test_reward: -332.438107 ± 403.276371, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.01it/s, env_step=15000, len=18, loss/actor=-123.322, loss/critic=20.795, n/ep=0, n/st=1, rew=1.52]\n",
      "Epoch #3: test_reward: -363.474983 ± 439.763058, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.52it/s, env_step=20000, len=718, loss/actor=-155.028, loss/critic=21.239, n/ep=0, n/st=1, rew=-552.39]\n",
      "Epoch #4: test_reward: -24.647221 ± 24.697056, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.23it/s, env_step=25000, len=1000, loss/actor=-185.323, loss/critic=28.371, n/ep=0, n/st=1, rew=-820.86]\n",
      "Epoch #5: test_reward: -246.243988 ± 419.989014, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.04s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1636.58 step/s',\n",
      " 'test_step': 24954,\n",
      " 'test_time': '15.25s',\n",
      " 'train_episode': 74,\n",
      " 'train_speed': '111.71 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.39s',\n",
      " 'train_time/model': '184.40s'}\n",
      "Final reward: -232.3160524841334, length: 309.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:20:05.500717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.10it/s, env_step=5000, len=74, loss/actor=-30.088, loss/critic=3.546, n/ep=0, n/st=1, rew=41.33]\n",
      "Epoch #1: test_reward: -108.070992 ± 327.938650, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.57it/s, env_step=10000, len=15, loss/actor=-73.733, loss/critic=6.198, n/ep=0, n/st=1, rew=-0.31]\n",
      "Epoch #2: test_reward: -158.803568 ± 337.242072, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.30it/s, env_step=15000, len=43, loss/actor=-108.210, loss/critic=10.655, n/ep=0, n/st=1, rew=-18.57]\n",
      "Epoch #3: test_reward: -354.953655 ± 544.871460, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.38it/s, env_step=20000, len=65, loss/actor=-143.221, loss/critic=19.307, n/ep=0, n/st=1, rew=-25.67]\n",
      "Epoch #4: test_reward: -238.336331 ± 339.924333, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.97it/s, env_step=25000, len=30, loss/actor=-174.628, loss/critic=33.224, n/ep=0, n/st=1, rew=-22.71]\n",
      "Epoch #5: test_reward: -128.616931 ± 237.003734, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.90s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1542.20 step/s',\n",
      " 'test_step': 25484,\n",
      " 'test_time': '16.52s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '113.96 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.06s',\n",
      " 'train_time/model': '180.32s'}\n",
      "Final reward: -176.0334682095525, length: 245.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:24:30.015950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.36it/s, env_step=5000, len=1000, loss/actor=-29.953, loss/critic=4.499, n/ep=0, n/st=1, rew=296.23]\n",
      "Epoch #1: test_reward: -96.355010 ± 486.050225, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.33it/s, env_step=10000, len=10, loss/actor=-72.091, loss/critic=7.582, n/ep=0, n/st=1, rew=-1.86]\n",
      "Epoch #2: test_reward: -97.663617 ± 247.727366, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.60it/s, env_step=15000, len=46, loss/actor=-106.427, loss/critic=13.033, n/ep=0, n/st=1, rew=-15.15]\n",
      "Epoch #3: test_reward: -319.484360 ± 393.353940, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.05it/s, env_step=20000, len=1000, loss/actor=-134.390, loss/critic=18.215, n/ep=0, n/st=1, rew=-770.51]\n",
      "Epoch #4: test_reward: -192.178927 ± 323.320669, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.64it/s, env_step=25000, len=24, loss/actor=-159.504, loss/critic=26.331, n/ep=0, n/st=1, rew=-19.33]\n",
      "Epoch #5: test_reward: -304.287065 ± 411.496141, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.24s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1493.32 step/s',\n",
      " 'test_step': 24196,\n",
      " 'test_time': '16.20s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '113.10 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.24s',\n",
      " 'train_time/model': '181.80s'}\n",
      "Final reward: -118.53408739666145, length: 144.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:28:54.967715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.45it/s, env_step=5000, len=77, loss/actor=-34.961, loss/critic=6.402, n/ep=0, n/st=1, rew=24.73]\n",
      "Epoch #1: test_reward: -31.456228 ± 64.105998, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.22it/s, env_step=10000, len=17, loss/actor=-95.795, loss/critic=18.820, n/ep=0, n/st=1, rew=-3.25]\n",
      "Epoch #2: test_reward: -211.167949 ± 441.743295, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.61it/s, env_step=15000, len=16, loss/actor=-163.960, loss/critic=27.678, n/ep=0, n/st=1, rew=-9.87]\n",
      "Epoch #3: test_reward: -119.072015 ± 286.040577, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.00it/s, env_step=20000, len=47, loss/actor=-224.746, loss/critic=64.907, n/ep=0, n/st=1, rew=-44.92]\n",
      "Epoch #4: test_reward: -253.584330 ± 429.894815, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.82it/s, env_step=25000, len=1000, loss/actor=-279.898, loss/critic=88.854, n/ep=0, n/st=1, rew=-1122.93]\n",
      "Epoch #5: test_reward: -160.153250 ± 357.371425, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.07s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1401.58 step/s',\n",
      " 'test_step': 18536,\n",
      " 'test_time': '13.23s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '113.72 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.67s',\n",
      " 'train_time/model': '181.17s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -33.51265433104718, length: 68.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:33:15.052049: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.21it/s, env_step=5000, len=1000, loss/actor=-31.589, loss/critic=4.209, n/ep=0, n/st=1, rew=-298.91]\n",
      "Epoch #1: test_reward: -109.752369 ± 214.219854, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.08it/s, env_step=10000, len=20, loss/actor=-70.907, loss/critic=7.448, n/ep=0, n/st=1, rew=-7.69]\n",
      "Epoch #2: test_reward: -16.120398 ± 60.927998, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.30it/s, env_step=15000, len=67, loss/actor=-102.487, loss/critic=9.727, n/ep=0, n/st=1, rew=2.34]\n",
      "Epoch #3: test_reward: 46.628917 ± 178.195494, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.16it/s, env_step=20000, len=21, loss/actor=-127.813, loss/critic=17.361, n/ep=0, n/st=1, rew=-18.39]\n",
      "Epoch #4: test_reward: -6.543583 ± 28.575536, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.42it/s, env_step=25000, len=69, loss/actor=-155.446, loss/critic=21.163, n/ep=0, n/st=1, rew=29.37]\n",
      "Epoch #5: test_reward: -82.640022 ± 134.300922, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.55s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1283.54 step/s',\n",
      " 'test_step': 19192,\n",
      " 'test_time': '14.95s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '113.33 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.17s',\n",
      " 'train_time/model': '181.43s'}\n",
      "Final reward: -31.74905936497684, length: 238.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:37:39.307804: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 108.52it/s, env_step=5000, len=1000, loss/actor=-33.726, loss/critic=5.848, n/ep=0, n/st=1, rew=-482.86]\n",
      "Epoch #1: test_reward: -279.811246 ± 304.902456, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.81it/s, env_step=10000, len=1000, loss/actor=-98.414, loss/critic=18.472, n/ep=0, n/st=1, rew=-1106.53]\n",
      "Epoch #2: test_reward: -253.073020 ± 448.603671, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.77it/s, env_step=15000, len=181, loss/actor=-181.616, loss/critic=61.532, n/ep=0, n/st=1, rew=-60.19]\n",
      "Epoch #3: test_reward: -149.027593 ± 327.012677, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.55it/s, env_step=20000, len=74, loss/actor=-254.184, loss/critic=70.328, n/ep=0, n/st=1, rew=-33.43]\n",
      "Epoch #4: test_reward: -251.183254 ± 420.688558, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.44it/s, env_step=25000, len=421, loss/actor=-327.107, loss/critic=131.683, n/ep=0, n/st=1, rew=-205.43]\n",
      "Epoch #5: test_reward: -460.462588 ± 551.720541, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.73s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1613.87 step/s',\n",
      " 'test_step': 26792,\n",
      " 'test_time': '16.60s',\n",
      " 'train_episode': 76,\n",
      " 'train_speed': '113.06 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.17s',\n",
      " 'train_time/model': '181.96s'}\n",
      "Final reward: -451.3460580001729, length: 418.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:42:06.222653: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.52it/s, env_step=5000, len=316, loss/actor=-29.549, loss/critic=3.452, n/ep=0, n/st=1, rew=107.98]\n",
      "Epoch #1: test_reward: 15.266327 ± 219.607281, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 108.90it/s, env_step=10000, len=1000, loss/actor=-67.531, loss/critic=6.338, n/ep=0, n/st=1, rew=-509.45]\n",
      "Epoch #2: test_reward: -15.682162 ± 18.489026, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.91it/s, env_step=15000, len=47, loss/actor=-103.138, loss/critic=10.070, n/ep=0, n/st=1, rew=14.11]\n",
      "Epoch #3: test_reward: -39.098142 ± 173.996521, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.48it/s, env_step=20000, len=27, loss/actor=-131.871, loss/critic=15.252, n/ep=0, n/st=1, rew=-4.82]\n",
      "Epoch #4: test_reward: -148.481024 ± 303.912260, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.90it/s, env_step=25000, len=63, loss/actor=-151.516, loss/critic=16.596, n/ep=0, n/st=1, rew=7.46]\n",
      "Epoch #5: test_reward: -391.898539 ± 334.386533, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '242.56s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1618.16 step/s',\n",
      " 'test_step': 25026,\n",
      " 'test_time': '15.47s',\n",
      " 'train_episode': 75,\n",
      " 'train_speed': '110.09 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.78s',\n",
      " 'train_time/model': '187.31s'}\n",
      "Final reward: -61.684254677184775, length: 188.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:46:37.358573: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.67it/s, env_step=5000, len=38, loss/actor=-31.225, loss/critic=4.740, n/ep=0, n/st=1, rew=-15.66]\n",
      "Epoch #1: test_reward: -144.328426 ± 395.770331, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.84it/s, env_step=10000, len=18, loss/actor=-72.838, loss/critic=7.723, n/ep=0, n/st=1, rew=8.07]\n",
      "Epoch #2: test_reward: -18.508165 ± 51.033563, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.10it/s, env_step=15000, len=24, loss/actor=-109.294, loss/critic=10.518, n/ep=0, n/st=1, rew=12.75]\n",
      "Epoch #3: test_reward: -47.678396 ± 153.247151, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.56it/s, env_step=20000, len=100, loss/actor=-139.177, loss/critic=21.202, n/ep=0, n/st=1, rew=-2.76]\n",
      "Epoch #4: test_reward: -226.497836 ± 326.714604, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 108.73it/s, env_step=25000, len=61, loss/actor=-161.957, loss/critic=20.503, n/ep=0, n/st=1, rew=-58.72]\n",
      "Epoch #5: test_reward: -344.011054 ± 361.616728, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.97s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1523.62 step/s',\n",
      " 'test_step': 21933,\n",
      " 'test_time': '14.40s',\n",
      " 'train_episode': 103,\n",
      " 'train_speed': '111.82 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.49s',\n",
      " 'train_time/model': '184.09s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -154.79327935748734, length: 249.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:51:04.055928: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 119.15it/s, env_step=5000, len=1000, loss/actor=-37.065, loss/critic=8.641, n/ep=0, n/st=1, rew=-778.46]\n",
      "Epoch #1: test_reward: -241.493430 ± 431.714197, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.90it/s, env_step=10000, len=97, loss/actor=-115.216, loss/critic=23.659, n/ep=0, n/st=1, rew=-40.34]\n",
      "Epoch #2: test_reward: -140.079320 ± 391.515563, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.02it/s, env_step=15000, len=25, loss/actor=-177.526, loss/critic=32.036, n/ep=0, n/st=1, rew=-17.08]\n",
      "Epoch #3: test_reward: -118.851454 ± 281.720447, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.50it/s, env_step=20000, len=1000, loss/actor=-219.986, loss/critic=36.341, n/ep=0, n/st=1, rew=-905.28]\n",
      "Epoch #4: test_reward: -113.512079 ± 216.596908, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.73it/s, env_step=25000, len=25, loss/actor=-257.050, loss/critic=50.274, n/ep=0, n/st=1, rew=-15.63]\n",
      "Epoch #5: test_reward: -352.473459 ± 495.687079, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.63s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1449.64 step/s',\n",
      " 'test_step': 22510,\n",
      " 'test_time': '15.53s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '115.15 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.71s',\n",
      " 'train_time/model': '178.39s'}\n",
      "Final reward: -132.11451712771094, length: 156.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:55:25.335913: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.71it/s, env_step=5000, len=1000, loss/actor=-31.982, loss/critic=4.426, n/ep=0, n/st=1, rew=-799.78]\n",
      "Epoch #1: test_reward: 5.864921 ± 19.856222, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.02it/s, env_step=10000, len=40, loss/actor=-78.740, loss/critic=9.276, n/ep=0, n/st=1, rew=-11.63]\n",
      "Epoch #2: test_reward: -271.711533 ± 419.506667, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.82it/s, env_step=15000, len=72, loss/actor=-117.218, loss/critic=14.731, n/ep=0, n/st=1, rew=-46.09]\n",
      "Epoch #3: test_reward: -5.093180 ± 14.874050, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.20it/s, env_step=20000, len=35, loss/actor=-148.994, loss/critic=24.452, n/ep=0, n/st=1, rew=21.52]\n",
      "Epoch #4: test_reward: -142.038771 ± 229.172365, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.77it/s, env_step=25000, len=35, loss/actor=-178.592, loss/critic=34.928, n/ep=0, n/st=1, rew=-20.88]\n",
      "Epoch #5: test_reward: -82.865777 ± 213.520591, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.80s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1567.97 step/s',\n",
      " 'test_step': 19137,\n",
      " 'test_time': '12.20s',\n",
      " 'train_episode': 72,\n",
      " 'train_speed': '112.82 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.00s',\n",
      " 'train_time/model': '182.60s'}\n",
      "Final reward: -193.1032139314897, length: 241.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 04:59:48.022473: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.46it/s, env_step=5000, len=60, loss/actor=-32.745, loss/critic=6.099, n/ep=0, n/st=1, rew=-1.53]\n",
      "Epoch #1: test_reward: -406.162900 ± 673.403705, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.86it/s, env_step=10000, len=863, loss/actor=-84.742, loss/critic=10.237, n/ep=0, n/st=1, rew=-1047.32]\n",
      "Epoch #2: test_reward: -257.238825 ± 509.376969, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 108.76it/s, env_step=15000, len=176, loss/actor=-125.601, loss/critic=18.671, n/ep=0, n/st=1, rew=1.24]\n",
      "Epoch #3: test_reward: -281.659107 ± 419.658921, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.90it/s, env_step=20000, len=1000, loss/actor=-158.391, loss/critic=22.264, n/ep=0, n/st=1, rew=-738.26]\n",
      "Epoch #4: test_reward: -16.100572 ± 20.200911, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.25it/s, env_step=25000, len=77, loss/actor=-188.093, loss/critic=22.176, n/ep=0, n/st=1, rew=-89.70]\n",
      "Epoch #5: test_reward: -20.690093 ± 26.815859, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.28s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1622.82 step/s',\n",
      " 'test_step': 20630,\n",
      " 'test_time': '12.71s',\n",
      " 'train_episode': 111,\n",
      " 'train_speed': '112.32 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.50s',\n",
      " 'train_time/model': '183.07s'}\n",
      "Final reward: -83.41755281476631, length: 127.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:04:11.750623: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.63it/s, env_step=5000, len=80, loss/actor=-32.247, loss/critic=4.570, n/ep=0, n/st=1, rew=65.10]\n",
      "Epoch #1: test_reward: -628.932941 ± 1103.580701, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.72it/s, env_step=10000, len=1000, loss/actor=-81.405, loss/critic=7.725, n/ep=0, n/st=1, rew=-657.73]\n",
      "Epoch #2: test_reward: -53.410049 ± 165.214903, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.36it/s, env_step=15000, len=81, loss/actor=-124.802, loss/critic=17.623, n/ep=0, n/st=1, rew=-48.22]\n",
      "Epoch #3: test_reward: -165.260744 ± 310.048594, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.43it/s, env_step=20000, len=186, loss/actor=-152.054, loss/critic=16.043, n/ep=0, n/st=1, rew=-132.05]\n",
      "Epoch #4: test_reward: -81.538774 ± 151.232567, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 119.35it/s, env_step=25000, len=10, loss/actor=-176.404, loss/critic=29.167, n/ep=0, n/st=1, rew=-23.87]\n",
      "Epoch #5: test_reward: -77.586719 ± 152.455612, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.83s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1565.95 step/s',\n",
      " 'test_step': 26086,\n",
      " 'test_time': '16.66s',\n",
      " 'train_episode': 73,\n",
      " 'train_speed': '113.55 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.76s',\n",
      " 'train_time/model': '181.41s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -251.45661092526015, length: 570.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:08:38.531652: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.18it/s, env_step=5000, len=65, loss/actor=-35.879, loss/critic=6.050, n/ep=0, n/st=1, rew=45.87]\n",
      "Epoch #1: test_reward: 23.817338 ± 57.799376, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.57it/s, env_step=10000, len=1000, loss/actor=-84.298, loss/critic=8.315, n/ep=0, n/st=1, rew=-927.38]\n",
      "Epoch #2: test_reward: -140.218315 ± 270.968472, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.64it/s, env_step=15000, len=24, loss/actor=-127.371, loss/critic=20.494, n/ep=0, n/st=1, rew=1.59]\n",
      "Epoch #3: test_reward: -228.299542 ± 293.166702, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.58it/s, env_step=20000, len=1000, loss/actor=-161.278, loss/critic=20.652, n/ep=0, n/st=1, rew=-845.35]\n",
      "Epoch #4: test_reward: -227.061334 ± 324.904986, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.65it/s, env_step=25000, len=40, loss/actor=-204.868, loss/critic=41.857, n/ep=0, n/st=1, rew=-38.70]\n",
      "Epoch #5: test_reward: -127.702727 ± 281.828434, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.54s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1555.79 step/s',\n",
      " 'test_step': 22662,\n",
      " 'test_time': '14.57s',\n",
      " 'train_episode': 67,\n",
      " 'train_speed': '113.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.32s',\n",
      " 'train_time/model': '180.66s'}\n",
      "Final reward: -50.79972103925671, length: 63.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:13:00.415535: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.40it/s, env_step=5000, len=24, loss/actor=-29.719, loss/critic=3.925, n/ep=0, n/st=1, rew=12.46]\n",
      "Epoch #1: test_reward: -140.903273 ± 284.710807, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.59it/s, env_step=10000, len=148, loss/actor=-70.143, loss/critic=7.117, n/ep=0, n/st=1, rew=-35.11]\n",
      "Epoch #2: test_reward: -126.401014 ± 266.039502, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.13it/s, env_step=15000, len=33, loss/actor=-106.802, loss/critic=13.521, n/ep=0, n/st=1, rew=-30.50]\n",
      "Epoch #3: test_reward: -16.159086 ± 21.170782, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.01it/s, env_step=20000, len=67, loss/actor=-134.780, loss/critic=17.972, n/ep=0, n/st=1, rew=-47.84]\n",
      "Epoch #4: test_reward: -74.512314 ± 148.421343, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.81it/s, env_step=25000, len=154, loss/actor=-163.630, loss/critic=23.875, n/ep=0, n/st=1, rew=-197.54]\n",
      "Epoch #5: test_reward: -118.075058 ± 244.985910, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.84s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1416.30 step/s',\n",
      " 'test_step': 18465,\n",
      " 'test_time': '13.04s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '112.71 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.08s',\n",
      " 'train_time/model': '182.72s'}\n",
      "Final reward: -101.57009792997901, length: 126.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:17:23.706767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.22it/s, env_step=5000, len=1000, loss/actor=-30.416, loss/critic=3.844, n/ep=0, n/st=1, rew=79.03]\n",
      "Epoch #1: test_reward: -160.769426 ± 279.796801, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.75it/s, env_step=10000, len=80, loss/actor=-78.339, loss/critic=9.180, n/ep=0, n/st=1, rew=16.43]\n",
      "Epoch #2: test_reward: -225.622928 ± 363.413407, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.59it/s, env_step=15000, len=33, loss/actor=-120.979, loss/critic=15.118, n/ep=0, n/st=1, rew=-5.19]\n",
      "Epoch #3: test_reward: -14.635715 ± 37.807157, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.50it/s, env_step=20000, len=1000, loss/actor=-156.602, loss/critic=25.579, n/ep=0, n/st=1, rew=-808.29]\n",
      "Epoch #4: test_reward: -338.371155 ± 394.975458, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 107.18it/s, env_step=25000, len=64, loss/actor=-186.790, loss/critic=26.773, n/ep=0, n/st=1, rew=-71.45]\n",
      "Epoch #5: test_reward: -446.237966 ± 687.013536, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.35s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1629.10 step/s',\n",
      " 'test_step': 25144,\n",
      " 'test_time': '15.43s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '111.15 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '185.66s'}\n",
      "Final reward: -15.868022487536646, length: 48.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:21:50.819952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.44it/s, env_step=5000, len=400, loss/actor=-36.289, loss/critic=6.700, n/ep=0, n/st=1, rew=155.45]\n",
      "Epoch #1: test_reward: -127.908849 ± 352.551405, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.75it/s, env_step=10000, len=303, loss/actor=-92.825, loss/critic=11.744, n/ep=0, n/st=1, rew=-118.27]\n",
      "Epoch #2: test_reward: -3.253343 ± 23.776697, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.18it/s, env_step=15000, len=32, loss/actor=-142.792, loss/critic=24.528, n/ep=0, n/st=1, rew=-25.25]\n",
      "Epoch #3: test_reward: -122.357999 ± 244.557601, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.85it/s, env_step=20000, len=13, loss/actor=-179.236, loss/critic=24.110, n/ep=0, n/st=1, rew=-7.26]\n",
      "Epoch #4: test_reward: -229.118981 ± 342.235053, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.53it/s, env_step=25000, len=1000, loss/actor=-204.460, loss/critic=29.187, n/ep=0, n/st=1, rew=-759.08]\n",
      "Epoch #5: test_reward: -121.246837 ± 260.842434, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.40s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1419.25 step/s',\n",
      " 'test_step': 18296,\n",
      " 'test_time': '12.89s',\n",
      " 'train_episode': 80,\n",
      " 'train_speed': '112.86 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.78s',\n",
      " 'train_time/model': '182.73s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -172.0697767299438, length: 229.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:26:13.713046: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.37it/s, env_step=5000, len=37, loss/actor=-31.080, loss/critic=4.486, n/ep=0, n/st=1, rew=11.69]\n",
      "Epoch #1: test_reward: -183.211993 ± 314.741327, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.12it/s, env_step=10000, len=19, loss/actor=-79.405, loss/critic=8.080, n/ep=0, n/st=1, rew=2.27]\n",
      "Epoch #2: test_reward: -62.650581 ± 229.065600, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.13it/s, env_step=15000, len=11, loss/actor=-126.268, loss/critic=17.489, n/ep=0, n/st=1, rew=-4.35]\n",
      "Epoch #3: test_reward: -143.048072 ± 265.764112, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.50it/s, env_step=20000, len=12, loss/actor=-168.587, loss/critic=31.821, n/ep=0, n/st=1, rew=-2.64]\n",
      "Epoch #4: test_reward: -168.421517 ± 347.813401, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.17it/s, env_step=25000, len=22, loss/actor=-202.996, loss/critic=40.424, n/ep=0, n/st=1, rew=-18.53]\n",
      "Epoch #5: test_reward: -209.095509 ± 381.835938, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.95s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1500.15 step/s',\n",
      " 'test_step': 23591,\n",
      " 'test_time': '15.73s',\n",
      " 'train_episode': 97,\n",
      " 'train_speed': '114.56 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.70s',\n",
      " 'train_time/model': '179.52s'}\n",
      "Final reward: -196.4655461320866, length: 245.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:30:36.455549: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.06it/s, env_step=5000, len=59, loss/actor=-30.164, loss/critic=4.355, n/ep=0, n/st=1, rew=32.34]\n",
      "Epoch #1: test_reward: -41.384910 ± 167.284259, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.44it/s, env_step=10000, len=37, loss/actor=-78.955, loss/critic=9.450, n/ep=0, n/st=1, rew=4.91]\n",
      "Epoch #2: test_reward: -214.060323 ± 399.213519, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 116.27it/s, env_step=15000, len=15, loss/actor=-123.610, loss/critic=16.974, n/ep=0, n/st=1, rew=5.33]\n",
      "Epoch #3: test_reward: -187.309727 ± 276.763640, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.04it/s, env_step=20000, len=45, loss/actor=-158.429, loss/critic=28.427, n/ep=0, n/st=1, rew=-19.14]\n",
      "Epoch #4: test_reward: -253.736114 ± 543.170796, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.87it/s, env_step=25000, len=16, loss/actor=-193.389, loss/critic=31.446, n/ep=0, n/st=1, rew=-23.89]\n",
      "Epoch #5: test_reward: -244.891993 ± 295.774204, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.57s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1550.36 step/s',\n",
      " 'test_step': 26558,\n",
      " 'test_time': '17.13s',\n",
      " 'train_episode': 112,\n",
      " 'train_speed': '113.41 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.18s',\n",
      " 'train_time/model': '181.26s'}\n",
      "Final reward: -3.043748374921054, length: 59.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:35:01.072388: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.90it/s, env_step=5000, len=271, loss/actor=-33.896, loss/critic=5.944, n/ep=0, n/st=1, rew=35.11]\n",
      "Epoch #1: test_reward: -152.978912 ± 447.785759, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 108.93it/s, env_step=10000, len=94, loss/actor=-85.028, loss/critic=13.411, n/ep=0, n/st=1, rew=-7.63]\n",
      "Epoch #2: test_reward: -154.904467 ± 296.803275, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.12it/s, env_step=15000, len=11, loss/actor=-133.865, loss/critic=18.237, n/ep=0, n/st=1, rew=-15.24]\n",
      "Epoch #3: test_reward: -142.147797 ± 288.580370, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.24it/s, env_step=20000, len=88, loss/actor=-179.666, loss/critic=45.831, n/ep=0, n/st=1, rew=-39.08]\n",
      "Epoch #4: test_reward: -263.054704 ± 370.203710, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.19it/s, env_step=25000, len=141, loss/actor=-215.554, loss/critic=56.041, n/ep=0, n/st=1, rew=-58.70]\n",
      "Epoch #5: test_reward: -118.498818 ± 305.917281, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.69s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1464.28 step/s',\n",
      " 'test_step': 22851,\n",
      " 'test_time': '15.61s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '112.57 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.99s',\n",
      " 'train_time/model': '183.09s'}\n",
      "Final reward: -154.0237979492136, length: 164.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:39:27.413875: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.59it/s, env_step=5000, len=1000, loss/actor=-34.066, loss/critic=4.878, n/ep=0, n/st=1, rew=-115.71]\n",
      "Epoch #1: test_reward: -302.906086 ± 346.556616, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.34it/s, env_step=10000, len=224, loss/actor=-79.801, loss/critic=9.944, n/ep=0, n/st=1, rew=-138.14]\n",
      "Epoch #2: test_reward: -13.107012 ± 21.352131, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.25it/s, env_step=15000, len=1000, loss/actor=-123.237, loss/critic=15.226, n/ep=0, n/st=1, rew=-849.84]\n",
      "Epoch #3: test_reward: -141.208128 ± 247.834546, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.72it/s, env_step=20000, len=1000, loss/actor=-169.389, loss/critic=30.066, n/ep=0, n/st=1, rew=-891.16]\n",
      "Epoch #4: test_reward: -112.729411 ± 295.061351, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 121.40it/s, env_step=25000, len=1000, loss/actor=-219.210, loss/critic=48.893, n/ep=0, n/st=1, rew=-995.06]\n",
      "Epoch #5: test_reward: -497.656554 ± 470.633453, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.05s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1642.70 step/s',\n",
      " 'test_step': 25716,\n",
      " 'test_time': '15.65s',\n",
      " 'train_episode': 73,\n",
      " 'train_speed': '117.16 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.28s',\n",
      " 'train_time/model': '175.11s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -301.7261248773434, length: 326.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:43:45.628199: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 108.10it/s, env_step=5000, len=1000, loss/actor=-37.863, loss/critic=6.340, n/ep=0, n/st=1, rew=-496.41]\n",
      "Epoch #1: test_reward: -331.615902 ± 499.932981, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.47it/s, env_step=10000, len=75, loss/actor=-99.223, loss/critic=19.904, n/ep=0, n/st=1, rew=32.03]\n",
      "Epoch #2: test_reward: -18.788540 ± 63.419633, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.89it/s, env_step=15000, len=165, loss/actor=-145.868, loss/critic=22.586, n/ep=0, n/st=1, rew=-32.73]\n",
      "Epoch #3: test_reward: -205.169377 ± 376.038460, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.58it/s, env_step=20000, len=243, loss/actor=-181.709, loss/critic=31.667, n/ep=0, n/st=1, rew=-81.89]\n",
      "Epoch #4: test_reward: -125.110433 ± 262.613087, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:40, 122.16it/s, env_step=25000, len=27, loss/actor=-215.185, loss/critic=34.554, n/ep=0, n/st=1, rew=-14.09]\n",
      "Epoch #5: test_reward: -200.774535 ± 354.753639, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.30s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1546.74 step/s',\n",
      " 'test_step': 22060,\n",
      " 'test_time': '14.26s',\n",
      " 'train_episode': 105,\n",
      " 'train_speed': '115.18 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.58s',\n",
      " 'train_time/model': '178.46s'}\n",
      "Final reward: -216.59790937164135, length: 262.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:48:05.474744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 106.54it/s, env_step=5000, len=70, loss/actor=-31.840, loss/critic=5.551, n/ep=0, n/st=1, rew=32.99]\n",
      "Epoch #1: test_reward: -119.939705 ± 396.989272, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.98it/s, env_step=10000, len=60, loss/actor=-78.989, loss/critic=8.536, n/ep=0, n/st=1, rew=-0.93]\n",
      "Epoch #2: test_reward: -371.487655 ± 471.703214, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.18it/s, env_step=15000, len=64, loss/actor=-119.166, loss/critic=13.240, n/ep=0, n/st=1, rew=22.84]\n",
      "Epoch #3: test_reward: -3.167366 ± 13.695256, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.63it/s, env_step=20000, len=74, loss/actor=-154.440, loss/critic=20.869, n/ep=0, n/st=1, rew=-28.24]\n",
      "Epoch #4: test_reward: -356.585120 ± 371.813354, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 121.65it/s, env_step=25000, len=31, loss/actor=-183.472, loss/critic=26.826, n/ep=0, n/st=1, rew=-22.31]\n",
      "Epoch #5: test_reward: -271.304855 ± 376.701178, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.45s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1675.49 step/s',\n",
      " 'test_step': 25788,\n",
      " 'test_time': '15.39s',\n",
      " 'train_episode': 100,\n",
      " 'train_speed': '114.12 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.03s',\n",
      " 'train_time/model': '180.04s'}\n",
      "Final reward: -108.97720871837552, length: 150.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:52:28.448682: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.91it/s, env_step=5000, len=42, loss/actor=-36.804, loss/critic=6.534, n/ep=0, n/st=1, rew=33.27]\n",
      "Epoch #1: test_reward: -421.355094 ± 698.223945, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.42it/s, env_step=10000, len=1000, loss/actor=-98.344, loss/critic=13.539, n/ep=0, n/st=1, rew=-796.03]\n",
      "Epoch #2: test_reward: -213.217894 ± 402.817404, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.35it/s, env_step=15000, len=140, loss/actor=-153.796, loss/critic=23.506, n/ep=0, n/st=1, rew=-67.49]\n",
      "Epoch #3: test_reward: -322.867515 ± 392.362822, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.42it/s, env_step=20000, len=1000, loss/actor=-194.432, loss/critic=34.160, n/ep=0, n/st=1, rew=-652.19]\n",
      "Epoch #4: test_reward: -152.216457 ± 269.933131, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.57it/s, env_step=25000, len=315, loss/actor=-222.271, loss/critic=44.287, n/ep=0, n/st=1, rew=-177.19]\n",
      "Epoch #5: test_reward: -402.702521 ± 371.611383, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.46s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1593.90 step/s',\n",
      " 'test_step': 27851,\n",
      " 'test_time': '17.47s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '113.64 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.22s',\n",
      " 'train_time/model': '180.77s'}\n",
      "Final reward: -106.30364939572515, length: 159.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 05:56:54.497530: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.34it/s, env_step=5000, len=1000, loss/actor=-33.039, loss/critic=4.852, n/ep=0, n/st=1, rew=-553.81]\n",
      "Epoch #1: test_reward: -321.264392 ± 310.084489, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.62it/s, env_step=10000, len=254, loss/actor=-84.414, loss/critic=10.411, n/ep=0, n/st=1, rew=127.35]\n",
      "Epoch #2: test_reward: -268.011800 ± 422.820591, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.25it/s, env_step=15000, len=1000, loss/actor=-117.116, loss/critic=12.512, n/ep=0, n/st=1, rew=-625.28]\n",
      "Epoch #3: test_reward: -16.148729 ± 30.125140, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.48it/s, env_step=20000, len=24, loss/actor=-143.614, loss/critic=15.824, n/ep=0, n/st=1, rew=-17.26]\n",
      "Epoch #4: test_reward: -115.858107 ± 213.802813, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 120.16it/s, env_step=25000, len=60, loss/actor=-166.080, loss/critic=22.837, n/ep=0, n/st=1, rew=-9.28]\n",
      "Epoch #5: test_reward: -3.262815 ± 23.495954, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.65s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1738.15 step/s',\n",
      " 'test_step': 23624,\n",
      " 'test_time': '13.59s',\n",
      " 'train_episode': 75,\n",
      " 'train_speed': '113.61 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.17s',\n",
      " 'train_time/model': '180.89s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -122.74660020265, length: 276.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:01:17.023720: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.69it/s, env_step=5000, len=185, loss/actor=-34.783, loss/critic=5.378, n/ep=0, n/st=1, rew=137.17]\n",
      "Epoch #1: test_reward: -185.613825 ± 391.883122, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.83it/s, env_step=10000, len=93, loss/actor=-81.503, loss/critic=9.065, n/ep=0, n/st=1, rew=-8.53]\n",
      "Epoch #2: test_reward: -227.443722 ± 343.787999, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.50it/s, env_step=15000, len=74, loss/actor=-122.080, loss/critic=14.188, n/ep=0, n/st=1, rew=42.62]\n",
      "Epoch #3: test_reward: -78.462868 ± 172.622762, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.02it/s, env_step=20000, len=1000, loss/actor=-155.005, loss/critic=16.523, n/ep=0, n/st=1, rew=-804.15]\n",
      "Epoch #4: test_reward: -80.875324 ± 205.650173, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.43it/s, env_step=25000, len=150, loss/actor=-179.603, loss/critic=22.529, n/ep=0, n/st=1, rew=-28.11]\n",
      "Epoch #5: test_reward: -174.859125 ± 246.416895, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.94s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1448.26 step/s',\n",
      " 'test_step': 23260,\n",
      " 'test_time': '16.06s',\n",
      " 'train_episode': 67,\n",
      " 'train_speed': '115.81 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.80s',\n",
      " 'train_time/model': '177.08s'}\n",
      "Final reward: -239.35632340307262, length: 436.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_014958-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:05:38.516506: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.49it/s, env_step=5000, len=19, loss/actor=-31.923, loss/critic=4.062, n/ep=0, n/st=1, rew=16.01]\n",
      "Epoch #1: test_reward: -197.561556 ± 544.518637, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.55it/s, env_step=10000, len=44, loss/actor=-73.299, loss/critic=8.041, n/ep=0, n/st=1, rew=-4.41]\n",
      "Epoch #2: test_reward: -193.147829 ± 378.615127, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.52it/s, env_step=15000, len=36, loss/actor=-110.329, loss/critic=13.658, n/ep=0, n/st=1, rew=-4.88]\n",
      "Epoch #3: test_reward: -84.787022 ± 247.814774, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.83it/s, env_step=20000, len=35, loss/actor=-141.613, loss/critic=16.343, n/ep=0, n/st=1, rew=-24.11]\n",
      "Epoch #4: test_reward: -305.374778 ± 355.270277, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.35it/s, env_step=25000, len=46, loss/actor=-169.785, loss/critic=25.639, n/ep=0, n/st=1, rew=-27.69]\n",
      "Epoch #5: test_reward: -112.753259 ± 231.000169, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.10s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1452.59 step/s',\n",
      " 'test_step': 23034,\n",
      " 'test_time': '15.86s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '112.49 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.36s',\n",
      " 'train_time/model': '182.88s'}\n",
      "Final reward: -333.1575086815839, length: 425.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_060538-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:10:06.003650: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.43it/s, env_step=5000, len=26, loss/actor=-32.153, loss/critic=5.238, n/ep=0, n/st=1, rew=6.05]\n",
      "Epoch #1: test_reward: -9.179233 ± 283.834511, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.02it/s, env_step=10000, len=53, loss/actor=-89.616, loss/critic=11.399, n/ep=0, n/st=1, rew=-45.80]\n",
      "Epoch #2: test_reward: -85.199300 ± 255.223252, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.11it/s, env_step=15000, len=107, loss/actor=-141.968, loss/critic=22.999, n/ep=0, n/st=1, rew=-75.30]\n",
      "Epoch #3: test_reward: -341.129575 ± 406.225379, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:46, 108.29it/s, env_step=20000, len=34, loss/actor=-179.242, loss/critic=34.314, n/ep=0, n/st=1, rew=-21.17]\n",
      "Epoch #4: test_reward: -186.229362 ± 328.655501, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.70it/s, env_step=25000, len=1000, loss/actor=-206.782, loss/critic=29.190, n/ep=0, n/st=1, rew=-724.88]\n",
      "Epoch #5: test_reward: -51.411248 ± 58.502133, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.68s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1574.44 step/s',\n",
      " 'test_step': 23972,\n",
      " 'test_time': '15.23s',\n",
      " 'train_episode': 92,\n",
      " 'train_speed': '112.38 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '183.20s'}\n",
      "Final reward: -101.29281574613074, length: 131.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:14:32.390412: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.28it/s, env_step=5000, len=82, loss/actor=-36.611, loss/critic=6.665, n/ep=0, n/st=1, rew=22.91]\n",
      "Epoch #1: test_reward: -163.689327 ± 529.075438, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.37it/s, env_step=10000, len=65, loss/actor=-90.227, loss/critic=12.130, n/ep=0, n/st=1, rew=-1.83]\n",
      "Epoch #2: test_reward: -243.381751 ± 483.053602, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.63it/s, env_step=15000, len=1000, loss/actor=-138.215, loss/critic=17.504, n/ep=0, n/st=1, rew=-735.66]\n",
      "Epoch #3: test_reward: -430.160929 ± 422.352092, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.06it/s, env_step=20000, len=163, loss/actor=-187.030, loss/critic=34.731, n/ep=0, n/st=1, rew=-27.40]\n",
      "Epoch #4: test_reward: -188.568795 ± 367.989118, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.52it/s, env_step=25000, len=29, loss/actor=-223.041, loss/critic=40.287, n/ep=0, n/st=1, rew=-11.45]\n",
      "Epoch #5: test_reward: -86.335421 ± 171.253813, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.86s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1534.54 step/s',\n",
      " 'test_step': 23028,\n",
      " 'test_time': '15.01s',\n",
      " 'train_episode': 113,\n",
      " 'train_speed': '112.69 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.60s',\n",
      " 'train_time/model': '182.25s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -325.5361237507779, length: 340.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:18:58.318036: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.55it/s, env_step=5000, len=123, loss/actor=-34.056, loss/critic=4.791, n/ep=0, n/st=1, rew=-66.65]\n",
      "Epoch #1: test_reward: -234.860232 ± 548.564595, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.46it/s, env_step=10000, len=314, loss/actor=-78.612, loss/critic=8.706, n/ep=0, n/st=1, rew=-24.70]\n",
      "Epoch #2: test_reward: 5.391900 ± 21.667538, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.27it/s, env_step=15000, len=22, loss/actor=-117.146, loss/critic=16.342, n/ep=0, n/st=1, rew=13.96]\n",
      "Epoch #3: test_reward: 7.786946 ± 14.560589, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.28it/s, env_step=20000, len=125, loss/actor=-147.231, loss/critic=20.655, n/ep=0, n/st=1, rew=-25.46]\n",
      "Epoch #4: test_reward: -113.071148 ± 288.973573, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.07it/s, env_step=25000, len=22, loss/actor=-176.221, loss/critic=34.506, n/ep=0, n/st=1, rew=-2.20]\n",
      "Epoch #5: test_reward: -198.073343 ± 292.486325, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.59s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1561.93 step/s',\n",
      " 'test_step': 19114,\n",
      " 'test_time': '12.24s',\n",
      " 'train_episode': 113,\n",
      " 'train_speed': '112.43 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.00s',\n",
      " 'train_time/model': '183.36s'}\n",
      "Final reward: -69.72830423369298, length: 135.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:23:21.376635: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.17it/s, env_step=5000, len=12, loss/actor=-31.658, loss/critic=4.854, n/ep=0, n/st=1, rew=-7.01]\n",
      "Epoch #1: test_reward: -114.139795 ± 281.756012, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 113.71it/s, env_step=10000, len=134, loss/actor=-81.794, loss/critic=12.895, n/ep=0, n/st=1, rew=3.10]\n",
      "Epoch #2: test_reward: -113.613365 ± 296.654514, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.57it/s, env_step=15000, len=31, loss/actor=-127.923, loss/critic=17.464, n/ep=0, n/st=1, rew=4.06]\n",
      "Epoch #3: test_reward: -210.276994 ± 389.414812, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 111.04it/s, env_step=20000, len=1000, loss/actor=-165.918, loss/critic=24.318, n/ep=0, n/st=1, rew=-869.32]\n",
      "Epoch #4: test_reward: -107.294895 ± 279.312812, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.33it/s, env_step=25000, len=345, loss/actor=-201.967, loss/critic=38.903, n/ep=0, n/st=1, rew=-175.49]\n",
      "Epoch #5: test_reward: -166.305058 ± 260.340748, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.94s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1496.18 step/s',\n",
      " 'test_step': 23768,\n",
      " 'test_time': '15.89s',\n",
      " 'train_episode': 66,\n",
      " 'train_speed': '112.08 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.16s',\n",
      " 'train_time/model': '183.90s'}\n",
      "Final reward: -22.733958759307235, length: 52.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:27:47.143753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.21it/s, env_step=5000, len=1000, loss/actor=-30.905, loss/critic=4.342, n/ep=0, n/st=1, rew=-661.07]\n",
      "Epoch #1: test_reward: -54.431272 ± 240.681927, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.15it/s, env_step=10000, len=129, loss/actor=-79.983, loss/critic=9.973, n/ep=0, n/st=1, rew=12.07]\n",
      "Epoch #2: test_reward: -207.665150 ± 393.773754, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.07it/s, env_step=15000, len=163, loss/actor=-128.828, loss/critic=18.279, n/ep=0, n/st=1, rew=-41.24]\n",
      "Epoch #3: test_reward: -171.523336 ± 328.226241, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.15it/s, env_step=20000, len=114, loss/actor=-168.244, loss/critic=25.343, n/ep=0, n/st=1, rew=-78.64]\n",
      "Epoch #4: test_reward: -489.762772 ± 387.788692, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.21it/s, env_step=25000, len=74, loss/actor=-196.963, loss/critic=30.841, n/ep=0, n/st=1, rew=-42.42]\n",
      "Epoch #5: test_reward: -159.860802 ± 308.818046, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1538.52 step/s',\n",
      " 'test_step': 24811,\n",
      " 'test_time': '16.13s',\n",
      " 'train_episode': 92,\n",
      " 'train_speed': '113.23 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.86s',\n",
      " 'train_time/model': '181.93s'}\n",
      "Final reward: -125.5887681512468, length: 222.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:32:12.841786: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.35it/s, env_step=5000, len=49, loss/actor=-27.398, loss/critic=3.150, n/ep=0, n/st=1, rew=15.11]\n",
      "Epoch #1: test_reward: -135.939215 ± 390.513318, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.40it/s, env_step=10000, len=81, loss/actor=-62.061, loss/critic=5.689, n/ep=0, n/st=1, rew=56.14]\n",
      "Epoch #2: test_reward: -33.748623 ± 165.220692, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.31it/s, env_step=15000, len=20, loss/actor=-91.419, loss/critic=8.970, n/ep=0, n/st=1, rew=3.21]\n",
      "Epoch #3: test_reward: -89.601614 ± 212.748674, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.40it/s, env_step=20000, len=43, loss/actor=-117.923, loss/critic=19.051, n/ep=0, n/st=1, rew=-16.67]\n",
      "Epoch #4: test_reward: -69.421008 ± 162.593169, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.35it/s, env_step=25000, len=51, loss/actor=-143.944, loss/critic=19.288, n/ep=0, n/st=1, rew=-26.61]\n",
      "Epoch #5: test_reward: -222.560654 ± 301.387908, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.56s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1360.16 step/s',\n",
      " 'test_step': 20827,\n",
      " 'test_time': '15.31s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '111.49 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.47s',\n",
      " 'train_time/model': '184.78s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -156.8523260995961, length: 237.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:36:41.115213: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.42it/s, env_step=5000, len=64, loss/actor=-31.885, loss/critic=4.520, n/ep=0, n/st=1, rew=48.75]\n",
      "Epoch #1: test_reward: -121.573445 ± 536.713278, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 116.28it/s, env_step=10000, len=21, loss/actor=-70.327, loss/critic=6.567, n/ep=0, n/st=1, rew=-7.01]\n",
      "Epoch #2: test_reward: -98.300017 ± 261.285750, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.50it/s, env_step=15000, len=48, loss/actor=-99.728, loss/critic=9.188, n/ep=0, n/st=1, rew=-0.90]\n",
      "Epoch #3: test_reward: -72.108245 ± 186.407749, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.29it/s, env_step=20000, len=84, loss/actor=-123.771, loss/critic=11.682, n/ep=0, n/st=1, rew=-14.94]\n",
      "Epoch #4: test_reward: -52.635262 ± 130.252819, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.77it/s, env_step=25000, len=73, loss/actor=-144.388, loss/critic=14.047, n/ep=0, n/st=1, rew=3.66]\n",
      "Epoch #5: test_reward: -51.842291 ± 66.211644, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.26s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1402.94 step/s',\n",
      " 'test_step': 21654,\n",
      " 'test_time': '15.43s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '114.77 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.46s',\n",
      " 'train_time/model': '179.36s'}\n",
      "Final reward: -35.29522969101405, length: 257.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:41:03.305052: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.30it/s, env_step=5000, len=1000, loss/actor=-31.761, loss/critic=3.771, n/ep=0, n/st=1, rew=-454.21]\n",
      "Epoch #1: test_reward: -103.438608 ± 361.397957, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.22it/s, env_step=10000, len=490, loss/actor=-71.209, loss/critic=7.470, n/ep=0, n/st=1, rew=-269.30]\n",
      "Epoch #2: test_reward: -181.897482 ± 502.309105, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.80it/s, env_step=15000, len=23, loss/actor=-106.597, loss/critic=11.490, n/ep=0, n/st=1, rew=4.96]\n",
      "Epoch #3: test_reward: -244.082179 ± 286.015786, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.02it/s, env_step=20000, len=44, loss/actor=-139.705, loss/critic=17.149, n/ep=0, n/st=1, rew=15.35]\n",
      "Epoch #4: test_reward: -322.319174 ± 499.970254, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.21it/s, env_step=25000, len=170, loss/actor=-167.479, loss/critic=23.487, n/ep=0, n/st=1, rew=-21.37]\n",
      "Epoch #5: test_reward: -177.564138 ± 305.341859, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.57s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1601.40 step/s',\n",
      " 'test_step': 29679,\n",
      " 'test_time': '18.53s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '113.62 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.22s',\n",
      " 'train_time/model': '180.82s'}\n",
      "Final reward: -43.144807625996535, length: 81.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:45:29.861382: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.28it/s, env_step=5000, len=18, loss/actor=-35.863, loss/critic=6.055, n/ep=0, n/st=1, rew=-1.31]\n",
      "Epoch #1: test_reward: 21.099390 ± 90.005150, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.16it/s, env_step=10000, len=21, loss/actor=-89.523, loss/critic=13.198, n/ep=0, n/st=1, rew=7.78]\n",
      "Epoch #2: test_reward: -210.615630 ± 447.819394, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.90it/s, env_step=15000, len=1000, loss/actor=-131.570, loss/critic=18.508, n/ep=0, n/st=1, rew=-678.47]\n",
      "Epoch #3: test_reward: -159.012858 ± 241.051348, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.44it/s, env_step=20000, len=110, loss/actor=-171.563, loss/critic=23.984, n/ep=0, n/st=1, rew=-66.35]\n",
      "Epoch #4: test_reward: -98.462193 ± 214.414330, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.34it/s, env_step=25000, len=78, loss/actor=-206.208, loss/critic=34.015, n/ep=0, n/st=1, rew=-25.16]\n",
      "Epoch #5: test_reward: -360.023603 ± 429.428467, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.25s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1458.97 step/s',\n",
      " 'test_step': 23727,\n",
      " 'test_time': '16.26s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '113.13 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.71s',\n",
      " 'train_time/model': '181.28s'}\n",
      "Final reward: -89.10529050796589, length: 246.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:49:56.079739: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.53it/s, env_step=5000, len=60, loss/actor=-33.348, loss/critic=6.177, n/ep=0, n/st=1, rew=-15.84]\n",
      "Epoch #1: test_reward: -144.159160 ± 137.479115, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.64it/s, env_step=10000, len=95, loss/actor=-86.685, loss/critic=12.664, n/ep=0, n/st=1, rew=31.60]\n",
      "Epoch #2: test_reward: -201.020772 ± 358.843699, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.72it/s, env_step=15000, len=24, loss/actor=-129.520, loss/critic=16.780, n/ep=0, n/st=1, rew=-0.01]\n",
      "Epoch #3: test_reward: -36.989914 ± 49.918818, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.51it/s, env_step=20000, len=377, loss/actor=-164.783, loss/critic=21.258, n/ep=0, n/st=1, rew=-145.23]\n",
      "Epoch #4: test_reward: -321.853415 ± 389.999792, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 120.76it/s, env_step=25000, len=1000, loss/actor=-191.154, loss/critic=27.571, n/ep=0, n/st=1, rew=-659.95]\n",
      "Epoch #5: test_reward: -314.388701 ± 367.839031, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.86s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1731.85 step/s',\n",
      " 'test_step': 28461,\n",
      " 'test_time': '16.43s',\n",
      " 'train_episode': 83,\n",
      " 'train_speed': '117.13 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.82s',\n",
      " 'train_time/model': '174.61s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -386.5936300635261, length: 455.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:54:15.697169: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.55it/s, env_step=5000, len=141, loss/actor=-29.195, loss/critic=3.468, n/ep=0, n/st=1, rew=11.94]\n",
      "Epoch #1: test_reward: -179.268625 ± 359.399418, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.77it/s, env_step=10000, len=111, loss/actor=-68.249, loss/critic=7.080, n/ep=0, n/st=1, rew=-1.48]\n",
      "Epoch #2: test_reward: -91.461851 ± 180.792113, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.24it/s, env_step=15000, len=40, loss/actor=-107.004, loss/critic=16.597, n/ep=0, n/st=1, rew=-9.15]\n",
      "Epoch #3: test_reward: -53.654857 ± 164.295989, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.78it/s, env_step=20000, len=71, loss/actor=-142.418, loss/critic=21.737, n/ep=0, n/st=1, rew=-74.01]\n",
      "Epoch #4: test_reward: -244.945960 ± 337.126675, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.94it/s, env_step=25000, len=24, loss/actor=-174.199, loss/critic=23.714, n/ep=0, n/st=1, rew=0.78]\n",
      "Epoch #5: test_reward: -252.075683 ± 336.625657, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.34s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1458.85 step/s',\n",
      " 'test_step': 23721,\n",
      " 'test_time': '16.26s',\n",
      " 'train_episode': 77,\n",
      " 'train_speed': '115.17 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.51s',\n",
      " 'train_time/model': '178.56s'}\n",
      "Final reward: -177.79254816159542, length: 228.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 06:58:37.542489: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.96it/s, env_step=5000, len=57, loss/actor=-31.101, loss/critic=4.407, n/ep=0, n/st=1, rew=19.08]\n",
      "Epoch #1: test_reward: 92.634349 ± 509.033626, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.24it/s, env_step=10000, len=1000, loss/actor=-78.463, loss/critic=7.895, n/ep=0, n/st=1, rew=-730.72]\n",
      "Epoch #2: test_reward: -167.046607 ± 258.565289, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.77it/s, env_step=15000, len=82, loss/actor=-119.934, loss/critic=16.001, n/ep=0, n/st=1, rew=40.24]\n",
      "Epoch #3: test_reward: -240.581470 ± 353.522006, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.54it/s, env_step=20000, len=313, loss/actor=-152.292, loss/critic=20.757, n/ep=0, n/st=1, rew=-19.82]\n",
      "Epoch #4: test_reward: -354.968834 ± 348.103060, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.17it/s, env_step=25000, len=25, loss/actor=-177.382, loss/critic=23.168, n/ep=0, n/st=1, rew=-6.76]\n",
      "Epoch #5: test_reward: -184.901046 ± 369.883993, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.37s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1751.36 step/s',\n",
      " 'test_step': 33057,\n",
      " 'test_time': '18.88s',\n",
      " 'train_episode': 86,\n",
      " 'train_speed': '113.38 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.08s',\n",
      " 'train_time/model': '181.42s'}\n",
      "Final reward: -86.95763178337228, length: 141.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_061005-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:03:05.436919: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:39, 125.34it/s, env_step=5000, len=48, loss/actor=-32.486, loss/critic=5.044, n/ep=0, n/st=1, rew=26.64]\n",
      "Epoch #1: test_reward: -99.593545 ± 423.597523, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.50it/s, env_step=10000, len=109, loss/actor=-81.407, loss/critic=9.558, n/ep=0, n/st=1, rew=-12.72]\n",
      "Epoch #2: test_reward: -74.578335 ± 226.686750, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.89it/s, env_step=15000, len=22, loss/actor=-123.794, loss/critic=16.753, n/ep=0, n/st=1, rew=-1.84]\n",
      "Epoch #3: test_reward: -78.641003 ± 208.368868, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.66it/s, env_step=20000, len=48, loss/actor=-162.074, loss/critic=24.393, n/ep=0, n/st=1, rew=-14.72]\n",
      "Epoch #4: test_reward: -166.706990 ± 299.897143, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.90it/s, env_step=25000, len=120, loss/actor=-195.753, loss/critic=39.957, n/ep=0, n/st=1, rew=18.38]\n",
      "Epoch #5: test_reward: -160.984498 ± 304.024269, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '228.94s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1344.95 step/s',\n",
      " 'test_step': 20579,\n",
      " 'test_time': '15.30s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '117.02 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.71s',\n",
      " 'train_time/model': '174.93s'}\n",
      "Final reward: -189.87317286000697, length: 257.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:07:23.435177: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 119.18it/s, env_step=5000, len=1000, loss/actor=-31.520, loss/critic=3.575, n/ep=0, n/st=1, rew=464.63]\n",
      "Epoch #1: test_reward: -189.839186 ± 441.992838, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 113.89it/s, env_step=10000, len=1000, loss/actor=-76.046, loss/critic=6.886, n/ep=0, n/st=1, rew=-630.80]\n",
      "Epoch #2: test_reward: -7.750418 ± 25.304467, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.13it/s, env_step=15000, len=121, loss/actor=-114.038, loss/critic=16.160, n/ep=0, n/st=1, rew=-34.81]\n",
      "Epoch #3: test_reward: -172.401345 ± 281.446009, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.84it/s, env_step=20000, len=86, loss/actor=-141.917, loss/critic=17.944, n/ep=0, n/st=1, rew=-7.75]\n",
      "Epoch #4: test_reward: -178.424946 ± 287.701662, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.13it/s, env_step=25000, len=1000, loss/actor=-164.830, loss/critic=17.718, n/ep=0, n/st=1, rew=-580.42]\n",
      "Epoch #5: test_reward: -27.365237 ± 47.599517, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.78s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1548.16 step/s',\n",
      " 'test_step': 19614,\n",
      " 'test_time': '12.67s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '112.05 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.60s',\n",
      " 'train_time/model': '183.51s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -198.82659460182427, length: 337.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:11:47.999114: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.39it/s, env_step=5000, len=24, loss/actor=-32.045, loss/critic=4.484, n/ep=0, n/st=1, rew=6.30]\n",
      "Epoch #1: test_reward: 30.883033 ± 160.933304, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.13it/s, env_step=10000, len=61, loss/actor=-75.397, loss/critic=8.074, n/ep=0, n/st=1, rew=39.50]\n",
      "Epoch #2: test_reward: -2.680304 ± 18.480851, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.73it/s, env_step=15000, len=28, loss/actor=-108.871, loss/critic=10.245, n/ep=0, n/st=1, rew=-10.92]\n",
      "Epoch #3: test_reward: -141.324082 ± 224.580167, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.29it/s, env_step=20000, len=38, loss/actor=-134.863, loss/critic=14.880, n/ep=0, n/st=1, rew=-21.14]\n",
      "Epoch #4: test_reward: -150.743187 ± 269.229055, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.71it/s, env_step=25000, len=1000, loss/actor=-157.505, loss/critic=16.822, n/ep=0, n/st=1, rew=-602.84]\n",
      "Epoch #5: test_reward: -233.546694 ± 329.812891, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.75s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1523.02 step/s',\n",
      " 'test_step': 21667,\n",
      " 'test_time': '14.23s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '113.37 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.78s',\n",
      " 'train_time/model': '181.74s'}\n",
      "Final reward: -105.66653636339746, length: 158.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:16:11.199233: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.35it/s, env_step=5000, len=71, loss/actor=-32.109, loss/critic=5.045, n/ep=0, n/st=1, rew=-71.68]\n",
      "Epoch #1: test_reward: -58.024889 ± 193.345537, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.87it/s, env_step=10000, len=9, loss/actor=-82.415, loss/critic=11.433, n/ep=0, n/st=1, rew=0.99]\n",
      "Epoch #2: test_reward: -124.907786 ± 326.344551, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.19it/s, env_step=15000, len=46, loss/actor=-131.422, loss/critic=23.419, n/ep=0, n/st=1, rew=-10.85]\n",
      "Epoch #3: test_reward: -18.664458 ± 33.332761, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.31it/s, env_step=20000, len=120, loss/actor=-168.746, loss/critic=25.978, n/ep=0, n/st=1, rew=-87.50]\n",
      "Epoch #4: test_reward: -247.840189 ± 408.458102, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.84it/s, env_step=25000, len=126, loss/actor=-202.853, loss/critic=42.038, n/ep=0, n/st=1, rew=-67.85]\n",
      "Epoch #5: test_reward: -234.971943 ± 337.717693, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.52s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1643.54 step/s',\n",
      " 'test_step': 26290,\n",
      " 'test_time': '16.00s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '111.35 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.43s',\n",
      " 'train_time/model': '185.09s'}\n",
      "Final reward: -253.41840338422554, length: 357.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:20:40.985598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.96it/s, env_step=5000, len=108, loss/actor=-33.618, loss/critic=4.650, n/ep=0, n/st=1, rew=66.62]\n",
      "Epoch #1: test_reward: -105.971010 ± 401.953409, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.04it/s, env_step=10000, len=45, loss/actor=-81.660, loss/critic=10.118, n/ep=0, n/st=1, rew=-1.69]\n",
      "Epoch #2: test_reward: -202.832474 ± 423.409305, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 108.83it/s, env_step=15000, len=84, loss/actor=-119.310, loss/critic=15.258, n/ep=0, n/st=1, rew=-29.04]\n",
      "Epoch #3: test_reward: -98.410572 ± 283.836105, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.35it/s, env_step=20000, len=145, loss/actor=-155.575, loss/critic=26.295, n/ep=0, n/st=1, rew=-104.92]\n",
      "Epoch #4: test_reward: -253.175936 ± 382.896985, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.02it/s, env_step=25000, len=12, loss/actor=-193.028, loss/critic=34.278, n/ep=0, n/st=1, rew=-17.93]\n",
      "Epoch #5: test_reward: -410.033880 ± 444.947612, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '241.52s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1473.66 step/s',\n",
      " 'test_step': 24506,\n",
      " 'test_time': '16.63s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '111.16 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.33s',\n",
      " 'train_time/model': '185.56s'}\n",
      "Final reward: -223.1819060559189, length: 249.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:25:11.430472: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.86it/s, env_step=5000, len=50, loss/actor=-33.108, loss/critic=4.065, n/ep=0, n/st=1, rew=18.61]\n",
      "Epoch #1: test_reward: -184.003983 ± 406.272542, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 113.71it/s, env_step=10000, len=50, loss/actor=-78.959, loss/critic=8.353, n/ep=0, n/st=1, rew=-1.75]\n",
      "Epoch #2: test_reward: -114.956782 ± 232.731526, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.38it/s, env_step=15000, len=39, loss/actor=-117.619, loss/critic=14.896, n/ep=0, n/st=1, rew=6.17]\n",
      "Epoch #3: test_reward: -185.752317 ± 265.173063, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.91it/s, env_step=20000, len=22, loss/actor=-145.019, loss/critic=16.677, n/ep=0, n/st=1, rew=-0.43]\n",
      "Epoch #4: test_reward: -229.765428 ± 263.965332, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.27it/s, env_step=25000, len=11, loss/actor=-172.620, loss/critic=36.595, n/ep=0, n/st=1, rew=-13.83]\n",
      "Epoch #5: test_reward: -65.153942 ± 79.701968, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.96s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1533.34 step/s',\n",
      " 'test_step': 23076,\n",
      " 'test_time': '15.05s',\n",
      " 'train_episode': 61,\n",
      " 'train_speed': '113.17 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.01s',\n",
      " 'train_time/model': '181.91s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -46.8052174344857, length: 85.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:29:34.952121: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.50it/s, env_step=5000, len=173, loss/actor=-33.169, loss/critic=4.198, n/ep=0, n/st=1, rew=21.98]\n",
      "Epoch #1: test_reward: -175.736516 ± 612.186732, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.28it/s, env_step=10000, len=131, loss/actor=-78.853, loss/critic=6.903, n/ep=0, n/st=1, rew=49.04]\n",
      "Epoch #2: test_reward: -138.992730 ± 275.960214, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.78it/s, env_step=15000, len=51, loss/actor=-118.819, loss/critic=12.524, n/ep=0, n/st=1, rew=-18.77]\n",
      "Epoch #3: test_reward: -9.745058 ± 17.119929, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.97it/s, env_step=20000, len=54, loss/actor=-153.249, loss/critic=23.981, n/ep=0, n/st=1, rew=-9.57]\n",
      "Epoch #4: test_reward: -168.550525 ± 356.319798, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.84it/s, env_step=25000, len=47, loss/actor=-184.761, loss/critic=36.562, n/ep=0, n/st=1, rew=-22.35]\n",
      "Epoch #5: test_reward: -387.313322 ± 437.915190, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.76s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1580.23 step/s',\n",
      " 'test_step': 22943,\n",
      " 'test_time': '14.52s',\n",
      " 'train_episode': 95,\n",
      " 'train_speed': '110.99 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.38s',\n",
      " 'train_time/model': '185.86s'}\n",
      "Final reward: -353.55043212131307, length: 439.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:34:03.917999: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.55it/s, env_step=5000, len=75, loss/actor=-31.194, loss/critic=4.603, n/ep=0, n/st=1, rew=-108.67]\n",
      "Epoch #1: test_reward: -189.888299 ± 532.763994, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.54it/s, env_step=10000, len=33, loss/actor=-67.631, loss/critic=6.460, n/ep=0, n/st=1, rew=8.86]\n",
      "Epoch #2: test_reward: -35.609270 ± 95.351851, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.85it/s, env_step=15000, len=22, loss/actor=-104.537, loss/critic=13.807, n/ep=0, n/st=1, rew=-23.65]\n",
      "Epoch #3: test_reward: -24.244156 ± 22.689792, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.06it/s, env_step=20000, len=125, loss/actor=-137.744, loss/critic=13.201, n/ep=0, n/st=1, rew=-63.73]\n",
      "Epoch #4: test_reward: -245.102128 ± 362.710233, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.95it/s, env_step=25000, len=21, loss/actor=-171.293, loss/critic=39.989, n/ep=0, n/st=1, rew=0.72]\n",
      "Epoch #5: test_reward: -451.179384 ± 504.290147, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.70s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1518.86 step/s',\n",
      " 'test_step': 22032,\n",
      " 'test_time': '14.51s',\n",
      " 'train_episode': 97,\n",
      " 'train_speed': '111.51 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.32s',\n",
      " 'train_time/model': '184.88s'}\n",
      "Final reward: -354.8951293707047, length: 353.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:38:31.804280: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.94it/s, env_step=5000, len=148, loss/actor=-35.937, loss/critic=5.845, n/ep=0, n/st=1, rew=70.71]\n",
      "Epoch #1: test_reward: -305.276628 ± 514.871769, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.64it/s, env_step=10000, len=16, loss/actor=-91.896, loss/critic=14.570, n/ep=0, n/st=1, rew=-10.66]\n",
      "Epoch #2: test_reward: -275.019238 ± 402.797747, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.58it/s, env_step=15000, len=19, loss/actor=-149.708, loss/critic=23.374, n/ep=0, n/st=1, rew=3.98]\n",
      "Epoch #3: test_reward: -204.501447 ± 359.747015, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.98it/s, env_step=20000, len=25, loss/actor=-197.432, loss/critic=39.333, n/ep=0, n/st=1, rew=-3.65]\n",
      "Epoch #4: test_reward: -293.806234 ± 432.983927, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.98it/s, env_step=25000, len=17, loss/actor=-238.726, loss/critic=43.666, n/ep=0, n/st=1, rew=-8.37]\n",
      "Epoch #5: test_reward: -198.216819 ± 351.078613, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.66s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1517.41 step/s',\n",
      " 'test_step': 24743,\n",
      " 'test_time': '16.31s',\n",
      " 'train_episode': 83,\n",
      " 'train_speed': '113.97 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.13s',\n",
      " 'train_time/model': '180.23s'}\n",
      "Final reward: -115.69580653970866, length: 139.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:42:56.033257: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.19it/s, env_step=5000, len=65, loss/actor=-30.999, loss/critic=4.098, n/ep=0, n/st=1, rew=35.14]\n",
      "Epoch #1: test_reward: -77.430642 ± 241.932129, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.89it/s, env_step=10000, len=25, loss/actor=-76.401, loss/critic=7.597, n/ep=0, n/st=1, rew=4.22]\n",
      "Epoch #2: test_reward: -162.050494 ± 265.517638, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.54it/s, env_step=15000, len=21, loss/actor=-114.557, loss/critic=13.832, n/ep=0, n/st=1, rew=-4.01]\n",
      "Epoch #3: test_reward: -120.046636 ± 179.206083, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.37it/s, env_step=20000, len=13, loss/actor=-149.831, loss/critic=33.163, n/ep=0, n/st=1, rew=-13.18]\n",
      "Epoch #4: test_reward: -49.932770 ± 67.268185, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 108.64it/s, env_step=25000, len=66, loss/actor=-179.277, loss/critic=35.428, n/ep=0, n/st=1, rew=22.42]\n",
      "Epoch #5: test_reward: -129.917457 ± 238.124651, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.59s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1473.78 step/s',\n",
      " 'test_step': 20874,\n",
      " 'test_time': '14.16s',\n",
      " 'train_episode': 68,\n",
      " 'train_speed': '112.40 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.22s',\n",
      " 'train_time/model': '183.20s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -285.3249957297281, length: 347.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:47:21.789884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.72it/s, env_step=5000, len=57, loss/actor=-33.120, loss/critic=4.667, n/ep=0, n/st=1, rew=-27.94]\n",
      "Epoch #1: test_reward: -223.791809 ± 336.887368, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.22it/s, env_step=10000, len=46, loss/actor=-78.973, loss/critic=9.190, n/ep=0, n/st=1, rew=20.38]\n",
      "Epoch #2: test_reward: -186.139392 ± 456.297005, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.36it/s, env_step=15000, len=1000, loss/actor=-117.231, loss/critic=13.753, n/ep=0, n/st=1, rew=-672.30]\n",
      "Epoch #3: test_reward: -83.281360 ± 199.840835, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.83it/s, env_step=20000, len=136, loss/actor=-152.953, loss/critic=24.499, n/ep=0, n/st=1, rew=-45.22]\n",
      "Epoch #4: test_reward: -23.912886 ± 22.637916, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.63it/s, env_step=25000, len=70, loss/actor=-184.305, loss/critic=33.744, n/ep=0, n/st=1, rew=-36.77]\n",
      "Epoch #5: test_reward: -341.604771 ± 405.164635, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1560.67 step/s',\n",
      " 'test_step': 23177,\n",
      " 'test_time': '14.85s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '111.07 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.56s',\n",
      " 'train_time/model': '185.52s'}\n",
      "Final reward: -284.16590880653337, length: 353.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:51:50.977532: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.31it/s, env_step=5000, len=15, loss/actor=-32.363, loss/critic=5.438, n/ep=0, n/st=1, rew=8.28]\n",
      "Epoch #1: test_reward: -35.665783 ± 112.169548, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.47it/s, env_step=10000, len=64, loss/actor=-87.193, loss/critic=13.933, n/ep=0, n/st=1, rew=13.40]\n",
      "Epoch #2: test_reward: -351.887727 ± 533.659894, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.30it/s, env_step=15000, len=162, loss/actor=-136.476, loss/critic=24.860, n/ep=0, n/st=1, rew=12.79]\n",
      "Epoch #3: test_reward: -224.699110 ± 420.314956, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.73it/s, env_step=20000, len=203, loss/actor=-176.775, loss/critic=30.567, n/ep=0, n/st=1, rew=-117.28]\n",
      "Epoch #4: test_reward: -47.555984 ± 51.412170, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.63it/s, env_step=25000, len=29, loss/actor=-211.876, loss/critic=42.656, n/ep=0, n/st=1, rew=-17.78]\n",
      "Epoch #5: test_reward: -435.022748 ± 526.008542, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.89s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1612.21 step/s',\n",
      " 'test_step': 24732,\n",
      " 'test_time': '15.34s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '114.39 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.61s',\n",
      " 'train_time/model': '179.94s'}\n",
      "Final reward: -168.59444673914223, length: 197.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 07:56:13.479724: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.51it/s, env_step=5000, len=41, loss/actor=-29.051, loss/critic=3.187, n/ep=0, n/st=1, rew=48.62]\n",
      "Epoch #1: test_reward: -21.294063 ± 109.293210, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.98it/s, env_step=10000, len=64, loss/actor=-69.671, loss/critic=7.177, n/ep=0, n/st=1, rew=21.16]\n",
      "Epoch #2: test_reward: -188.507777 ± 312.794276, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 108.90it/s, env_step=15000, len=1000, loss/actor=-101.431, loss/critic=10.146, n/ep=0, n/st=1, rew=-632.53]\n",
      "Epoch #3: test_reward: -47.111999 ± 148.934309, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.02it/s, env_step=20000, len=707, loss/actor=-134.752, loss/critic=14.835, n/ep=0, n/st=1, rew=-445.88]\n",
      "Epoch #4: test_reward: -196.062255 ± 271.561858, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.24it/s, env_step=25000, len=67, loss/actor=-166.632, loss/critic=22.478, n/ep=0, n/st=1, rew=27.05]\n",
      "Epoch #5: test_reward: -183.694656 ± 334.170989, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.79s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1433.46 step/s',\n",
      " 'test_step': 22700,\n",
      " 'test_time': '15.84s',\n",
      " 'train_episode': 91,\n",
      " 'train_speed': '111.63 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.60s',\n",
      " 'train_time/model': '184.35s'}\n",
      "Final reward: -163.38728004805722, length: 239.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:00:41.916994: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.22it/s, env_step=5000, len=29, loss/actor=-33.049, loss/critic=4.884, n/ep=0, n/st=1, rew=24.96]\n",
      "Epoch #1: test_reward: 84.335548 ± 228.531237, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.53it/s, env_step=10000, len=87, loss/actor=-76.850, loss/critic=13.138, n/ep=0, n/st=1, rew=3.13]\n",
      "Epoch #2: test_reward: 8.197040 ± 13.029376, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.31it/s, env_step=15000, len=35, loss/actor=-109.567, loss/critic=12.647, n/ep=0, n/st=1, rew=-3.54]\n",
      "Epoch #3: test_reward: -119.776969 ± 207.246845, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.23it/s, env_step=20000, len=94, loss/actor=-139.025, loss/critic=20.912, n/ep=0, n/st=1, rew=-8.21]\n",
      "Epoch #4: test_reward: -189.837962 ± 248.355960, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.80it/s, env_step=25000, len=202, loss/actor=-172.800, loss/critic=33.581, n/ep=0, n/st=1, rew=-113.66]\n",
      "Epoch #5: test_reward: -252.214549 ± 465.486471, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.93s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1598.63 step/s',\n",
      " 'test_step': 24857,\n",
      " 'test_time': '15.55s',\n",
      " 'train_episode': 102,\n",
      " 'train_speed': '113.96 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.73s',\n",
      " 'train_time/model': '180.65s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -123.28209048548604, length: 128.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:05:05.551890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.90it/s, env_step=5000, len=87, loss/actor=-33.356, loss/critic=5.570, n/ep=0, n/st=1, rew=53.68]\n",
      "Epoch #1: test_reward: 45.355560 ± 37.809745, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.27it/s, env_step=10000, len=31, loss/actor=-86.798, loss/critic=11.098, n/ep=0, n/st=1, rew=2.81]\n",
      "Epoch #2: test_reward: -72.129738 ± 206.465433, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.09it/s, env_step=15000, len=10, loss/actor=-136.765, loss/critic=27.588, n/ep=0, n/st=1, rew=-5.29]\n",
      "Epoch #3: test_reward: -287.520660 ± 372.798741, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.86it/s, env_step=20000, len=221, loss/actor=-174.065, loss/critic=26.951, n/ep=0, n/st=1, rew=-11.87]\n",
      "Epoch #4: test_reward: -294.462464 ± 416.170305, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.23it/s, env_step=25000, len=168, loss/actor=-197.755, loss/critic=34.295, n/ep=0, n/st=1, rew=-82.86]\n",
      "Epoch #5: test_reward: -383.882124 ± 507.940161, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1628.12 step/s',\n",
      " 'test_step': 25075,\n",
      " 'test_time': '15.40s',\n",
      " 'train_episode': 122,\n",
      " 'train_speed': '113.37 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.90s',\n",
      " 'train_time/model': '181.62s'}\n",
      "Final reward: -328.1212704986402, length: 417.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:09:30.770922: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.14it/s, env_step=5000, len=51, loss/actor=-30.746, loss/critic=4.812, n/ep=0, n/st=1, rew=43.63]\n",
      "Epoch #1: test_reward: -60.850753 ± 262.839037, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.44it/s, env_step=10000, len=1000, loss/actor=-86.582, loss/critic=12.800, n/ep=0, n/st=1, rew=-875.31]\n",
      "Epoch #2: test_reward: -178.586728 ± 308.981849, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.46it/s, env_step=15000, len=149, loss/actor=-151.940, loss/critic=30.822, n/ep=0, n/st=1, rew=-36.30]\n",
      "Epoch #3: test_reward: -240.673067 ± 437.804365, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.20it/s, env_step=20000, len=214, loss/actor=-213.922, loss/critic=53.797, n/ep=0, n/st=1, rew=-108.54]\n",
      "Epoch #4: test_reward: -336.346333 ± 478.751268, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.30it/s, env_step=25000, len=165, loss/actor=-266.596, loss/critic=86.081, n/ep=0, n/st=1, rew=-132.27]\n",
      "Epoch #5: test_reward: -138.551452 ± 326.899157, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1459.42 step/s',\n",
      " 'test_step': 23341,\n",
      " 'test_time': '15.99s',\n",
      " 'train_episode': 76,\n",
      " 'train_speed': '115.00 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.91s',\n",
      " 'train_time/model': '178.48s'}\n",
      "Final reward: -392.74450503982905, length: 455.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:13:53.623255: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.59it/s, env_step=5000, len=360, loss/actor=-33.345, loss/critic=5.335, n/ep=0, n/st=1, rew=17.25]\n",
      "Epoch #1: test_reward: -176.503659 ± 366.114672, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.27it/s, env_step=10000, len=15, loss/actor=-88.359, loss/critic=13.360, n/ep=0, n/st=1, rew=-4.28]\n",
      "Epoch #2: test_reward: -22.519538 ± 50.106163, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.10it/s, env_step=15000, len=8, loss/actor=-145.027, loss/critic=30.628, n/ep=0, n/st=1, rew=-5.47]\n",
      "Epoch #3: test_reward: -330.494276 ± 435.597699, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.72it/s, env_step=20000, len=34, loss/actor=-206.859, loss/critic=71.433, n/ep=0, n/st=1, rew=-32.50]\n",
      "Epoch #4: test_reward: -248.631589 ± 457.762747, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.26it/s, env_step=25000, len=217, loss/actor=-269.865, loss/critic=92.499, n/ep=0, n/st=1, rew=-230.02]\n",
      "Epoch #5: test_reward: -57.175779 ± 37.856665, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.76s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1682.96 step/s',\n",
      " 'test_step': 23563,\n",
      " 'test_time': '14.00s',\n",
      " 'train_episode': 83,\n",
      " 'train_speed': '114.28 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.75s',\n",
      " 'train_time/model': '180.01s'}\n",
      "Final reward: -51.98501015611625, length: 94.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:18:13.360409: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.56it/s, env_step=5000, len=158, loss/actor=-31.907, loss/critic=4.505, n/ep=0, n/st=1, rew=61.25]\n",
      "Epoch #1: test_reward: -200.712829 ± 355.688173, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:47, 106.28it/s, env_step=10000, len=59, loss/actor=-81.911, loss/critic=9.630, n/ep=0, n/st=1, rew=-12.19]\n",
      "Epoch #2: test_reward: -527.743093 ± 642.475983, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.09it/s, env_step=15000, len=1000, loss/actor=-125.125, loss/critic=13.813, n/ep=0, n/st=1, rew=-482.41]\n",
      "Epoch #3: test_reward: -228.323428 ± 343.551855, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.61it/s, env_step=20000, len=29, loss/actor=-159.976, loss/critic=34.260, n/ep=0, n/st=1, rew=-42.40]\n",
      "Epoch #4: test_reward: -192.289385 ± 337.827874, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 107.79it/s, env_step=25000, len=36, loss/actor=-189.595, loss/critic=33.713, n/ep=0, n/st=1, rew=-42.84]\n",
      "Epoch #5: test_reward: -248.782091 ± 348.501030, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '244.69s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1609.13 step/s',\n",
      " 'test_step': 27858,\n",
      " 'test_time': '17.31s',\n",
      " 'train_episode': 73,\n",
      " 'train_speed': '109.95 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.56s',\n",
      " 'train_time/model': '187.82s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -191.03903580293394, length: 262.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:22:46.849258: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.34it/s, env_step=5000, len=81, loss/actor=-33.480, loss/critic=6.041, n/ep=0, n/st=1, rew=40.91]\n",
      "Epoch #1: test_reward: 0.420452 ± 40.170650, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.13it/s, env_step=10000, len=1000, loss/actor=-91.757, loss/critic=12.450, n/ep=0, n/st=1, rew=-1086.83]\n",
      "Epoch #2: test_reward: -148.693904 ± 403.626556, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.62it/s, env_step=15000, len=13, loss/actor=-142.976, loss/critic=23.485, n/ep=0, n/st=1, rew=-0.38]\n",
      "Epoch #3: test_reward: -101.788893 ± 276.945406, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.94it/s, env_step=20000, len=14, loss/actor=-180.687, loss/critic=38.745, n/ep=0, n/st=1, rew=-9.04]\n",
      "Epoch #4: test_reward: -195.696411 ± 340.270769, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.15it/s, env_step=25000, len=28, loss/actor=-212.686, loss/critic=47.902, n/ep=0, n/st=1, rew=-24.00]\n",
      "Epoch #5: test_reward: -13.030480 ± 21.417849, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.80s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1417.95 step/s',\n",
      " 'test_step': 19101,\n",
      " 'test_time': '13.47s',\n",
      " 'train_episode': 103,\n",
      " 'train_speed': '115.56 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.78s',\n",
      " 'train_time/model': '177.55s'}\n",
      "Final reward: -608.1312985482806, length: 611.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:27:06.287145: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.30it/s, env_step=5000, len=203, loss/actor=-31.990, loss/critic=4.827, n/ep=0, n/st=1, rew=28.73]\n",
      "Epoch #1: test_reward: -190.364899 ± 553.184788, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.42it/s, env_step=10000, len=26, loss/actor=-78.511, loss/critic=8.736, n/ep=0, n/st=1, rew=0.46]\n",
      "Epoch #2: test_reward: -44.145958 ± 185.662874, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.97it/s, env_step=15000, len=1000, loss/actor=-115.387, loss/critic=11.729, n/ep=0, n/st=1, rew=-575.77]\n",
      "Epoch #3: test_reward: -160.034122 ± 208.711603, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.75it/s, env_step=20000, len=26, loss/actor=-147.407, loss/critic=18.137, n/ep=0, n/st=1, rew=-5.07]\n",
      "Epoch #4: test_reward: -224.747139 ± 308.861114, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.34it/s, env_step=25000, len=64, loss/actor=-170.237, loss/critic=26.228, n/ep=0, n/st=1, rew=-12.33]\n",
      "Epoch #5: test_reward: -87.373660 ± 210.831445, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.25s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1420.84 step/s',\n",
      " 'test_step': 22655,\n",
      " 'test_time': '15.94s',\n",
      " 'train_episode': 73,\n",
      " 'train_speed': '112.46 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.21s',\n",
      " 'train_time/model': '183.10s'}\n",
      "Final reward: -135.1960198422268, length: 252.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:31:33.094242: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.23it/s, env_step=5000, len=91, loss/actor=-29.566, loss/critic=3.831, n/ep=0, n/st=1, rew=40.17]\n",
      "Epoch #1: test_reward: -232.839648 ± 409.884272, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 111.05it/s, env_step=10000, len=43, loss/actor=-71.425, loss/critic=7.955, n/ep=0, n/st=1, rew=-21.86]\n",
      "Epoch #2: test_reward: -207.375355 ± 286.481135, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.20it/s, env_step=15000, len=18, loss/actor=-110.288, loss/critic=15.532, n/ep=0, n/st=1, rew=-27.50]\n",
      "Epoch #3: test_reward: -179.114202 ± 323.927232, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.85it/s, env_step=20000, len=19, loss/actor=-150.502, loss/critic=21.342, n/ep=0, n/st=1, rew=-23.13]\n",
      "Epoch #4: test_reward: -95.918498 ± 136.620201, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.41it/s, env_step=25000, len=1000, loss/actor=-190.367, loss/critic=35.877, n/ep=0, n/st=1, rew=-977.30]\n",
      "Epoch #5: test_reward: -320.042951 ± 393.660124, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.81s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1630.11 step/s',\n",
      " 'test_step': 25896,\n",
      " 'test_time': '15.89s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '112.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.88s',\n",
      " 'train_time/model': '183.04s'}\n",
      "Final reward: -156.11186080377098, length: 152.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:35:59.426979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 107.72it/s, env_step=5000, len=145, loss/actor=-33.917, loss/critic=5.509, n/ep=0, n/st=1, rew=101.44]\n",
      "Epoch #1: test_reward: -161.823366 ± 415.759851, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.64it/s, env_step=10000, len=16, loss/actor=-85.286, loss/critic=11.447, n/ep=0, n/st=1, rew=-7.97]\n",
      "Epoch #2: test_reward: -68.352894 ± 199.069988, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.47it/s, env_step=15000, len=32, loss/actor=-126.871, loss/critic=18.107, n/ep=0, n/st=1, rew=-1.79]\n",
      "Epoch #3: test_reward: 1.852065 ± 27.965428, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.01it/s, env_step=20000, len=18, loss/actor=-162.479, loss/critic=23.471, n/ep=0, n/st=1, rew=-17.29]\n",
      "Epoch #4: test_reward: -62.909829 ± 170.566982, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.61it/s, env_step=25000, len=127, loss/actor=-195.831, loss/critic=31.915, n/ep=0, n/st=1, rew=-19.12]\n",
      "Epoch #5: test_reward: -79.218649 ± 177.230837, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.18s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1507.93 step/s',\n",
      " 'test_step': 21425,\n",
      " 'test_time': '14.21s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '113.14 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.04s',\n",
      " 'train_time/model': '181.93s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -70.65502626972417, length: 190.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:40:23.455121: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.41it/s, env_step=5000, len=56, loss/actor=-32.493, loss/critic=4.901, n/ep=0, n/st=1, rew=19.52]\n",
      "Epoch #1: test_reward: -47.407930 ± 227.118543, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 116.03it/s, env_step=10000, len=78, loss/actor=-81.951, loss/critic=11.381, n/ep=0, n/st=1, rew=-43.00]\n",
      "Epoch #2: test_reward: -84.527003 ± 218.462858, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.64it/s, env_step=15000, len=47, loss/actor=-127.689, loss/critic=17.556, n/ep=0, n/st=1, rew=-2.47]\n",
      "Epoch #3: test_reward: -261.952569 ± 325.005325, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.50it/s, env_step=20000, len=12, loss/actor=-166.785, loss/critic=20.293, n/ep=0, n/st=1, rew=-6.61]\n",
      "Epoch #4: test_reward: -84.383030 ± 225.755449, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.88it/s, env_step=25000, len=145, loss/actor=-198.818, loss/critic=29.825, n/ep=0, n/st=1, rew=-55.28]\n",
      "Epoch #5: test_reward: -239.262017 ± 344.594949, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.23s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1426.78 step/s',\n",
      " 'test_step': 22237,\n",
      " 'test_time': '15.59s',\n",
      " 'train_episode': 119,\n",
      " 'train_speed': '112.80 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.42s',\n",
      " 'train_time/model': '182.22s'}\n",
      "Final reward: -302.19928237852696, length: 391.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:44:50.263844: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.38it/s, env_step=5000, len=19, loss/actor=-31.469, loss/critic=5.348, n/ep=0, n/st=1, rew=1.32]\n",
      "Epoch #1: test_reward: -119.030551 ± 258.390136, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.91it/s, env_step=10000, len=215, loss/actor=-80.539, loss/critic=11.406, n/ep=0, n/st=1, rew=-96.41]\n",
      "Epoch #2: test_reward: -529.018616 ± 442.264384, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.30it/s, env_step=15000, len=956, loss/actor=-135.804, loss/critic=19.947, n/ep=0, n/st=1, rew=-750.51]\n",
      "Epoch #3: test_reward: -19.997322 ± 24.948832, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.33it/s, env_step=20000, len=70, loss/actor=-203.410, loss/critic=42.257, n/ep=0, n/st=1, rew=11.50]\n",
      "Epoch #4: test_reward: -236.782715 ± 384.668511, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.49it/s, env_step=25000, len=55, loss/actor=-277.252, loss/critic=94.445, n/ep=0, n/st=1, rew=-8.93]\n",
      "Epoch #5: test_reward: -133.828230 ± 318.550084, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.98s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1597.00 step/s',\n",
      " 'test_step': 23512,\n",
      " 'test_time': '14.72s',\n",
      " 'train_episode': 113,\n",
      " 'train_speed': '111.98 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.47s',\n",
      " 'train_time/model': '183.79s'}\n",
      "Final reward: -152.2560290474525, length: 185.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:49:16.922037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.84it/s, env_step=5000, len=24, loss/actor=-30.640, loss/critic=4.036, n/ep=0, n/st=1, rew=1.48]\n",
      "Epoch #1: test_reward: -186.879186 ± 427.152832, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.77it/s, env_step=10000, len=19, loss/actor=-68.203, loss/critic=6.153, n/ep=0, n/st=1, rew=5.82]\n",
      "Epoch #2: test_reward: -63.111523 ± 184.350285, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.59it/s, env_step=15000, len=96, loss/actor=-107.793, loss/critic=11.204, n/ep=0, n/st=1, rew=3.31]\n",
      "Epoch #3: test_reward: -227.747427 ± 434.775656, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.73it/s, env_step=20000, len=93, loss/actor=-143.033, loss/critic=21.455, n/ep=0, n/st=1, rew=-13.11]\n",
      "Epoch #4: test_reward: -551.007241 ± 635.247556, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.94it/s, env_step=25000, len=45, loss/actor=-162.270, loss/critic=17.374, n/ep=0, n/st=1, rew=-42.86]\n",
      "Epoch #5: test_reward: -251.238197 ± 382.836170, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.51s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1545.31 step/s',\n",
      " 'test_step': 25687,\n",
      " 'test_time': '16.62s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '113.70 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.15s',\n",
      " 'train_time/model': '180.73s'}\n",
      "Final reward: -165.93535564123513, length: 245.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:53:42.282736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.98it/s, env_step=5000, len=180, loss/actor=-29.867, loss/critic=3.716, n/ep=0, n/st=1, rew=-72.01]\n",
      "Epoch #1: test_reward: 12.650731 ± 30.581635, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.17it/s, env_step=10000, len=24, loss/actor=-65.649, loss/critic=5.856, n/ep=0, n/st=1, rew=-8.40]\n",
      "Epoch #2: test_reward: -100.251809 ± 196.711577, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.36it/s, env_step=15000, len=1000, loss/actor=-92.976, loss/critic=9.158, n/ep=0, n/st=1, rew=-395.75]\n",
      "Epoch #3: test_reward: -245.019031 ± 199.231627, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.89it/s, env_step=20000, len=1000, loss/actor=-116.148, loss/critic=12.545, n/ep=0, n/st=1, rew=-282.52]\n",
      "Epoch #4: test_reward: -171.453125 ± 296.278478, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.95it/s, env_step=25000, len=27, loss/actor=-138.578, loss/critic=16.132, n/ep=0, n/st=1, rew=-4.76]\n",
      "Epoch #5: test_reward: -190.242099 ± 240.312039, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.57s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1643.96 step/s',\n",
      " 'test_step': 25892,\n",
      " 'test_time': '15.75s',\n",
      " 'train_episode': 86,\n",
      " 'train_speed': '113.73 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.35s',\n",
      " 'train_time/model': '180.47s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -200.2251291052267, length: 371.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 08:58:07.005932: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.05it/s, env_step=5000, len=1000, loss/actor=-31.469, loss/critic=4.219, n/ep=0, n/st=1, rew=506.22]\n",
      "Epoch #1: test_reward: -43.044486 ± 176.561702, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 113.80it/s, env_step=10000, len=277, loss/actor=-85.977, loss/critic=13.775, n/ep=0, n/st=1, rew=-52.85]\n",
      "Epoch #2: test_reward: -229.947377 ± 346.275285, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.32it/s, env_step=15000, len=275, loss/actor=-143.722, loss/critic=23.189, n/ep=0, n/st=1, rew=-136.22]\n",
      "Epoch #3: test_reward: -27.960128 ± 48.813336, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.84it/s, env_step=20000, len=820, loss/actor=-187.233, loss/critic=38.227, n/ep=0, n/st=1, rew=-844.29]\n",
      "Epoch #4: test_reward: -26.189054 ± 24.428190, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.61it/s, env_step=25000, len=24, loss/actor=-233.169, loss/critic=63.960, n/ep=0, n/st=1, rew=-13.13]\n",
      "Epoch #5: test_reward: -159.581163 ± 260.479894, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.17s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1763.39 step/s',\n",
      " 'test_step': 24202,\n",
      " 'test_time': '13.72s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '114.45 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.94s',\n",
      " 'train_time/model': '179.50s'}\n",
      "Final reward: -321.89368738317955, length: 355.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:02:28.192393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.81it/s, env_step=5000, len=30, loss/actor=-35.298, loss/critic=7.110, n/ep=0, n/st=1, rew=19.79]\n",
      "Epoch #1: test_reward: -350.715501 ± 685.889745, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.16it/s, env_step=10000, len=34, loss/actor=-93.793, loss/critic=18.311, n/ep=0, n/st=1, rew=8.81]\n",
      "Epoch #2: test_reward: -160.659782 ± 367.291210, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.74it/s, env_step=15000, len=86, loss/actor=-142.111, loss/critic=22.279, n/ep=0, n/st=1, rew=26.52]\n",
      "Epoch #3: test_reward: -275.416694 ± 393.239503, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.30it/s, env_step=20000, len=1000, loss/actor=-185.120, loss/critic=34.262, n/ep=0, n/st=1, rew=-1006.20]\n",
      "Epoch #4: test_reward: -328.715168 ± 461.790295, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.68it/s, env_step=25000, len=76, loss/actor=-226.868, loss/critic=46.622, n/ep=0, n/st=1, rew=-24.81]\n",
      "Epoch #5: test_reward: -221.892252 ± 348.735093, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.63s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1576.98 step/s',\n",
      " 'test_step': 26862,\n",
      " 'test_time': '17.03s',\n",
      " 'train_episode': 106,\n",
      " 'train_speed': '112.82 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.99s',\n",
      " 'train_time/model': '182.60s'}\n",
      "Final reward: -236.65987393793293, length: 245.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:06:55.498523: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.56it/s, env_step=5000, len=42, loss/actor=-31.594, loss/critic=4.764, n/ep=0, n/st=1, rew=-32.02]\n",
      "Epoch #1: test_reward: 149.008564 ± 199.306434, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.54it/s, env_step=10000, len=1000, loss/actor=-78.783, loss/critic=7.892, n/ep=0, n/st=1, rew=-733.03]\n",
      "Epoch #2: test_reward: -37.501633 ± 83.233712, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 108.70it/s, env_step=15000, len=55, loss/actor=-121.138, loss/critic=12.672, n/ep=0, n/st=1, rew=8.59]\n",
      "Epoch #3: test_reward: -72.898308 ± 166.174559, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.99it/s, env_step=20000, len=1000, loss/actor=-152.573, loss/critic=15.485, n/ep=0, n/st=1, rew=-602.35]\n",
      "Epoch #4: test_reward: -362.389471 ± 642.740851, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.61it/s, env_step=25000, len=1000, loss/actor=-181.405, loss/critic=30.447, n/ep=0, n/st=1, rew=-592.24]\n",
      "Epoch #5: test_reward: -253.458677 ± 434.500799, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.85s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1547.96 step/s',\n",
      " 'test_step': 24232,\n",
      " 'test_time': '15.65s',\n",
      " 'train_episode': 69,\n",
      " 'train_speed': '113.53 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.94s',\n",
      " 'train_time/model': '181.25s'}\n",
      "Final reward: -327.77667397692284, length: 345.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:11:20.644349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.38it/s, env_step=5000, len=59, loss/actor=-32.358, loss/critic=5.387, n/ep=0, n/st=1, rew=27.24]\n",
      "Epoch #1: test_reward: -11.624166 ± 66.895090, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.39it/s, env_step=10000, len=25, loss/actor=-84.397, loss/critic=15.758, n/ep=0, n/st=1, rew=-0.76]\n",
      "Epoch #2: test_reward: -302.241460 ± 418.338582, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.85it/s, env_step=15000, len=112, loss/actor=-137.206, loss/critic=25.622, n/ep=0, n/st=1, rew=30.24]\n",
      "Epoch #3: test_reward: -225.607677 ± 429.925000, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.54it/s, env_step=20000, len=43, loss/actor=-174.108, loss/critic=25.418, n/ep=0, n/st=1, rew=19.68]\n",
      "Epoch #4: test_reward: -120.740443 ± 317.064945, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.67it/s, env_step=25000, len=94, loss/actor=-204.995, loss/critic=33.275, n/ep=0, n/st=1, rew=-47.06]\n",
      "Epoch #5: test_reward: -167.342264 ± 305.939184, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.54s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1490.83 step/s',\n",
      " 'test_step': 21211,\n",
      " 'test_time': '14.23s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '115.04 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.65s',\n",
      " 'train_time/model': '178.67s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -94.86975165444323, length: 149.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:15:40.726702: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 108.58it/s, env_step=5000, len=25, loss/actor=-31.205, loss/critic=4.751, n/ep=0, n/st=1, rew=-32.59]\n",
      "Epoch #1: test_reward: -347.822914 ± 505.960646, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.50it/s, env_step=10000, len=12, loss/actor=-70.197, loss/critic=6.688, n/ep=0, n/st=1, rew=-1.65]\n",
      "Epoch #2: test_reward: -191.118877 ± 294.770807, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 107.15it/s, env_step=15000, len=25, loss/actor=-103.501, loss/critic=14.417, n/ep=0, n/st=1, rew=3.35]\n",
      "Epoch #3: test_reward: -322.031795 ± 327.030115, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.50it/s, env_step=20000, len=25, loss/actor=-129.877, loss/critic=20.154, n/ep=0, n/st=1, rew=-3.09]\n",
      "Epoch #4: test_reward: -183.500268 ± 333.796233, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 106.65it/s, env_step=25000, len=59, loss/actor=-150.938, loss/critic=16.107, n/ep=0, n/st=1, rew=-42.41]\n",
      "Epoch #5: test_reward: -85.052703 ± 206.418643, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '247.59s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1596.14 step/s',\n",
      " 'test_step': 27743,\n",
      " 'test_time': '17.38s',\n",
      " 'train_episode': 100,\n",
      " 'train_speed': '108.60 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.88s',\n",
      " 'train_time/model': '190.33s'}\n",
      "Final reward: -187.8175149762427, length: 326.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:20:17.730562: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.91it/s, env_step=5000, len=12, loss/actor=-31.071, loss/critic=3.919, n/ep=0, n/st=1, rew=1.51]\n",
      "Epoch #1: test_reward: -292.943411 ± 463.416211, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.88it/s, env_step=10000, len=1000, loss/actor=-74.235, loss/critic=7.002, n/ep=0, n/st=1, rew=-789.43]\n",
      "Epoch #2: test_reward: -125.464943 ± 251.867041, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.75it/s, env_step=15000, len=81, loss/actor=-116.187, loss/critic=14.670, n/ep=0, n/st=1, rew=-36.86]\n",
      "Epoch #3: test_reward: -192.335002 ± 323.297226, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.66it/s, env_step=20000, len=40, loss/actor=-155.404, loss/critic=23.389, n/ep=0, n/st=1, rew=-22.40]\n",
      "Epoch #4: test_reward: -87.016092 ± 178.162125, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.38it/s, env_step=25000, len=17, loss/actor=-195.485, loss/critic=50.041, n/ep=0, n/st=1, rew=-12.08]\n",
      "Epoch #5: test_reward: -358.584264 ± 409.226728, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.56s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1510.14 step/s',\n",
      " 'test_step': 24788,\n",
      " 'test_time': '16.41s',\n",
      " 'train_episode': 92,\n",
      " 'train_speed': '113.05 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.44s',\n",
      " 'train_time/model': '181.71s'}\n",
      "Final reward: -122.97354068017133, length: 156.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:24:44.136096: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.14it/s, env_step=5000, len=48, loss/actor=-36.095, loss/critic=6.404, n/ep=0, n/st=1, rew=27.63]\n",
      "Epoch #1: test_reward: 5.254647 ± 8.187692, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.43it/s, env_step=10000, len=44, loss/actor=-94.230, loss/critic=14.683, n/ep=0, n/st=1, rew=3.16]\n",
      "Epoch #2: test_reward: -238.759706 ± 455.448350, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:41, 119.23it/s, env_step=15000, len=1000, loss/actor=-149.268, loss/critic=23.379, n/ep=0, n/st=1, rew=-1064.57]\n",
      "Epoch #3: test_reward: -304.609135 ± 399.404427, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.42it/s, env_step=20000, len=14, loss/actor=-206.740, loss/critic=66.195, n/ep=0, n/st=1, rew=-14.43]\n",
      "Epoch #4: test_reward: -265.528414 ± 423.640939, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 113.84it/s, env_step=25000, len=10, loss/actor=-261.141, loss/critic=101.056, n/ep=0, n/st=1, rew=-16.63]\n",
      "Epoch #5: test_reward: -292.764023 ± 454.315307, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.16s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1536.87 step/s',\n",
      " 'test_step': 21058,\n",
      " 'test_time': '13.70s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '115.50 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.84s',\n",
      " 'train_time/model': '177.61s'}\n",
      "Final reward: -147.30612595662268, length: 181.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:29:03.113557: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 120.08it/s, env_step=5000, len=22, loss/actor=-34.559, loss/critic=5.912, n/ep=0, n/st=1, rew=14.08]\n",
      "Epoch #1: test_reward: -144.247152 ± 453.201955, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.95it/s, env_step=10000, len=51, loss/actor=-80.331, loss/critic=9.580, n/ep=0, n/st=1, rew=-12.28]\n",
      "Epoch #2: test_reward: -83.719329 ± 274.552730, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.37it/s, env_step=15000, len=58, loss/actor=-115.900, loss/critic=16.083, n/ep=0, n/st=1, rew=-27.82]\n",
      "Epoch #3: test_reward: -72.184826 ± 170.271966, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:41, 120.62it/s, env_step=20000, len=124, loss/actor=-144.242, loss/critic=16.931, n/ep=0, n/st=1, rew=13.43]\n",
      "Epoch #4: test_reward: -156.663400 ± 246.697431, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.02it/s, env_step=25000, len=17, loss/actor=-167.816, loss/critic=23.044, n/ep=0, n/st=1, rew=-7.33]\n",
      "Epoch #5: test_reward: -58.839387 ± 127.694259, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.84s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1367.59 step/s',\n",
      " 'test_step': 21099,\n",
      " 'test_time': '15.43s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '114.99 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.89s',\n",
      " 'train_time/model': '178.52s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -558.7121622902866, length: 812.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:33:26.337336: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.83it/s, env_step=5000, len=101, loss/actor=-32.972, loss/critic=4.963, n/ep=0, n/st=1, rew=9.92]\n",
      "Epoch #1: test_reward: -80.532400 ± 251.767907, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.68it/s, env_step=10000, len=60, loss/actor=-82.797, loss/critic=8.406, n/ep=0, n/st=1, rew=0.97]\n",
      "Epoch #2: test_reward: -16.325843 ± 13.028911, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.64it/s, env_step=15000, len=21, loss/actor=-123.199, loss/critic=17.301, n/ep=0, n/st=1, rew=1.90]\n",
      "Epoch #3: test_reward: -13.070273 ± 22.377620, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.94it/s, env_step=20000, len=165, loss/actor=-157.592, loss/critic=25.963, n/ep=0, n/st=1, rew=-65.63]\n",
      "Epoch #4: test_reward: -9.262462 ± 15.494653, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.56it/s, env_step=25000, len=91, loss/actor=-195.150, loss/critic=39.453, n/ep=0, n/st=1, rew=-29.29]\n",
      "Epoch #5: test_reward: -219.821007 ± 408.645893, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.71s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1594.28 step/s',\n",
      " 'test_step': 15488,\n",
      " 'test_time': '9.71s',\n",
      " 'train_episode': 101,\n",
      " 'train_speed': '113.64 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.91s',\n",
      " 'train_time/model': '181.08s'}\n",
      "Final reward: -20.469683929336934, length: 49.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:37:43.004958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.46it/s, env_step=5000, len=152, loss/actor=-33.600, loss/critic=5.050, n/ep=0, n/st=1, rew=5.75]\n",
      "Epoch #1: test_reward: 35.844403 ± 384.062834, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 116.18it/s, env_step=10000, len=15, loss/actor=-80.637, loss/critic=8.987, n/ep=0, n/st=1, rew=1.33]\n",
      "Epoch #2: test_reward: -146.051457 ± 312.049520, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.72it/s, env_step=15000, len=59, loss/actor=-124.091, loss/critic=23.704, n/ep=0, n/st=1, rew=17.61]\n",
      "Epoch #3: test_reward: -83.049812 ± 238.580096, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.29it/s, env_step=20000, len=17, loss/actor=-160.384, loss/critic=35.711, n/ep=0, n/st=1, rew=-10.16]\n",
      "Epoch #4: test_reward: -7.526157 ± 43.587971, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.47it/s, env_step=25000, len=35, loss/actor=-188.986, loss/critic=41.285, n/ep=0, n/st=1, rew=10.98]\n",
      "Epoch #5: test_reward: -187.464971 ± 356.047559, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.22s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1470.21 step/s',\n",
      " 'test_step': 20910,\n",
      " 'test_time': '14.22s',\n",
      " 'train_episode': 142,\n",
      " 'train_speed': '114.15 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.20s',\n",
      " 'train_time/model': '179.80s'}\n",
      "Final reward: -222.36870271535545, length: 310.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:42:05.165784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.91it/s, env_step=5000, len=13, loss/actor=-34.241, loss/critic=5.583, n/ep=0, n/st=1, rew=-5.07]\n",
      "Epoch #1: test_reward: -127.733809 ± 361.904716, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.57it/s, env_step=10000, len=66, loss/actor=-84.212, loss/critic=10.718, n/ep=0, n/st=1, rew=-18.92]\n",
      "Epoch #2: test_reward: -308.860112 ± 471.564060, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.34it/s, env_step=15000, len=62, loss/actor=-119.403, loss/critic=14.424, n/ep=0, n/st=1, rew=3.10]\n",
      "Epoch #3: test_reward: -286.046219 ± 426.900023, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.86it/s, env_step=20000, len=1000, loss/actor=-145.721, loss/critic=19.019, n/ep=0, n/st=1, rew=-745.51]\n",
      "Epoch #4: test_reward: -83.939076 ± 197.235454, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.31it/s, env_step=25000, len=1000, loss/actor=-175.257, loss/critic=34.140, n/ep=0, n/st=1, rew=-795.35]\n",
      "Epoch #5: test_reward: -256.994932 ± 340.771649, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.87s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1443.12 step/s',\n",
      " 'test_step': 23482,\n",
      " 'test_time': '16.27s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '113.33 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.72s',\n",
      " 'train_time/model': '181.88s'}\n",
      "Final reward: -294.0000540898979, length: 363.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:46:31.214079: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.23it/s, env_step=5000, len=144, loss/actor=-30.828, loss/critic=4.404, n/ep=0, n/st=1, rew=54.80]\n",
      "Epoch #1: test_reward: 153.490645 ± 181.425118, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.42it/s, env_step=10000, len=1000, loss/actor=-73.106, loss/critic=7.999, n/ep=0, n/st=1, rew=-494.71]\n",
      "Epoch #2: test_reward: -86.399504 ± 200.982377, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.38it/s, env_step=15000, len=29, loss/actor=-111.760, loss/critic=12.320, n/ep=0, n/st=1, rew=-31.61]\n",
      "Epoch #3: test_reward: -189.896558 ± 278.808656, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.24it/s, env_step=20000, len=24, loss/actor=-143.420, loss/critic=21.229, n/ep=0, n/st=1, rew=2.72]\n",
      "Epoch #4: test_reward: -14.090184 ± 20.146058, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.24it/s, env_step=25000, len=12, loss/actor=-171.483, loss/critic=34.403, n/ep=0, n/st=1, rew=-11.54]\n",
      "Epoch #5: test_reward: -212.579655 ± 294.064000, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.31s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1589.89 step/s',\n",
      " 'test_step': 23351,\n",
      " 'test_time': '14.69s',\n",
      " 'train_episode': 76,\n",
      " 'train_speed': '113.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.47s',\n",
      " 'train_time/model': '181.15s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -146.6383928839993, length: 260.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:50:54.377944: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.58it/s, env_step=5000, len=90, loss/actor=-32.454, loss/critic=4.674, n/ep=0, n/st=1, rew=49.01]\n",
      "Epoch #1: test_reward: -145.320382 ± 355.187215, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.83it/s, env_step=10000, len=33, loss/actor=-79.108, loss/critic=10.100, n/ep=0, n/st=1, rew=4.45]\n",
      "Epoch #2: test_reward: -259.415299 ± 321.949963, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.09it/s, env_step=15000, len=160, loss/actor=-119.542, loss/critic=16.461, n/ep=0, n/st=1, rew=-67.99]\n",
      "Epoch #3: test_reward: -264.570875 ± 503.533146, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.57it/s, env_step=20000, len=51, loss/actor=-152.263, loss/critic=19.543, n/ep=0, n/st=1, rew=-30.20]\n",
      "Epoch #4: test_reward: -164.607828 ± 285.848347, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.64it/s, env_step=25000, len=54, loss/actor=-181.347, loss/critic=25.438, n/ep=0, n/st=1, rew=-40.50]\n",
      "Epoch #5: test_reward: -84.222759 ± 139.656427, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.90s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1599.99 step/s',\n",
      " 'test_step': 25909,\n",
      " 'test_time': '16.19s',\n",
      " 'train_episode': 105,\n",
      " 'train_speed': '113.27 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.74s',\n",
      " 'train_time/model': '181.97s'}\n",
      "Final reward: -188.6890040108532, length: 246.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:55:20.323634: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.31it/s, env_step=5000, len=1000, loss/actor=-33.991, loss/critic=6.510, n/ep=0, n/st=1, rew=-830.65]\n",
      "Epoch #1: test_reward: -87.513789 ± 347.617737, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.58it/s, env_step=10000, len=365, loss/actor=-103.714, loss/critic=17.325, n/ep=0, n/st=1, rew=-39.24]\n",
      "Epoch #2: test_reward: -322.039590 ± 634.481093, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.07it/s, env_step=15000, len=96, loss/actor=-152.480, loss/critic=28.440, n/ep=0, n/st=1, rew=-66.59]\n",
      "Epoch #3: test_reward: -148.003956 ± 393.659440, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.05it/s, env_step=20000, len=34, loss/actor=-191.723, loss/critic=38.304, n/ep=0, n/st=1, rew=1.00]\n",
      "Epoch #4: test_reward: -14.936114 ± 19.264248, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.49it/s, env_step=25000, len=29, loss/actor=-227.868, loss/critic=52.015, n/ep=0, n/st=1, rew=-6.18]\n",
      "Epoch #5: test_reward: -297.969797 ± 509.343877, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1435.08 step/s',\n",
      " 'test_step': 19249,\n",
      " 'test_time': '13.41s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '111.62 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.47s',\n",
      " 'train_time/model': '184.50s'}\n",
      "Final reward: -173.01298313466992, length: 157.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 09:59:46.447966: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.68it/s, env_step=5000, len=51, loss/actor=-35.450, loss/critic=5.685, n/ep=0, n/st=1, rew=-33.35]\n",
      "Epoch #1: test_reward: -26.997087 ± 43.309700, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.82it/s, env_step=10000, len=27, loss/actor=-93.815, loss/critic=16.248, n/ep=0, n/st=1, rew=1.62]\n",
      "Epoch #2: test_reward: -340.062122 ± 492.049490, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.49it/s, env_step=15000, len=146, loss/actor=-145.828, loss/critic=26.065, n/ep=0, n/st=1, rew=-44.15]\n",
      "Epoch #3: test_reward: -171.706122 ± 428.789349, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.67it/s, env_step=20000, len=122, loss/actor=-177.939, loss/critic=23.052, n/ep=0, n/st=1, rew=-72.33]\n",
      "Epoch #4: test_reward: -220.370104 ± 364.357774, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.55it/s, env_step=25000, len=99, loss/actor=-197.913, loss/critic=45.424, n/ep=0, n/st=1, rew=27.15]\n",
      "Epoch #5: test_reward: -77.154176 ± 266.255471, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.12s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1465.32 step/s',\n",
      " 'test_step': 20206,\n",
      " 'test_time': '13.79s',\n",
      " 'train_episode': 126,\n",
      " 'train_speed': '113.98 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.08s',\n",
      " 'train_time/model': '180.25s'}\n",
      "Final reward: -314.2864955182095, length: 353.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:04:08.633556: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.17it/s, env_step=5000, len=115, loss/actor=-35.087, loss/critic=6.688, n/ep=0, n/st=1, rew=26.89]\n",
      "Epoch #1: test_reward: -203.125553 ± 384.550774, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 113.74it/s, env_step=10000, len=25, loss/actor=-95.481, loss/critic=19.297, n/ep=0, n/st=1, rew=13.24]\n",
      "Epoch #2: test_reward: -110.248569 ± 297.342808, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.82it/s, env_step=15000, len=39, loss/actor=-140.604, loss/critic=20.505, n/ep=0, n/st=1, rew=-11.38]\n",
      "Epoch #3: test_reward: -120.231934 ± 296.929189, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.27it/s, env_step=20000, len=46, loss/actor=-181.701, loss/critic=39.449, n/ep=0, n/st=1, rew=-45.41]\n",
      "Epoch #4: test_reward: -398.491796 ± 441.960243, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.02it/s, env_step=25000, len=167, loss/actor=-220.526, loss/critic=47.796, n/ep=0, n/st=1, rew=-87.14]\n",
      "Epoch #5: test_reward: -223.033799 ± 398.597099, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.29s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1447.91 step/s',\n",
      " 'test_step': 23002,\n",
      " 'test_time': '15.89s',\n",
      " 'train_episode': 95,\n",
      " 'train_speed': '113.94 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.98s',\n",
      " 'train_time/model': '180.43s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -522.6711737708376, length: 478.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:08:33.319220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 120.18it/s, env_step=5000, len=1000, loss/actor=-31.624, loss/critic=4.394, n/ep=0, n/st=1, rew=-419.43]\n",
      "Epoch #1: test_reward: -445.475127 ± 497.293105, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.19it/s, env_step=10000, len=1000, loss/actor=-80.182, loss/critic=8.551, n/ep=0, n/st=1, rew=-898.85]\n",
      "Epoch #2: test_reward: -149.823769 ± 299.621683, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.47it/s, env_step=15000, len=12, loss/actor=-119.092, loss/critic=17.331, n/ep=0, n/st=1, rew=-6.43]\n",
      "Epoch #3: test_reward: -1.259404 ± 10.166116, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.26it/s, env_step=20000, len=45, loss/actor=-154.683, loss/critic=25.548, n/ep=0, n/st=1, rew=-1.91]\n",
      "Epoch #4: test_reward: -143.399750 ± 307.711349, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.94it/s, env_step=25000, len=1000, loss/actor=-185.903, loss/critic=36.112, n/ep=0, n/st=1, rew=-979.63]\n",
      "Epoch #5: test_reward: -111.681101 ± 259.033875, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.93s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1571.53 step/s',\n",
      " 'test_step': 22673,\n",
      " 'test_time': '14.43s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '115.47 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.43s',\n",
      " 'train_time/model': '178.07s'}\n",
      "Final reward: -458.60921736875855, length: 520.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:12:54.136774: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.17it/s, env_step=5000, len=203, loss/actor=-33.173, loss/critic=5.239, n/ep=0, n/st=1, rew=-16.45]\n",
      "Epoch #1: test_reward: -380.086416 ± 542.995962, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.23it/s, env_step=10000, len=46, loss/actor=-81.750, loss/critic=9.812, n/ep=0, n/st=1, rew=-5.05]\n",
      "Epoch #2: test_reward: -500.394071 ± 513.696393, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.70it/s, env_step=15000, len=28, loss/actor=-120.953, loss/critic=15.353, n/ep=0, n/st=1, rew=0.22]\n",
      "Epoch #3: test_reward: -18.134731 ± 46.020017, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.41it/s, env_step=20000, len=34, loss/actor=-152.629, loss/critic=22.633, n/ep=0, n/st=1, rew=7.23]\n",
      "Epoch #4: test_reward: -181.857969 ± 253.682749, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.32it/s, env_step=25000, len=15, loss/actor=-176.854, loss/critic=32.777, n/ep=0, n/st=1, rew=-10.07]\n",
      "Epoch #5: test_reward: -70.364096 ± 185.793361, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.99s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1602.73 step/s',\n",
      " 'test_step': 23772,\n",
      " 'test_time': '14.83s',\n",
      " 'train_episode': 96,\n",
      " 'train_speed': '113.04 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.28s',\n",
      " 'train_time/model': '181.87s'}\n",
      "Final reward: -178.5377928552476, length: 277.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:17:18.722349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.02it/s, env_step=5000, len=1000, loss/actor=-35.713, loss/critic=7.033, n/ep=0, n/st=1, rew=-807.58]\n",
      "Epoch #1: test_reward: -22.584916 ± 129.545652, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.53it/s, env_step=10000, len=19, loss/actor=-94.477, loss/critic=16.764, n/ep=0, n/st=1, rew=10.19]\n",
      "Epoch #2: test_reward: -126.996813 ± 297.147289, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.10it/s, env_step=15000, len=27, loss/actor=-148.150, loss/critic=27.565, n/ep=0, n/st=1, rew=14.30]\n",
      "Epoch #3: test_reward: -199.141765 ± 375.980622, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:46, 106.66it/s, env_step=20000, len=1000, loss/actor=-191.645, loss/critic=38.243, n/ep=0, n/st=1, rew=-1155.83]\n",
      "Epoch #4: test_reward: -257.452841 ± 413.970479, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 108.57it/s, env_step=25000, len=29, loss/actor=-236.665, loss/critic=53.726, n/ep=0, n/st=1, rew=-10.25]\n",
      "Epoch #5: test_reward: -135.843292 ± 334.296084, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.01s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1394.86 step/s',\n",
      " 'test_step': 19628,\n",
      " 'test_time': '14.07s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '110.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.62s',\n",
      " 'train_time/model': '186.32s'}\n",
      "Final reward: -238.94158504108037, length: 248.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:21:47.765038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.10it/s, env_step=5000, len=1000, loss/actor=-33.811, loss/critic=4.944, n/ep=0, n/st=1, rew=-256.15]\n",
      "Epoch #1: test_reward: -280.768853 ± 491.618918, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.09it/s, env_step=10000, len=66, loss/actor=-78.031, loss/critic=8.451, n/ep=0, n/st=1, rew=-44.21]\n",
      "Epoch #2: test_reward: -157.509770 ± 337.722488, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.88it/s, env_step=15000, len=26, loss/actor=-116.213, loss/critic=15.158, n/ep=0, n/st=1, rew=10.86]\n",
      "Epoch #3: test_reward: -217.663257 ± 327.930525, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.33it/s, env_step=20000, len=1000, loss/actor=-147.254, loss/critic=16.967, n/ep=0, n/st=1, rew=-683.49]\n",
      "Epoch #4: test_reward: -243.326205 ± 346.296948, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.62it/s, env_step=25000, len=59, loss/actor=-176.887, loss/critic=32.253, n/ep=0, n/st=1, rew=-21.61]\n",
      "Epoch #5: test_reward: -456.497193 ± 441.317072, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.56s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1620.45 step/s',\n",
      " 'test_step': 28684,\n",
      " 'test_time': '17.70s',\n",
      " 'train_episode': 71,\n",
      " 'train_speed': '113.71 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.50s',\n",
      " 'train_time/model': '180.35s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -369.5686454030677, length: 554.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:26:14.795342: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.06it/s, env_step=5000, len=291, loss/actor=-35.360, loss/critic=5.477, n/ep=0, n/st=1, rew=51.74]\n",
      "Epoch #1: test_reward: -83.732724 ± 302.954139, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.01it/s, env_step=10000, len=16, loss/actor=-91.115, loss/critic=11.547, n/ep=0, n/st=1, rew=-17.83]\n",
      "Epoch #2: test_reward: -49.558409 ± 227.088620, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.05it/s, env_step=15000, len=1000, loss/actor=-138.716, loss/critic=16.274, n/ep=0, n/st=1, rew=-940.64]\n",
      "Epoch #3: test_reward: -326.090578 ± 402.657204, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.29it/s, env_step=20000, len=47, loss/actor=-178.149, loss/critic=29.051, n/ep=0, n/st=1, rew=-7.84]\n",
      "Epoch #4: test_reward: -164.867751 ± 280.721294, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.44it/s, env_step=25000, len=20, loss/actor=-209.403, loss/critic=33.481, n/ep=0, n/st=1, rew=-21.53]\n",
      "Epoch #5: test_reward: -279.241564 ± 325.547654, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '241.53s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1533.94 step/s',\n",
      " 'test_step': 25337,\n",
      " 'test_time': '16.52s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '111.10 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.61s',\n",
      " 'train_time/model': '185.40s'}\n",
      "Final reward: -93.04991434270761, length: 167.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:30:44.791568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.65it/s, env_step=5000, len=32, loss/actor=-30.886, loss/critic=4.301, n/ep=0, n/st=1, rew=11.85]\n",
      "Epoch #1: test_reward: -131.242672 ± 236.991054, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.84it/s, env_step=10000, len=126, loss/actor=-69.828, loss/critic=6.948, n/ep=0, n/st=1, rew=-44.78]\n",
      "Epoch #2: test_reward: -83.249218 ± 241.891219, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.67it/s, env_step=15000, len=164, loss/actor=-100.938, loss/critic=9.957, n/ep=0, n/st=1, rew=19.65]\n",
      "Epoch #3: test_reward: -179.584601 ± 289.555160, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.86it/s, env_step=20000, len=51, loss/actor=-125.814, loss/critic=10.862, n/ep=0, n/st=1, rew=19.33]\n",
      "Epoch #4: test_reward: -95.875626 ± 179.006809, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.68it/s, env_step=25000, len=50, loss/actor=-146.501, loss/critic=13.777, n/ep=0, n/st=1, rew=-11.66]\n",
      "Epoch #5: test_reward: -103.394111 ± 159.082112, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.23s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1485.66 step/s',\n",
      " 'test_step': 23571,\n",
      " 'test_time': '15.87s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '113.45 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.10s',\n",
      " 'train_time/model': '181.26s'}\n",
      "Final reward: -98.30846362244684, length: 230.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:35:09.723314: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.42it/s, env_step=5000, len=1000, loss/actor=-29.092, loss/critic=3.577, n/ep=0, n/st=1, rew=185.19]\n",
      "Epoch #1: test_reward: -178.542221 ± 314.888084, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:41, 119.44it/s, env_step=10000, len=125, loss/actor=-73.218, loss/critic=7.235, n/ep=0, n/st=1, rew=-80.15]\n",
      "Epoch #2: test_reward: -55.521752 ± 163.430018, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.99it/s, env_step=15000, len=80, loss/actor=-112.051, loss/critic=10.688, n/ep=0, n/st=1, rew=5.59]\n",
      "Epoch #3: test_reward: -73.775317 ± 220.956829, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.28it/s, env_step=20000, len=79, loss/actor=-138.894, loss/critic=16.300, n/ep=0, n/st=1, rew=-15.96]\n",
      "Epoch #4: test_reward: -9.501181 ± 24.516178, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.34it/s, env_step=25000, len=133, loss/actor=-163.117, loss/critic=24.195, n/ep=0, n/st=1, rew=14.15]\n",
      "Epoch #5: test_reward: -133.031026 ± 272.652794, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.78s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1448.96 step/s',\n",
      " 'test_step': 19724,\n",
      " 'test_time': '13.61s',\n",
      " 'train_episode': 102,\n",
      " 'train_speed': '113.55 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.98s',\n",
      " 'train_time/model': '181.19s'}\n",
      "Final reward: -26.363383378319337, length: 79.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:39:30.974395: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.39it/s, env_step=5000, len=1000, loss/actor=-31.745, loss/critic=5.066, n/ep=0, n/st=1, rew=-652.67]\n",
      "Epoch #1: test_reward: 27.624443 ± 106.039095, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.91it/s, env_step=10000, len=25, loss/actor=-86.742, loss/critic=12.876, n/ep=0, n/st=1, rew=7.03]\n",
      "Epoch #2: test_reward: -187.255774 ± 305.128309, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.87it/s, env_step=15000, len=1000, loss/actor=-137.475, loss/critic=21.887, n/ep=0, n/st=1, rew=-939.24]\n",
      "Epoch #3: test_reward: -225.933962 ± 444.211088, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 109.47it/s, env_step=20000, len=277, loss/actor=-177.489, loss/critic=26.606, n/ep=0, n/st=1, rew=-35.86]\n",
      "Epoch #4: test_reward: -148.480525 ± 283.126513, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.20it/s, env_step=25000, len=1000, loss/actor=-209.327, loss/critic=32.837, n/ep=0, n/st=1, rew=-740.60]\n",
      "Epoch #5: test_reward: -28.802433 ± 28.136027, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.44s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1489.34 step/s',\n",
      " 'test_step': 20828,\n",
      " 'test_time': '13.98s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '112.89 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.22s',\n",
      " 'train_time/model': '182.24s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -102.1886250024265, length: 145.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:43:54.305214: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.62it/s, env_step=5000, len=144, loss/actor=-29.424, loss/critic=3.923, n/ep=0, n/st=1, rew=111.10]\n",
      "Epoch #1: test_reward: -101.620082 ± 209.597793, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.08it/s, env_step=10000, len=77, loss/actor=-73.180, loss/critic=8.934, n/ep=0, n/st=1, rew=-5.16]\n",
      "Epoch #2: test_reward: 13.440982 ± 15.369007, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.65it/s, env_step=15000, len=1000, loss/actor=-112.125, loss/critic=12.350, n/ep=0, n/st=1, rew=-687.19]\n",
      "Epoch #3: test_reward: -431.546178 ± 338.243319, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.51it/s, env_step=20000, len=193, loss/actor=-143.951, loss/critic=18.227, n/ep=0, n/st=1, rew=7.00]\n",
      "Epoch #4: test_reward: -492.638391 ± 523.958390, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.97it/s, env_step=25000, len=55, loss/actor=-172.309, loss/critic=28.435, n/ep=0, n/st=1, rew=50.47]\n",
      "Epoch #5: test_reward: -171.496858 ± 246.696372, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.82s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1806.45 step/s',\n",
      " 'test_step': 30049,\n",
      " 'test_time': '16.63s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '113.03 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.32s',\n",
      " 'train_time/model': '181.87s'}\n",
      "Final reward: -337.33505029451754, length: 347.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:48:21.088038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.91it/s, env_step=5000, len=241, loss/actor=-32.845, loss/critic=4.464, n/ep=0, n/st=1, rew=41.60]\n",
      "Epoch #1: test_reward: -87.391136 ± 382.480192, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.15it/s, env_step=10000, len=116, loss/actor=-82.465, loss/critic=11.709, n/ep=0, n/st=1, rew=49.79]\n",
      "Epoch #2: test_reward: -134.995530 ± 447.504942, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.19it/s, env_step=15000, len=17, loss/actor=-121.680, loss/critic=20.623, n/ep=0, n/st=1, rew=-1.89]\n",
      "Epoch #3: test_reward: -227.704020 ± 318.759436, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.75it/s, env_step=20000, len=79, loss/actor=-159.791, loss/critic=28.636, n/ep=0, n/st=1, rew=-52.37]\n",
      "Epoch #4: test_reward: -277.222447 ± 406.113355, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.62it/s, env_step=25000, len=1000, loss/actor=-185.620, loss/critic=25.771, n/ep=0, n/st=1, rew=-747.63]\n",
      "Epoch #5: test_reward: -156.538814 ± 281.155365, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.02s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1398.85 step/s',\n",
      " 'test_step': 21672,\n",
      " 'test_time': '15.49s',\n",
      " 'train_episode': 68,\n",
      " 'train_speed': '114.40 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.10s',\n",
      " 'train_time/model': '179.43s'}\n",
      "Final reward: -163.10133017564604, length: 242.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:52:43.734008: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.79it/s, env_step=5000, len=1000, loss/actor=-34.078, loss/critic=4.833, n/ep=0, n/st=1, rew=-845.43]\n",
      "Epoch #1: test_reward: -97.803882 ± 406.547816, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.37it/s, env_step=10000, len=73, loss/actor=-79.884, loss/critic=9.248, n/ep=0, n/st=1, rew=23.20]\n",
      "Epoch #2: test_reward: -69.171658 ± 242.811150, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.18it/s, env_step=15000, len=69, loss/actor=-121.242, loss/critic=17.649, n/ep=0, n/st=1, rew=3.14]\n",
      "Epoch #3: test_reward: -147.852280 ± 328.467265, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 111.11it/s, env_step=20000, len=1000, loss/actor=-154.583, loss/critic=26.960, n/ep=0, n/st=1, rew=-899.22]\n",
      "Epoch #4: test_reward: -244.742036 ± 365.591022, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.49it/s, env_step=25000, len=74, loss/actor=-182.355, loss/critic=27.912, n/ep=0, n/st=1, rew=-27.51]\n",
      "Epoch #5: test_reward: -166.308258 ± 290.945383, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.16s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1524.63 step/s',\n",
      " 'test_step': 24938,\n",
      " 'test_time': '16.36s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '111.70 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '184.54s'}\n",
      "Final reward: -303.4290295569841, length: 375.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 10:57:13.056054: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.73it/s, env_step=5000, len=1000, loss/actor=-33.061, loss/critic=5.353, n/ep=0, n/st=1, rew=-556.94]\n",
      "Epoch #1: test_reward: -268.585407 ± 479.138110, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.07it/s, env_step=10000, len=13, loss/actor=-84.305, loss/critic=9.745, n/ep=0, n/st=1, rew=-1.81]\n",
      "Epoch #2: test_reward: -116.510551 ± 259.619420, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.27it/s, env_step=15000, len=61, loss/actor=-128.790, loss/critic=25.939, n/ep=0, n/st=1, rew=-52.33]\n",
      "Epoch #3: test_reward: -2.452633 ± 16.168570, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.41it/s, env_step=20000, len=105, loss/actor=-164.605, loss/critic=32.249, n/ep=0, n/st=1, rew=-15.27]\n",
      "Epoch #4: test_reward: -11.410883 ± 24.909453, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 108.06it/s, env_step=25000, len=22, loss/actor=-196.446, loss/critic=40.756, n/ep=0, n/st=1, rew=-13.94]\n",
      "Epoch #5: test_reward: -72.547166 ± 123.576366, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.03s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1510.29 step/s',\n",
      " 'test_step': 18416,\n",
      " 'test_time': '12.19s',\n",
      " 'train_episode': 94,\n",
      " 'train_speed': '110.21 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.75s',\n",
      " 'train_time/model': '187.08s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 36.38431949299827, length: 280.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:01:41.032852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.29it/s, env_step=5000, len=309, loss/actor=-33.675, loss/critic=5.350, n/ep=0, n/st=1, rew=-70.20]\n",
      "Epoch #1: test_reward: -166.011152 ± 495.976458, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.24it/s, env_step=10000, len=88, loss/actor=-86.105, loss/critic=10.323, n/ep=0, n/st=1, rew=-25.15]\n",
      "Epoch #2: test_reward: -6.106003 ± 27.793528, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.68it/s, env_step=15000, len=48, loss/actor=-128.604, loss/critic=18.788, n/ep=0, n/st=1, rew=32.63]\n",
      "Epoch #3: test_reward: -159.798080 ± 276.427613, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.54it/s, env_step=20000, len=18, loss/actor=-163.692, loss/critic=29.258, n/ep=0, n/st=1, rew=-3.12]\n",
      "Epoch #4: test_reward: -77.003516 ± 208.417797, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.45it/s, env_step=25000, len=35, loss/actor=-197.067, loss/critic=43.259, n/ep=0, n/st=1, rew=-22.91]\n",
      "Epoch #5: test_reward: -299.544489 ± 376.729588, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.89s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1499.83 step/s',\n",
      " 'test_step': 20865,\n",
      " 'test_time': '13.91s',\n",
      " 'train_episode': 122,\n",
      " 'train_speed': '114.17 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.07s',\n",
      " 'train_time/model': '179.90s'}\n",
      "Final reward: -522.8349433923756, length: 566.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:06:03.788018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.50it/s, env_step=5000, len=289, loss/actor=-31.326, loss/critic=4.380, n/ep=0, n/st=1, rew=-248.80]\n",
      "Epoch #1: test_reward: 10.785461 ± 25.788206, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.96it/s, env_step=10000, len=29, loss/actor=-73.641, loss/critic=7.584, n/ep=0, n/st=1, rew=18.66]\n",
      "Epoch #2: test_reward: -88.284178 ± 212.645186, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.43it/s, env_step=15000, len=26, loss/actor=-115.357, loss/critic=13.438, n/ep=0, n/st=1, rew=-39.59]\n",
      "Epoch #3: test_reward: -170.828302 ± 289.571855, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.13it/s, env_step=20000, len=95, loss/actor=-156.826, loss/critic=25.066, n/ep=0, n/st=1, rew=-2.89]\n",
      "Epoch #4: test_reward: -324.987939 ± 359.421399, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.72it/s, env_step=25000, len=204, loss/actor=-193.337, loss/critic=40.738, n/ep=0, n/st=1, rew=-41.52]\n",
      "Epoch #5: test_reward: -199.966214 ± 312.782084, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '228.54s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1572.35 step/s',\n",
      " 'test_step': 22405,\n",
      " 'test_time': '14.25s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '116.66 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.60s',\n",
      " 'train_time/model': '175.70s'}\n",
      "Final reward: -234.570431456734, length: 386.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:10:21.492474: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.54it/s, env_step=5000, len=1000, loss/actor=-31.851, loss/critic=3.952, n/ep=0, n/st=1, rew=15.68]\n",
      "Epoch #1: test_reward: -2.660419 ± 165.761759, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.49it/s, env_step=10000, len=162, loss/actor=-72.992, loss/critic=7.280, n/ep=0, n/st=1, rew=-82.49]\n",
      "Epoch #2: test_reward: -165.764799 ± 297.781881, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.44it/s, env_step=15000, len=240, loss/actor=-105.958, loss/critic=15.483, n/ep=0, n/st=1, rew=-130.08]\n",
      "Epoch #3: test_reward: -79.241664 ± 185.568128, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.04it/s, env_step=20000, len=12, loss/actor=-129.346, loss/critic=15.050, n/ep=0, n/st=1, rew=-16.41]\n",
      "Epoch #4: test_reward: -122.943594 ± 159.074343, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.36it/s, env_step=25000, len=1000, loss/actor=-155.346, loss/critic=26.903, n/ep=0, n/st=1, rew=-671.32]\n",
      "Epoch #5: test_reward: -154.853179 ± 227.363847, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.17s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1501.18 step/s',\n",
      " 'test_step': 23555,\n",
      " 'test_time': '15.69s',\n",
      " 'train_episode': 88,\n",
      " 'train_speed': '112.88 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.89s',\n",
      " 'train_time/model': '182.59s'}\n",
      "Final reward: -130.62053937030305, length: 330.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:14:47.673072: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.64it/s, env_step=5000, len=1000, loss/actor=-33.428, loss/critic=5.954, n/ep=0, n/st=1, rew=-385.25]\n",
      "Epoch #1: test_reward: -276.281807 ± 359.375498, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.66it/s, env_step=10000, len=22, loss/actor=-95.780, loss/critic=16.394, n/ep=0, n/st=1, rew=16.86]\n",
      "Epoch #2: test_reward: -87.016559 ± 281.238803, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.03it/s, env_step=15000, len=40, loss/actor=-149.067, loss/critic=23.780, n/ep=0, n/st=1, rew=-8.70]\n",
      "Epoch #3: test_reward: -210.910783 ± 379.201961, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.54it/s, env_step=20000, len=26, loss/actor=-189.582, loss/critic=47.369, n/ep=0, n/st=1, rew=-17.28]\n",
      "Epoch #4: test_reward: -118.140562 ± 298.851840, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.35it/s, env_step=25000, len=110, loss/actor=-226.142, loss/critic=54.916, n/ep=0, n/st=1, rew=-42.20]\n",
      "Epoch #5: test_reward: -101.118227 ± 242.437686, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.73s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1404.68 step/s',\n",
      " 'test_step': 21383,\n",
      " 'test_time': '15.22s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '113.38 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.47s',\n",
      " 'train_time/model': '182.03s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -464.8926824593776, length: 542.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:19:12.953468: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.74it/s, env_step=5000, len=105, loss/actor=-37.454, loss/critic=7.033, n/ep=0, n/st=1, rew=-2.17]\n",
      "Epoch #1: test_reward: -214.999507 ± 441.804973, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.44it/s, env_step=10000, len=1000, loss/actor=-96.564, loss/critic=12.027, n/ep=0, n/st=1, rew=-1038.49]\n",
      "Epoch #2: test_reward: -101.254331 ± 303.801158, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.49it/s, env_step=15000, len=1000, loss/actor=-143.509, loss/critic=18.416, n/ep=0, n/st=1, rew=-903.84]\n",
      "Epoch #3: test_reward: -192.158907 ± 360.173428, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.68it/s, env_step=20000, len=19, loss/actor=-182.673, loss/critic=34.893, n/ep=0, n/st=1, rew=-23.35]\n",
      "Epoch #4: test_reward: -124.977642 ± 307.937833, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.40it/s, env_step=25000, len=29, loss/actor=-217.398, loss/critic=45.666, n/ep=0, n/st=1, rew=4.11]\n",
      "Epoch #5: test_reward: -559.529384 ± 456.528380, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.95s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1518.68 step/s',\n",
      " 'test_step': 24329,\n",
      " 'test_time': '16.02s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '115.24 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.46s',\n",
      " 'train_time/model': '178.47s'}\n",
      "Final reward: -189.02541847138838, length: 267.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:23:34.688537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.29it/s, env_step=5000, len=198, loss/actor=-32.195, loss/critic=4.385, n/ep=0, n/st=1, rew=84.40]\n",
      "Epoch #1: test_reward: -79.028088 ± 267.676151, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.47it/s, env_step=10000, len=1000, loss/actor=-73.575, loss/critic=6.818, n/ep=0, n/st=1, rew=-563.45]\n",
      "Epoch #2: test_reward: -9.605939 ± 28.093309, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.90it/s, env_step=15000, len=44, loss/actor=-105.362, loss/critic=13.741, n/ep=0, n/st=1, rew=3.82]\n",
      "Epoch #3: test_reward: -81.203419 ± 162.629453, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.77it/s, env_step=20000, len=11, loss/actor=-134.211, loss/critic=15.146, n/ep=0, n/st=1, rew=-5.38]\n",
      "Epoch #4: test_reward: -133.678199 ± 211.425396, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.24it/s, env_step=25000, len=14, loss/actor=-170.207, loss/critic=33.394, n/ep=0, n/st=1, rew=-4.69]\n",
      "Epoch #5: test_reward: -130.952095 ± 324.698434, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.78s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1458.81 step/s',\n",
      " 'test_step': 20303,\n",
      " 'test_time': '13.92s',\n",
      " 'train_episode': 72,\n",
      " 'train_speed': '114.23 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.82s',\n",
      " 'train_time/model': '180.04s'}\n",
      "Final reward: -357.33545971859775, length: 451.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:27:57.243186: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.74it/s, env_step=5000, len=135, loss/actor=-35.760, loss/critic=6.027, n/ep=0, n/st=1, rew=-88.85]\n",
      "Epoch #1: test_reward: -289.302844 ± 527.228582, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.47it/s, env_step=10000, len=44, loss/actor=-84.481, loss/critic=13.491, n/ep=0, n/st=1, rew=3.20]\n",
      "Epoch #2: test_reward: -224.068390 ± 463.637805, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.46it/s, env_step=15000, len=59, loss/actor=-125.150, loss/critic=19.556, n/ep=0, n/st=1, rew=-16.40]\n",
      "Epoch #3: test_reward: -175.256958 ± 348.385997, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.15it/s, env_step=20000, len=1000, loss/actor=-160.797, loss/critic=24.056, n/ep=0, n/st=1, rew=-622.86]\n",
      "Epoch #4: test_reward: -384.010283 ± 366.066207, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.19it/s, env_step=25000, len=93, loss/actor=-191.719, loss/critic=30.509, n/ep=0, n/st=1, rew=-62.43]\n",
      "Epoch #5: test_reward: -315.204144 ± 371.351121, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.46s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1605.14 step/s',\n",
      " 'test_step': 27764,\n",
      " 'test_time': '17.30s',\n",
      " 'train_episode': 105,\n",
      " 'train_speed': '112.53 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '182.90s'}\n",
      "Final reward: -199.80650283299343, length: 350.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:32:26.244777: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.66it/s, env_step=5000, len=371, loss/actor=-35.254, loss/critic=6.525, n/ep=0, n/st=1, rew=-108.09]\n",
      "Epoch #1: test_reward: -856.111957 ± 791.711033, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.16it/s, env_step=10000, len=16, loss/actor=-96.179, loss/critic=14.830, n/ep=0, n/st=1, rew=-2.05]\n",
      "Epoch #2: test_reward: -207.450405 ± 399.519769, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.53it/s, env_step=15000, len=54, loss/actor=-162.998, loss/critic=30.231, n/ep=0, n/st=1, rew=-30.74]\n",
      "Epoch #3: test_reward: -24.527436 ± 21.812565, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.29it/s, env_step=20000, len=17, loss/actor=-227.755, loss/critic=41.422, n/ep=0, n/st=1, rew=-15.92]\n",
      "Epoch #4: test_reward: -262.252077 ± 419.794670, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.06it/s, env_step=25000, len=1000, loss/actor=-280.301, loss/critic=72.186, n/ep=0, n/st=1, rew=-1151.08]\n",
      "Epoch #5: test_reward: -183.801038 ± 460.110227, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.70s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1577.05 step/s',\n",
      " 'test_step': 23303,\n",
      " 'test_time': '14.78s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '115.25 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.04s',\n",
      " 'train_time/model': '177.88s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -304.56653404034296, length: 245.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:36:46.465788: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.30it/s, env_step=5000, len=64, loss/actor=-29.928, loss/critic=4.270, n/ep=0, n/st=1, rew=-95.40]\n",
      "Epoch #1: test_reward: -44.229786 ± 224.052931, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.71it/s, env_step=10000, len=1000, loss/actor=-71.895, loss/critic=7.511, n/ep=0, n/st=1, rew=-710.58]\n",
      "Epoch #2: test_reward: -211.974015 ± 321.985784, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.87it/s, env_step=15000, len=36, loss/actor=-111.430, loss/critic=11.843, n/ep=0, n/st=1, rew=-46.31]\n",
      "Epoch #3: test_reward: -164.382123 ± 254.617336, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.71it/s, env_step=20000, len=1000, loss/actor=-142.257, loss/critic=16.964, n/ep=0, n/st=1, rew=-536.77]\n",
      "Epoch #4: test_reward: -57.320303 ± 224.070606, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.11it/s, env_step=25000, len=46, loss/actor=-171.288, loss/critic=31.820, n/ep=0, n/st=1, rew=-55.30]\n",
      "Epoch #5: test_reward: -247.955567 ± 360.572304, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.00s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1525.85 step/s',\n",
      " 'test_step': 23934,\n",
      " 'test_time': '15.69s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '115.04 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.45s',\n",
      " 'train_time/model': '178.87s'}\n",
      "Final reward: -258.1421439269228, length: 360.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:41:08.311096: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.99it/s, env_step=5000, len=81, loss/actor=-32.219, loss/critic=4.827, n/ep=0, n/st=1, rew=18.12]\n",
      "Epoch #1: test_reward: -226.991056 ± 549.841913, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.05it/s, env_step=10000, len=1000, loss/actor=-76.433, loss/critic=7.195, n/ep=0, n/st=1, rew=-675.30]\n",
      "Epoch #2: test_reward: -64.161247 ± 158.263851, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.20it/s, env_step=15000, len=81, loss/actor=-118.293, loss/critic=13.259, n/ep=0, n/st=1, rew=-32.87]\n",
      "Epoch #3: test_reward: -111.329827 ± 210.079773, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.21it/s, env_step=20000, len=54, loss/actor=-148.939, loss/critic=20.817, n/ep=0, n/st=1, rew=33.28]\n",
      "Epoch #4: test_reward: -118.393461 ± 196.600096, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.34it/s, env_step=25000, len=242, loss/actor=-176.931, loss/critic=23.825, n/ep=0, n/st=1, rew=-129.51]\n",
      "Epoch #5: test_reward: -101.026975 ± 252.657149, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1340.00 step/s',\n",
      " 'test_step': 20482,\n",
      " 'test_time': '15.29s',\n",
      " 'train_episode': 88,\n",
      " 'train_speed': '113.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.66s',\n",
      " 'train_time/model': '180.97s'}\n",
      "Final reward: -298.47823402778056, length: 329.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:45:31.991295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.31it/s, env_step=5000, len=61, loss/actor=-35.903, loss/critic=7.049, n/ep=0, n/st=1, rew=-48.58]\n",
      "Epoch #1: test_reward: -258.565985 ± 534.463603, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.01it/s, env_step=10000, len=48, loss/actor=-93.437, loss/critic=15.858, n/ep=0, n/st=1, rew=8.95]\n",
      "Epoch #2: test_reward: -365.104794 ± 428.252784, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.45it/s, env_step=15000, len=27, loss/actor=-139.157, loss/critic=20.128, n/ep=0, n/st=1, rew=-8.06]\n",
      "Epoch #3: test_reward: -629.311203 ± 452.774260, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.59it/s, env_step=20000, len=24, loss/actor=-169.832, loss/critic=26.343, n/ep=0, n/st=1, rew=-9.30]\n",
      "Epoch #4: test_reward: -13.311996 ± 15.904579, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.59it/s, env_step=25000, len=118, loss/actor=-194.444, loss/critic=26.661, n/ep=0, n/st=1, rew=35.58]\n",
      "Epoch #5: test_reward: -149.408323 ± 288.344040, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1730.00 step/s',\n",
      " 'test_step': 28002,\n",
      " 'test_time': '16.19s',\n",
      " 'train_episode': 118,\n",
      " 'train_speed': '115.10 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.62s',\n",
      " 'train_time/model': '178.58s'}\n",
      "Final reward: -86.94395875113705, length: 146.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:49:53.967384: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.20it/s, env_step=5000, len=17, loss/actor=-32.691, loss/critic=4.661, n/ep=0, n/st=1, rew=22.98]\n",
      "Epoch #1: test_reward: -265.731504 ± 441.804683, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.79it/s, env_step=10000, len=12, loss/actor=-80.088, loss/critic=9.797, n/ep=0, n/st=1, rew=-0.45]\n",
      "Epoch #2: test_reward: -308.626544 ± 416.861436, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.64it/s, env_step=15000, len=17, loss/actor=-122.566, loss/critic=16.132, n/ep=0, n/st=1, rew=6.61]\n",
      "Epoch #3: test_reward: -156.637712 ± 229.075085, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.84it/s, env_step=20000, len=25, loss/actor=-159.834, loss/critic=32.188, n/ep=0, n/st=1, rew=-5.80]\n",
      "Epoch #4: test_reward: -215.485372 ± 357.872705, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.06it/s, env_step=25000, len=55, loss/actor=-191.103, loss/critic=32.810, n/ep=0, n/st=1, rew=-9.15]\n",
      "Epoch #5: test_reward: -83.026013 ± 219.948064, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.85s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1513.70 step/s',\n",
      " 'test_step': 25181,\n",
      " 'test_time': '16.64s',\n",
      " 'train_episode': 115,\n",
      " 'train_speed': '113.01 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.70s',\n",
      " 'train_time/model': '182.51s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -22.82428350792596, length: 52.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:54:18.935453: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.86it/s, env_step=5000, len=101, loss/actor=-31.348, loss/critic=5.462, n/ep=0, n/st=1, rew=76.69]\n",
      "Epoch #1: test_reward: -103.238774 ± 451.307988, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.11it/s, env_step=10000, len=98, loss/actor=-79.640, loss/critic=10.142, n/ep=0, n/st=1, rew=11.30]\n",
      "Epoch #2: test_reward: -13.468422 ± 22.000227, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.90it/s, env_step=15000, len=23, loss/actor=-127.708, loss/critic=19.089, n/ep=0, n/st=1, rew=-9.69]\n",
      "Epoch #3: test_reward: -231.320513 ± 313.230096, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.94it/s, env_step=20000, len=871, loss/actor=-170.513, loss/critic=26.885, n/ep=0, n/st=1, rew=-715.30]\n",
      "Epoch #4: test_reward: -314.352537 ± 453.073504, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.65it/s, env_step=25000, len=52, loss/actor=-205.028, loss/critic=42.845, n/ep=0, n/st=1, rew=-24.54]\n",
      "Epoch #5: test_reward: -317.684557 ± 393.838471, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.08s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1633.83 step/s',\n",
      " 'test_step': 24740,\n",
      " 'test_time': '15.14s',\n",
      " 'train_episode': 101,\n",
      " 'train_speed': '114.19 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.65s',\n",
      " 'train_time/model': '180.29s'}\n",
      "Final reward: -133.77841153983664, length: 172.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 11:58:41.745754: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.25it/s, env_step=5000, len=170, loss/actor=-33.157, loss/critic=4.607, n/ep=0, n/st=1, rew=104.21]\n",
      "Epoch #1: test_reward: -346.030935 ± 474.076619, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.25it/s, env_step=10000, len=16, loss/actor=-74.225, loss/critic=8.180, n/ep=0, n/st=1, rew=1.13]\n",
      "Epoch #2: test_reward: -148.359411 ± 274.450270, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.60it/s, env_step=15000, len=1000, loss/actor=-111.408, loss/critic=12.115, n/ep=0, n/st=1, rew=-782.99]\n",
      "Epoch #3: test_reward: -24.180668 ± 78.437334, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.78it/s, env_step=20000, len=67, loss/actor=-140.669, loss/critic=16.829, n/ep=0, n/st=1, rew=8.24]\n",
      "Epoch #4: test_reward: -288.034309 ± 306.521071, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.57it/s, env_step=25000, len=70, loss/actor=-164.546, loss/critic=27.263, n/ep=0, n/st=1, rew=25.39]\n",
      "Epoch #5: test_reward: -98.256348 ± 366.133337, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.88s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1642.28 step/s',\n",
      " 'test_step': 26751,\n",
      " 'test_time': '16.29s',\n",
      " 'train_episode': 130,\n",
      " 'train_speed': '112.82 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.05s',\n",
      " 'train_time/model': '182.54s'}\n",
      "Final reward: -86.96361202281989, length: 213.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:03:08.430756: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.77it/s, env_step=5000, len=1000, loss/actor=-36.163, loss/critic=5.921, n/ep=0, n/st=1, rew=-675.18]\n",
      "Epoch #1: test_reward: -215.644440 ± 398.297570, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.05it/s, env_step=10000, len=464, loss/actor=-103.791, loss/critic=19.633, n/ep=0, n/st=1, rew=-164.13]\n",
      "Epoch #2: test_reward: -134.095838 ± 348.325276, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:41, 119.52it/s, env_step=15000, len=1000, loss/actor=-164.192, loss/critic=28.098, n/ep=0, n/st=1, rew=-608.01]\n",
      "Epoch #3: test_reward: -89.441228 ± 255.025824, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.64it/s, env_step=20000, len=71, loss/actor=-210.492, loss/critic=40.531, n/ep=0, n/st=1, rew=-142.27]\n",
      "Epoch #4: test_reward: -218.855688 ± 414.279216, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.16it/s, env_step=25000, len=56, loss/actor=-231.750, loss/critic=51.927, n/ep=0, n/st=1, rew=-84.33]\n",
      "Epoch #5: test_reward: -199.268417 ± 277.155201, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.93s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1475.99 step/s',\n",
      " 'test_step': 23500,\n",
      " 'test_time': '15.92s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '115.74 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.61s',\n",
      " 'train_time/model': '177.39s'}\n",
      "Final reward: -266.3494121772027, length: 338.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:07:29.530872: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.60it/s, env_step=5000, len=33, loss/actor=-34.731, loss/critic=6.210, n/ep=0, n/st=1, rew=34.15]\n",
      "Epoch #1: test_reward: -451.499096 ± 732.279203, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.06it/s, env_step=10000, len=91, loss/actor=-88.522, loss/critic=10.631, n/ep=0, n/st=1, rew=44.78]\n",
      "Epoch #2: test_reward: -103.534370 ± 278.930578, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.83it/s, env_step=15000, len=63, loss/actor=-133.276, loss/critic=14.426, n/ep=1, n/st=1, rew=7.94]\n",
      "Epoch #3: test_reward: -338.932728 ± 421.901583, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:41, 119.81it/s, env_step=20000, len=43, loss/actor=-172.938, loss/critic=20.220, n/ep=0, n/st=1, rew=-1.86]\n",
      "Epoch #4: test_reward: -98.841800 ± 224.470219, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.42it/s, env_step=25000, len=136, loss/actor=-203.911, loss/critic=37.147, n/ep=0, n/st=1, rew=-118.79]\n",
      "Epoch #5: test_reward: -116.149034 ± 276.443016, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.51s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1505.66 step/s',\n",
      " 'test_step': 24046,\n",
      " 'test_time': '15.97s',\n",
      " 'train_episode': 83,\n",
      " 'train_speed': '114.39 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.84s',\n",
      " 'train_time/model': '179.70s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -110.6183122157726, length: 158.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:11:52.387687: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.51it/s, env_step=5000, len=861, loss/actor=-31.969, loss/critic=5.185, n/ep=0, n/st=1, rew=-475.58]\n",
      "Epoch #1: test_reward: -255.012859 ± 330.629275, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.65it/s, env_step=10000, len=17, loss/actor=-75.117, loss/critic=8.481, n/ep=0, n/st=1, rew=-1.51]\n",
      "Epoch #2: test_reward: -9.062573 ± 26.450920, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.11it/s, env_step=15000, len=28, loss/actor=-110.388, loss/critic=13.014, n/ep=0, n/st=1, rew=8.85]\n",
      "Epoch #3: test_reward: -124.494889 ± 251.050468, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.12it/s, env_step=20000, len=1000, loss/actor=-143.222, loss/critic=18.133, n/ep=0, n/st=1, rew=-777.10]\n",
      "Epoch #4: test_reward: -97.838941 ± 210.723860, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.63it/s, env_step=25000, len=35, loss/actor=-172.748, loss/critic=22.711, n/ep=0, n/st=1, rew=-4.18]\n",
      "Epoch #5: test_reward: -65.688271 ± 178.831934, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.11s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1505.55 step/s',\n",
      " 'test_step': 21325,\n",
      " 'test_time': '14.16s',\n",
      " 'train_episode': 99,\n",
      " 'train_speed': '112.13 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.11s',\n",
      " 'train_time/model': '183.84s'}\n",
      "Final reward: -164.22173310781946, length: 334.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:16:18.642215: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:39, 126.49it/s, env_step=5000, len=43, loss/actor=-37.940, loss/critic=6.598, n/ep=0, n/st=1, rew=25.79]\n",
      "Epoch #1: test_reward: -132.335963 ± 420.921705, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.17it/s, env_step=10000, len=96, loss/actor=-92.417, loss/critic=13.434, n/ep=0, n/st=1, rew=68.82]\n",
      "Epoch #2: test_reward: -146.146543 ± 346.343872, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.03it/s, env_step=15000, len=65, loss/actor=-138.899, loss/critic=22.896, n/ep=0, n/st=1, rew=-22.25]\n",
      "Epoch #3: test_reward: -273.244499 ± 423.396526, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.64it/s, env_step=20000, len=89, loss/actor=-179.547, loss/critic=30.345, n/ep=0, n/st=1, rew=-0.61]\n",
      "Epoch #4: test_reward: -127.384747 ± 297.405652, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.29it/s, env_step=25000, len=1000, loss/actor=-210.383, loss/critic=39.208, n/ep=0, n/st=1, rew=-896.05]\n",
      "Epoch #5: test_reward: -110.518935 ± 224.739592, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.41s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1367.19 step/s',\n",
      " 'test_step': 20617,\n",
      " 'test_time': '15.08s',\n",
      " 'train_episode': 96,\n",
      " 'train_speed': '116.64 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.44s',\n",
      " 'train_time/model': '175.89s'}\n",
      "Final reward: -228.8955756018441, length: 287.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:20:36.881149: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.41it/s, env_step=5000, len=111, loss/actor=-33.420, loss/critic=5.132, n/ep=0, n/st=1, rew=31.62]\n",
      "Epoch #1: test_reward: -105.817610 ± 292.419346, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.11it/s, env_step=10000, len=33, loss/actor=-81.218, loss/critic=11.511, n/ep=0, n/st=1, rew=17.00]\n",
      "Epoch #2: test_reward: -184.626865 ± 370.033980, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.04it/s, env_step=15000, len=15, loss/actor=-127.790, loss/critic=24.104, n/ep=0, n/st=1, rew=-3.15]\n",
      "Epoch #3: test_reward: -23.663692 ± 14.180674, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.04it/s, env_step=20000, len=32, loss/actor=-168.579, loss/critic=29.426, n/ep=0, n/st=1, rew=-24.88]\n",
      "Epoch #4: test_reward: -258.768232 ± 371.814006, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.48it/s, env_step=25000, len=353, loss/actor=-204.954, loss/critic=40.317, n/ep=0, n/st=1, rew=-351.40]\n",
      "Epoch #5: test_reward: -29.904918 ± 26.929446, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.04s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1564.32 step/s',\n",
      " 'test_step': 19123,\n",
      " 'test_time': '12.22s',\n",
      " 'train_episode': 91,\n",
      " 'train_speed': '112.71 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.05s',\n",
      " 'train_time/model': '182.76s'}\n",
      "Final reward: -259.01877270022385, length: 304.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:24:59.980119: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.41it/s, env_step=5000, len=269, loss/actor=-35.049, loss/critic=5.437, n/ep=0, n/st=1, rew=55.93]\n",
      "Epoch #1: test_reward: -275.244357 ± 620.537907, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.17it/s, env_step=10000, len=88, loss/actor=-84.208, loss/critic=10.242, n/ep=0, n/st=1, rew=0.80]\n",
      "Epoch #2: test_reward: -55.535902 ± 287.502856, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.30it/s, env_step=15000, len=1000, loss/actor=-121.460, loss/critic=12.120, n/ep=0, n/st=1, rew=-814.61]\n",
      "Epoch #3: test_reward: -362.093104 ± 422.489198, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.04it/s, env_step=20000, len=1000, loss/actor=-151.953, loss/critic=17.566, n/ep=0, n/st=1, rew=-675.48]\n",
      "Epoch #4: test_reward: -125.523254 ± 230.868012, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.48it/s, env_step=25000, len=149, loss/actor=-181.033, loss/critic=34.084, n/ep=0, n/st=1, rew=-75.67]\n",
      "Epoch #5: test_reward: -273.612988 ± 382.453889, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '241.11s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1506.50 step/s',\n",
      " 'test_step': 25179,\n",
      " 'test_time': '16.71s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '111.41 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.86s',\n",
      " 'train_time/model': '184.54s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -170.80579394260445, length: 247.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:29:29.808732: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.72it/s, env_step=5000, len=115, loss/actor=-31.493, loss/critic=4.058, n/ep=0, n/st=1, rew=82.47]\n",
      "Epoch #1: test_reward: -97.389153 ± 363.895718, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.40it/s, env_step=10000, len=31, loss/actor=-73.357, loss/critic=7.508, n/ep=0, n/st=1, rew=-14.28]\n",
      "Epoch #2: test_reward: -4.299612 ± 11.264139, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.74it/s, env_step=15000, len=1000, loss/actor=-108.269, loss/critic=11.550, n/ep=0, n/st=1, rew=-838.20]\n",
      "Epoch #3: test_reward: -145.476597 ± 275.731567, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.76it/s, env_step=20000, len=60, loss/actor=-138.279, loss/critic=23.176, n/ep=0, n/st=1, rew=8.98]\n",
      "Epoch #4: test_reward: -90.340789 ± 216.543720, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.76it/s, env_step=25000, len=111, loss/actor=-164.736, loss/critic=19.015, n/ep=0, n/st=1, rew=-66.33]\n",
      "Epoch #5: test_reward: -147.669895 ± 214.669866, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1507.73 step/s',\n",
      " 'test_step': 21408,\n",
      " 'test_time': '14.20s',\n",
      " 'train_episode': 115,\n",
      " 'train_speed': '112.02 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.93s',\n",
      " 'train_time/model': '184.24s'}\n",
      "Final reward: -37.08132794907565, length: 156.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:33:54.899342: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.74it/s, env_step=5000, len=99, loss/actor=-32.688, loss/critic=5.193, n/ep=0, n/st=1, rew=9.37]\n",
      "Epoch #1: test_reward: -118.223799 ± 413.794691, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.13it/s, env_step=10000, len=70, loss/actor=-77.772, loss/critic=9.377, n/ep=0, n/st=1, rew=-49.31]\n",
      "Epoch #2: test_reward: -83.625247 ± 211.607535, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.07it/s, env_step=15000, len=1000, loss/actor=-122.909, loss/critic=16.153, n/ep=0, n/st=1, rew=-759.77]\n",
      "Epoch #3: test_reward: -73.425303 ± 192.455660, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:47, 106.29it/s, env_step=20000, len=19, loss/actor=-161.546, loss/critic=20.441, n/ep=0, n/st=1, rew=-19.39]\n",
      "Epoch #4: test_reward: -135.593725 ± 262.490286, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:47, 104.81it/s, env_step=25000, len=27, loss/actor=-190.379, loss/critic=29.185, n/ep=0, n/st=1, rew=-18.91]\n",
      "Epoch #5: test_reward: -132.422544 ± 346.380699, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '243.35s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1363.53 step/s',\n",
      " 'test_step': 20895,\n",
      " 'test_time': '15.32s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '109.64 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.49s',\n",
      " 'train_time/model': '188.54s'}\n",
      "Final reward: -230.78883770772637, length: 464.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:38:28.058829: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.51it/s, env_step=5000, len=107, loss/actor=-33.070, loss/critic=6.888, n/ep=0, n/st=1, rew=6.57]\n",
      "Epoch #1: test_reward: -39.431782 ± 479.006070, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:41, 120.84it/s, env_step=10000, len=411, loss/actor=-86.325, loss/critic=13.837, n/ep=0, n/st=1, rew=-124.02]\n",
      "Epoch #2: test_reward: -109.786517 ± 301.992509, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.77it/s, env_step=15000, len=20, loss/actor=-138.829, loss/critic=22.744, n/ep=0, n/st=1, rew=-0.97]\n",
      "Epoch #3: test_reward: -118.769044 ± 229.754443, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.59it/s, env_step=20000, len=49, loss/actor=-180.912, loss/critic=34.555, n/ep=0, n/st=1, rew=-42.87]\n",
      "Epoch #4: test_reward: -234.846071 ± 399.864964, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.25it/s, env_step=25000, len=1000, loss/actor=-219.036, loss/critic=37.507, n/ep=0, n/st=1, rew=-703.78]\n",
      "Epoch #5: test_reward: -266.227771 ± 370.713861, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.32s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1476.76 step/s',\n",
      " 'test_step': 24114,\n",
      " 'test_time': '16.33s',\n",
      " 'train_episode': 78,\n",
      " 'train_speed': '115.21 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.61s',\n",
      " 'train_time/model': '178.38s'}\n",
      "Final reward: -225.99934555592873, length: 255.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:42:50.270142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.34it/s, env_step=5000, len=150, loss/actor=-31.618, loss/critic=3.825, n/ep=0, n/st=1, rew=46.97]\n",
      "Epoch #1: test_reward: -224.193563 ± 618.297187, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 108.22it/s, env_step=10000, len=150, loss/actor=-74.061, loss/critic=8.081, n/ep=0, n/st=1, rew=44.12]\n",
      "Epoch #2: test_reward: -143.421892 ± 267.970919, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 107.46it/s, env_step=15000, len=8, loss/actor=-109.927, loss/critic=11.894, n/ep=0, n/st=1, rew=-9.86]\n",
      "Epoch #3: test_reward: -85.998589 ± 209.419018, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.38it/s, env_step=20000, len=35, loss/actor=-142.464, loss/critic=19.765, n/ep=0, n/st=1, rew=-18.99]\n",
      "Epoch #4: test_reward: -101.656834 ± 227.832419, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.19it/s, env_step=25000, len=1000, loss/actor=-178.192, loss/critic=29.478, n/ep=0, n/st=1, rew=-979.15]\n",
      "Epoch #5: test_reward: -130.414896 ± 227.010288, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '241.89s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1406.37 step/s',\n",
      " 'test_step': 22175,\n",
      " 'test_time': '15.77s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '110.56 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.90s',\n",
      " 'train_time/model': '186.22s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -248.988836612424, length: 337.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:47:21.275725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.51it/s, env_step=5000, len=63, loss/actor=-33.329, loss/critic=4.347, n/ep=0, n/st=1, rew=0.95]\n",
      "Epoch #1: test_reward: -322.082027 ± 510.484407, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.42it/s, env_step=10000, len=422, loss/actor=-90.640, loss/critic=13.366, n/ep=0, n/st=1, rew=-105.94]\n",
      "Epoch #2: test_reward: -168.502392 ± 376.127354, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 117.20it/s, env_step=15000, len=17, loss/actor=-152.557, loss/critic=26.293, n/ep=0, n/st=1, rew=-17.01]\n",
      "Epoch #3: test_reward: -241.877951 ± 476.874376, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.32it/s, env_step=20000, len=1000, loss/actor=-204.464, loss/critic=32.697, n/ep=0, n/st=1, rew=-1040.10]\n",
      "Epoch #4: test_reward: -190.431273 ± 328.765707, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.28it/s, env_step=25000, len=314, loss/actor=-259.268, loss/critic=57.602, n/ep=0, n/st=1, rew=-206.52]\n",
      "Epoch #5: test_reward: -417.707167 ± 608.224799, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '233.99s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1500.58 step/s',\n",
      " 'test_step': 24421,\n",
      " 'test_time': '16.27s',\n",
      " 'train_episode': 77,\n",
      " 'train_speed': '114.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.86s',\n",
      " 'train_time/model': '178.85s'}\n",
      "Final reward: -549.7991424518044, length: 480.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:51:44.998128: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.44it/s, env_step=5000, len=11, loss/actor=-30.913, loss/critic=4.167, n/ep=0, n/st=1, rew=-3.45]\n",
      "Epoch #1: test_reward: -241.844093 ± 535.067933, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.78it/s, env_step=10000, len=1000, loss/actor=-74.722, loss/critic=7.159, n/ep=0, n/st=1, rew=-931.31]\n",
      "Epoch #2: test_reward: -178.755121 ± 331.352315, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.47it/s, env_step=15000, len=1000, loss/actor=-111.453, loss/critic=13.823, n/ep=0, n/st=1, rew=-592.08]\n",
      "Epoch #3: test_reward: -122.251835 ± 214.595686, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.02it/s, env_step=20000, len=81, loss/actor=-143.646, loss/critic=19.424, n/ep=0, n/st=1, rew=-22.81]\n",
      "Epoch #4: test_reward: -55.643282 ± 171.063108, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.49it/s, env_step=25000, len=101, loss/actor=-171.243, loss/critic=20.829, n/ep=0, n/st=1, rew=-70.99]\n",
      "Epoch #5: test_reward: -263.340956 ± 367.359978, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.23s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1619.55 step/s',\n",
      " 'test_step': 27374,\n",
      " 'test_time': '16.90s',\n",
      " 'train_episode': 106,\n",
      " 'train_speed': '111.94 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.97s',\n",
      " 'train_time/model': '184.35s'}\n",
      "Final reward: -146.08313275316323, length: 212.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 12:56:13.888109: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.43it/s, env_step=5000, len=67, loss/actor=-32.059, loss/critic=4.426, n/ep=0, n/st=1, rew=16.16]\n",
      "Epoch #1: test_reward: -19.726688 ± 301.236971, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.28it/s, env_step=10000, len=57, loss/actor=-73.241, loss/critic=9.879, n/ep=0, n/st=1, rew=52.16]\n",
      "Epoch #2: test_reward: -45.101503 ± 186.578455, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.25it/s, env_step=15000, len=30, loss/actor=-111.589, loss/critic=15.452, n/ep=0, n/st=1, rew=-1.74]\n",
      "Epoch #3: test_reward: 1.257796 ± 13.094663, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 108.98it/s, env_step=20000, len=32, loss/actor=-149.777, loss/critic=29.346, n/ep=0, n/st=1, rew=-6.40]\n",
      "Epoch #4: test_reward: -144.293053 ± 269.918211, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 107.22it/s, env_step=25000, len=1000, loss/actor=-188.141, loss/critic=28.505, n/ep=0, n/st=1, rew=-740.03]\n",
      "Epoch #5: test_reward: -306.545089 ± 353.357337, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '240.21s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1601.82 step/s',\n",
      " 'test_step': 23714,\n",
      " 'test_time': '14.80s',\n",
      " 'train_episode': 97,\n",
      " 'train_speed': '110.91 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.69s',\n",
      " 'train_time/model': '185.72s'}\n",
      "Final reward: -262.11289291324744, length: 357.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:00:43.211095: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.85it/s, env_step=5000, len=1000, loss/actor=-32.547, loss/critic=4.655, n/ep=0, n/st=1, rew=-162.16]\n",
      "Epoch #1: test_reward: -87.344973 ± 270.080707, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.36it/s, env_step=10000, len=118, loss/actor=-86.593, loss/critic=13.341, n/ep=0, n/st=1, rew=19.53]\n",
      "Epoch #2: test_reward: -345.868584 ± 534.669487, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 108.78it/s, env_step=15000, len=61, loss/actor=-139.062, loss/critic=23.605, n/ep=0, n/st=1, rew=-22.55]\n",
      "Epoch #3: test_reward: -319.182146 ± 442.327868, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.39it/s, env_step=20000, len=40, loss/actor=-185.744, loss/critic=30.498, n/ep=0, n/st=1, rew=-33.36]\n",
      "Epoch #4: test_reward: -208.740918 ± 342.473606, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.90it/s, env_step=25000, len=15, loss/actor=-229.180, loss/critic=57.446, n/ep=0, n/st=1, rew=-15.10]\n",
      "Epoch #5: test_reward: -222.666678 ± 386.546564, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.45s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1599.25 step/s',\n",
      " 'test_step': 26517,\n",
      " 'test_time': '16.58s',\n",
      " 'train_episode': 72,\n",
      " 'train_speed': '112.17 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.24s',\n",
      " 'train_time/model': '183.63s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -206.14339235852236, length: 207.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:05:11.403600: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.43it/s, env_step=5000, len=394, loss/actor=-33.575, loss/critic=5.358, n/ep=0, n/st=1, rew=-87.41]\n",
      "Epoch #1: test_reward: -368.764796 ± 505.884928, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:46, 107.18it/s, env_step=10000, len=9, loss/actor=-84.113, loss/critic=11.697, n/ep=0, n/st=1, rew=2.77]\n",
      "Epoch #2: test_reward: -93.299975 ± 252.620728, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.18it/s, env_step=15000, len=1000, loss/actor=-132.781, loss/critic=15.719, n/ep=0, n/st=1, rew=-782.13]\n",
      "Epoch #3: test_reward: -133.190773 ± 260.291051, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.78it/s, env_step=20000, len=64, loss/actor=-172.714, loss/critic=22.702, n/ep=0, n/st=1, rew=-19.32]\n",
      "Epoch #4: test_reward: -20.758591 ± 23.705036, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.71it/s, env_step=25000, len=1000, loss/actor=-209.295, loss/critic=40.458, n/ep=0, n/st=1, rew=-779.52]\n",
      "Epoch #5: test_reward: -483.557847 ± 447.540740, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.52s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1629.04 step/s',\n",
      " 'test_step': 24753,\n",
      " 'test_time': '15.19s',\n",
      " 'train_episode': 70,\n",
      " 'train_speed': '111.94 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.42s',\n",
      " 'train_time/model': '183.91s'}\n",
      "Final reward: -205.18458385964828, length: 262.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:09:38.616511: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.69it/s, env_step=5000, len=241, loss/actor=-33.205, loss/critic=4.611, n/ep=0, n/st=1, rew=51.71]\n",
      "Epoch #1: test_reward: -136.062150 ± 341.883259, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.70it/s, env_step=10000, len=642, loss/actor=-80.810, loss/critic=10.104, n/ep=0, n/st=1, rew=-307.16]\n",
      "Epoch #2: test_reward: -123.541609 ± 284.963211, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.64it/s, env_step=15000, len=30, loss/actor=-128.108, loss/critic=17.434, n/ep=0, n/st=1, rew=10.53]\n",
      "Epoch #3: test_reward: -213.309497 ± 319.383170, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.35it/s, env_step=20000, len=31, loss/actor=-169.579, loss/critic=23.330, n/ep=0, n/st=1, rew=1.72]\n",
      "Epoch #4: test_reward: -118.199671 ± 263.702435, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.32it/s, env_step=25000, len=48, loss/actor=-209.859, loss/critic=50.532, n/ep=0, n/st=1, rew=-42.84]\n",
      "Epoch #5: test_reward: -218.238924 ± 325.572632, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.95s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1433.34 step/s',\n",
      " 'test_step': 21830,\n",
      " 'test_time': '15.23s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '114.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.67s',\n",
      " 'train_time/model': '179.05s'}\n",
      "Final reward: -116.86681189653866, length: 139.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:13:59.973767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.42it/s, env_step=5000, len=16, loss/actor=-33.430, loss/critic=5.824, n/ep=0, n/st=1, rew=-6.00]\n",
      "Epoch #1: test_reward: -226.889393 ± 493.970856, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.79it/s, env_step=10000, len=25, loss/actor=-88.742, loss/critic=14.407, n/ep=0, n/st=1, rew=-8.10]\n",
      "Epoch #2: test_reward: -165.966032 ± 390.216839, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.62it/s, env_step=15000, len=50, loss/actor=-135.581, loss/critic=16.548, n/ep=0, n/st=1, rew=14.70]\n",
      "Epoch #3: test_reward: -18.065070 ± 46.091427, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.13it/s, env_step=20000, len=65, loss/actor=-173.827, loss/critic=30.088, n/ep=0, n/st=1, rew=0.29]\n",
      "Epoch #4: test_reward: -233.829997 ± 342.676462, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 116.05it/s, env_step=25000, len=163, loss/actor=-206.101, loss/critic=34.146, n/ep=0, n/st=1, rew=-23.70]\n",
      "Epoch #5: test_reward: -24.496261 ± 34.396369, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.92s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1546.38 step/s',\n",
      " 'test_step': 18890,\n",
      " 'test_time': '12.22s',\n",
      " 'train_episode': 122,\n",
      " 'train_speed': '113.27 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.66s',\n",
      " 'train_time/model': '182.05s'}\n",
      "Final reward: -27.181233950445197, length: 63.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:18:19.773165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.48it/s, env_step=5000, len=1000, loss/actor=-34.775, loss/critic=5.409, n/ep=0, n/st=1, rew=-167.13]\n",
      "Epoch #1: test_reward: -392.501485 ± 435.008794, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.03it/s, env_step=10000, len=26, loss/actor=-90.871, loss/critic=12.037, n/ep=0, n/st=1, rew=-20.30]\n",
      "Epoch #2: test_reward: -124.560545 ± 247.174624, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.59it/s, env_step=15000, len=1000, loss/actor=-138.267, loss/critic=15.678, n/ep=0, n/st=1, rew=-585.16]\n",
      "Epoch #3: test_reward: -161.530735 ± 211.893422, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.13it/s, env_step=20000, len=39, loss/actor=-176.521, loss/critic=26.250, n/ep=0, n/st=1, rew=11.65]\n",
      "Epoch #4: test_reward: -22.885129 ± 31.313509, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.20it/s, env_step=25000, len=139, loss/actor=-205.223, loss/critic=33.494, n/ep=0, n/st=1, rew=-94.24]\n",
      "Epoch #5: test_reward: -172.181613 ± 282.922996, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.24s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1624.10 step/s',\n",
      " 'test_step': 24185,\n",
      " 'test_time': '14.89s',\n",
      " 'train_episode': 75,\n",
      " 'train_speed': '115.02 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.59s',\n",
      " 'train_time/model': '178.76s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -173.19667855717498, length: 245.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:22:40.681182: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.35it/s, env_step=5000, len=1000, loss/actor=-32.534, loss/critic=6.099, n/ep=0, n/st=1, rew=-732.02]\n",
      "Epoch #1: test_reward: -269.626506 ± 441.450809, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.37it/s, env_step=10000, len=59, loss/actor=-95.166, loss/critic=15.875, n/ep=0, n/st=1, rew=-39.56]\n",
      "Epoch #2: test_reward: -322.527455 ± 474.412746, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.29it/s, env_step=15000, len=1000, loss/actor=-151.764, loss/critic=23.986, n/ep=0, n/st=1, rew=-1223.31]\n",
      "Epoch #3: test_reward: -95.643724 ± 212.647794, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.72it/s, env_step=20000, len=46, loss/actor=-197.379, loss/critic=35.365, n/ep=0, n/st=1, rew=4.74]\n",
      "Epoch #4: test_reward: -115.673172 ± 237.913306, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.50it/s, env_step=25000, len=57, loss/actor=-238.268, loss/critic=51.347, n/ep=0, n/st=1, rew=-25.74]\n",
      "Epoch #5: test_reward: -142.680135 ± 247.076646, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.53s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1446.52 step/s',\n",
      " 'test_step': 22635,\n",
      " 'test_time': '15.65s',\n",
      " 'train_episode': 84,\n",
      " 'train_speed': '113.18 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.99s',\n",
      " 'train_time/model': '181.89s'}\n",
      "Final reward: -131.90117842787072, length: 135.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:27:05.747150: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 116.00it/s, env_step=5000, len=51, loss/actor=-32.292, loss/critic=4.029, n/ep=0, n/st=1, rew=29.67]\n",
      "Epoch #1: test_reward: -84.391231 ± 355.980086, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.32it/s, env_step=10000, len=1000, loss/actor=-74.161, loss/critic=7.289, n/ep=0, n/st=1, rew=-702.38]\n",
      "Epoch #2: test_reward: -157.901949 ± 323.812655, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.82it/s, env_step=15000, len=1000, loss/actor=-111.516, loss/critic=11.375, n/ep=0, n/st=1, rew=-770.12]\n",
      "Epoch #3: test_reward: -224.775846 ± 330.852764, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.46it/s, env_step=20000, len=126, loss/actor=-141.389, loss/critic=15.238, n/ep=0, n/st=1, rew=-53.59]\n",
      "Epoch #4: test_reward: -68.710283 ± 171.901425, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.62it/s, env_step=25000, len=119, loss/actor=-159.921, loss/critic=16.517, n/ep=0, n/st=1, rew=-33.04]\n",
      "Epoch #5: test_reward: -189.245166 ± 276.041405, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.38s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1518.54 step/s',\n",
      " 'test_step': 24558,\n",
      " 'test_time': '16.17s',\n",
      " 'train_episode': 63,\n",
      " 'train_speed': '116.17 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.45s',\n",
      " 'train_time/model': '176.75s'}\n",
      "Final reward: -160.52752197092786, length: 262.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:31:26.131964: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.78it/s, env_step=5000, len=158, loss/actor=-30.360, loss/critic=4.596, n/ep=0, n/st=1, rew=88.28]\n",
      "Epoch #1: test_reward: -266.452032 ± 358.584528, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.59it/s, env_step=10000, len=1000, loss/actor=-75.094, loss/critic=8.864, n/ep=0, n/st=1, rew=-871.09]\n",
      "Epoch #2: test_reward: -187.488989 ± 279.556107, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.67it/s, env_step=15000, len=22, loss/actor=-112.429, loss/critic=14.274, n/ep=0, n/st=1, rew=-29.69]\n",
      "Epoch #3: test_reward: -40.589669 ± 127.488858, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.81it/s, env_step=20000, len=59, loss/actor=-136.927, loss/critic=15.212, n/ep=0, n/st=1, rew=8.02]\n",
      "Epoch #4: test_reward: -594.362950 ± 385.305898, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.91it/s, env_step=25000, len=64, loss/actor=-157.271, loss/critic=25.318, n/ep=0, n/st=1, rew=19.16]\n",
      "Epoch #5: test_reward: -118.470145 ± 179.852428, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.09s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1640.29 step/s',\n",
      " 'test_step': 29176,\n",
      " 'test_time': '17.79s',\n",
      " 'train_episode': 88,\n",
      " 'train_speed': '114.00 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.13s',\n",
      " 'train_time/model': '180.17s'}\n",
      "Final reward: -26.186045691730044, length: 55.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:35:50.269369: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.87it/s, env_step=5000, len=182, loss/actor=-35.173, loss/critic=5.437, n/ep=0, n/st=1, rew=-123.04]\n",
      "Epoch #1: test_reward: -77.575025 ± 408.145439, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.64it/s, env_step=10000, len=22, loss/actor=-84.256, loss/critic=10.856, n/ep=0, n/st=1, rew=-13.44]\n",
      "Epoch #2: test_reward: -20.131875 ± 46.335581, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.31it/s, env_step=15000, len=129, loss/actor=-122.205, loss/critic=14.215, n/ep=0, n/st=1, rew=-56.76]\n",
      "Epoch #3: test_reward: -101.584753 ± 265.976361, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.19it/s, env_step=20000, len=59, loss/actor=-154.609, loss/critic=26.099, n/ep=0, n/st=1, rew=-34.07]\n",
      "Epoch #4: test_reward: -245.666884 ± 402.121356, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.81it/s, env_step=25000, len=16, loss/actor=-186.500, loss/critic=29.325, n/ep=0, n/st=1, rew=-13.46]\n",
      "Epoch #5: test_reward: -120.539719 ± 278.067977, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.67s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1427.60 step/s',\n",
      " 'test_step': 19310,\n",
      " 'test_time': '13.53s',\n",
      " 'train_episode': 71,\n",
      " 'train_speed': '114.08 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.01s',\n",
      " 'train_time/model': '180.14s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -140.4220124072005, length: 184.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:40:12.167391: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.29it/s, env_step=5000, len=1000, loss/actor=-34.623, loss/critic=5.676, n/ep=0, n/st=1, rew=198.21]\n",
      "Epoch #1: test_reward: -151.556469 ± 467.853153, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.05it/s, env_step=10000, len=23, loss/actor=-92.808, loss/critic=11.223, n/ep=0, n/st=1, rew=-15.40]\n",
      "Epoch #2: test_reward: -130.255745 ± 306.237746, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.99it/s, env_step=15000, len=1000, loss/actor=-145.483, loss/critic=16.365, n/ep=0, n/st=1, rew=-793.31]\n",
      "Epoch #3: test_reward: -23.751595 ± 11.732302, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.39it/s, env_step=20000, len=44, loss/actor=-197.739, loss/critic=38.340, n/ep=0, n/st=1, rew=-24.42]\n",
      "Epoch #4: test_reward: -364.047514 ± 496.448103, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.59it/s, env_step=25000, len=14, loss/actor=-241.676, loss/critic=49.656, n/ep=0, n/st=1, rew=1.62]\n",
      "Epoch #5: test_reward: -488.723648 ± 592.567786, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.41s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1616.00 step/s',\n",
      " 'test_step': 25079,\n",
      " 'test_time': '15.52s',\n",
      " 'train_episode': 79,\n",
      " 'train_speed': '113.18 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.73s',\n",
      " 'train_time/model': '181.16s'}\n",
      "Final reward: -245.21437273557802, length: 291.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:44:37.819983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.61it/s, env_step=5000, len=594, loss/actor=-34.068, loss/critic=4.334, n/ep=0, n/st=1, rew=152.85]\n",
      "Epoch #1: test_reward: -517.057678 ± 763.188319, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.08it/s, env_step=10000, len=1000, loss/actor=-81.554, loss/critic=8.958, n/ep=0, n/st=1, rew=-615.30]\n",
      "Epoch #2: test_reward: -153.919343 ± 282.729602, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.63it/s, env_step=15000, len=462, loss/actor=-124.269, loss/critic=13.013, n/ep=0, n/st=1, rew=-330.00]\n",
      "Epoch #3: test_reward: -244.453889 ± 310.636867, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:41, 119.56it/s, env_step=20000, len=1000, loss/actor=-161.034, loss/critic=22.854, n/ep=0, n/st=1, rew=-700.18]\n",
      "Epoch #4: test_reward: -94.977962 ± 204.743204, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.59it/s, env_step=25000, len=15, loss/actor=-204.041, loss/critic=34.632, n/ep=0, n/st=1, rew=-15.14]\n",
      "Epoch #5: test_reward: -108.215987 ± 263.335379, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.21s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1413.29 step/s',\n",
      " 'test_step': 22837,\n",
      " 'test_time': '16.16s',\n",
      " 'train_episode': 82,\n",
      " 'train_speed': '116.80 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.09s',\n",
      " 'train_time/model': '174.96s'}\n",
      "Final reward: -343.396384718471, length: 377.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:48:57.498918: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.30it/s, env_step=5000, len=62, loss/actor=-31.682, loss/critic=3.843, n/ep=0, n/st=1, rew=36.51]\n",
      "Epoch #1: test_reward: -124.708341 ± 294.448497, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.43it/s, env_step=10000, len=152, loss/actor=-67.990, loss/critic=5.540, n/ep=0, n/st=1, rew=-85.71]\n",
      "Epoch #2: test_reward: -118.711024 ± 169.628615, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.45it/s, env_step=15000, len=19, loss/actor=-97.413, loss/critic=10.776, n/ep=0, n/st=1, rew=-4.19]\n",
      "Epoch #3: test_reward: -214.916475 ± 384.258545, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.67it/s, env_step=20000, len=1000, loss/actor=-121.884, loss/critic=9.297, n/ep=0, n/st=1, rew=-525.83]\n",
      "Epoch #4: test_reward: -81.975340 ± 154.424532, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.38it/s, env_step=25000, len=1000, loss/actor=-143.063, loss/critic=14.672, n/ep=0, n/st=1, rew=-476.49]\n",
      "Epoch #5: test_reward: -148.217128 ± 202.423991, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.23s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1585.92 step/s',\n",
      " 'test_step': 27572,\n",
      " 'test_time': '17.39s',\n",
      " 'train_episode': 85,\n",
      " 'train_speed': '114.76 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.77s',\n",
      " 'train_time/model': '179.08s'}\n",
      "Final reward: -23.234819187731077, length: 62.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:53:19.857108: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.97it/s, env_step=5000, len=1000, loss/actor=-32.878, loss/critic=4.311, n/ep=0, n/st=1, rew=-695.61]\n",
      "Epoch #1: test_reward: 84.343861 ± 402.814058, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.28it/s, env_step=10000, len=20, loss/actor=-78.022, loss/critic=8.117, n/ep=0, n/st=1, rew=-16.59]\n",
      "Epoch #2: test_reward: -81.386424 ± 228.274141, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.62it/s, env_step=15000, len=28, loss/actor=-112.240, loss/critic=11.746, n/ep=0, n/st=1, rew=-6.42]\n",
      "Epoch #3: test_reward: -80.802482 ± 180.767708, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.65it/s, env_step=20000, len=75, loss/actor=-136.095, loss/critic=19.227, n/ep=0, n/st=1, rew=-18.44]\n",
      "Epoch #4: test_reward: -175.437081 ± 250.986104, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.66it/s, env_step=25000, len=1000, loss/actor=-156.743, loss/critic=21.226, n/ep=0, n/st=1, rew=-652.42]\n",
      "Epoch #5: test_reward: -245.376243 ± 295.577401, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.62s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1527.64 step/s',\n",
      " 'test_step': 26167,\n",
      " 'test_time': '17.13s',\n",
      " 'train_episode': 74,\n",
      " 'train_speed': '112.36 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.66s',\n",
      " 'train_time/model': '182.83s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -128.33466844737285, length: 332.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 13:57:48.482990: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.42it/s, env_step=5000, len=238, loss/actor=-31.980, loss/critic=4.822, n/ep=0, n/st=1, rew=-6.85]\n",
      "Epoch #1: test_reward: 162.739485 ± 256.600564, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.87it/s, env_step=10000, len=68, loss/actor=-81.884, loss/critic=12.678, n/ep=0, n/st=1, rew=-26.67]\n",
      "Epoch #2: test_reward: -283.757110 ± 413.094911, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.76it/s, env_step=15000, len=1000, loss/actor=-123.101, loss/critic=18.594, n/ep=0, n/st=1, rew=-703.03]\n",
      "Epoch #3: test_reward: -173.270577 ± 307.829493, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.52it/s, env_step=20000, len=23, loss/actor=-162.250, loss/critic=26.113, n/ep=0, n/st=1, rew=-6.74]\n",
      "Epoch #4: test_reward: -194.157076 ± 308.317849, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.12it/s, env_step=25000, len=356, loss/actor=-198.573, loss/critic=38.849, n/ep=0, n/st=1, rew=-221.49]\n",
      "Epoch #5: test_reward: -326.930828 ± 452.026765, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.53s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1541.72 step/s',\n",
      " 'test_step': 25684,\n",
      " 'test_time': '16.66s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '112.68 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.25s',\n",
      " 'train_time/model': '182.62s'}\n",
      "Final reward: -241.93430808932786, length: 246.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:02:15.812016: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.73it/s, env_step=5000, len=1000, loss/actor=-32.485, loss/critic=5.334, n/ep=0, n/st=1, rew=181.38]\n",
      "Epoch #1: test_reward: -174.454393 ± 349.705260, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.22it/s, env_step=10000, len=1000, loss/actor=-84.791, loss/critic=13.145, n/ep=0, n/st=1, rew=-957.99]\n",
      "Epoch #2: test_reward: -160.099463 ± 416.256468, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.96it/s, env_step=15000, len=1000, loss/actor=-128.224, loss/critic=19.895, n/ep=0, n/st=1, rew=-570.18]\n",
      "Epoch #3: test_reward: -269.840430 ± 321.064733, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.50it/s, env_step=20000, len=13, loss/actor=-167.203, loss/critic=31.886, n/ep=0, n/st=1, rew=-13.07]\n",
      "Epoch #4: test_reward: -219.796041 ± 368.612780, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:46, 108.69it/s, env_step=25000, len=1000, loss/actor=-211.503, loss/critic=37.474, n/ep=0, n/st=1, rew=-921.97]\n",
      "Epoch #5: test_reward: -258.772712 ± 387.944641, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.91s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1481.38 step/s',\n",
      " 'test_step': 23890,\n",
      " 'test_time': '16.13s',\n",
      " 'train_episode': 66,\n",
      " 'train_speed': '111.71 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '184.53s'}\n",
      "Final reward: -238.05498478720293, length: 239.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_070305-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:06:44.459719: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.58it/s, env_step=5000, len=129, loss/actor=-33.331, loss/critic=5.072, n/ep=0, n/st=1, rew=85.42]\n",
      "Epoch #1: test_reward: 77.475308 ± 129.777382, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.18it/s, env_step=10000, len=118, loss/actor=-79.064, loss/critic=9.079, n/ep=0, n/st=1, rew=-62.72]\n",
      "Epoch #2: test_reward: -340.687686 ± 341.851292, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.66it/s, env_step=15000, len=62, loss/actor=-120.508, loss/critic=16.266, n/ep=0, n/st=1, rew=-31.97]\n",
      "Epoch #3: test_reward: -166.256529 ± 307.365196, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.54it/s, env_step=20000, len=1000, loss/actor=-156.227, loss/critic=22.344, n/ep=0, n/st=1, rew=-738.05]\n",
      "Epoch #4: test_reward: -168.125965 ± 294.131435, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.46it/s, env_step=25000, len=171, loss/actor=-196.101, loss/critic=37.923, n/ep=0, n/st=1, rew=-61.30]\n",
      "Epoch #5: test_reward: -297.166684 ± 431.995143, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.81s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1564.77 step/s',\n",
      " 'test_step': 26299,\n",
      " 'test_time': '16.81s',\n",
      " 'train_episode': 94,\n",
      " 'train_speed': '112.61 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.87s',\n",
      " 'train_time/model': '183.13s'}\n",
      "Final reward: -282.9871658473493, length: 357.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:11:12.678768: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.40it/s, env_step=5000, len=132, loss/actor=-30.721, loss/critic=4.407, n/ep=1, n/st=1, rew=6.45]\n",
      "Epoch #1: test_reward: -141.771734 ± 264.056086, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.50it/s, env_step=10000, len=49, loss/actor=-72.074, loss/critic=9.278, n/ep=0, n/st=1, rew=-22.94]\n",
      "Epoch #2: test_reward: -87.401816 ± 226.308128, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 116.28it/s, env_step=15000, len=1000, loss/actor=-108.646, loss/critic=12.490, n/ep=0, n/st=1, rew=-669.81]\n",
      "Epoch #3: test_reward: -16.615477 ± 16.300601, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.12it/s, env_step=20000, len=25, loss/actor=-142.328, loss/critic=23.337, n/ep=0, n/st=1, rew=9.02]\n",
      "Epoch #4: test_reward: -21.716595 ± 24.763978, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.30it/s, env_step=25000, len=89, loss/actor=-176.773, loss/critic=48.959, n/ep=0, n/st=1, rew=-90.57]\n",
      "Epoch #5: test_reward: -112.039364 ± 258.747221, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.12s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1549.66 step/s',\n",
      " 'test_step': 18333,\n",
      " 'test_time': '11.83s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '115.05 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.48s',\n",
      " 'train_time/model': '178.81s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -74.30874933948101, length: 101.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:15:29.619018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.23it/s, env_step=5000, len=549, loss/actor=-36.122, loss/critic=6.257, n/ep=0, n/st=1, rew=-76.72]\n",
      "Epoch #1: test_reward: -253.376999 ± 438.866577, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.62it/s, env_step=10000, len=1000, loss/actor=-94.618, loss/critic=11.826, n/ep=0, n/st=1, rew=-1208.81]\n",
      "Epoch #2: test_reward: -75.454954 ± 200.564439, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.19it/s, env_step=15000, len=1000, loss/actor=-143.435, loss/critic=21.445, n/ep=0, n/st=1, rew=-968.50]\n",
      "Epoch #3: test_reward: -82.094114 ± 194.334300, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.67it/s, env_step=20000, len=1000, loss/actor=-187.836, loss/critic=29.647, n/ep=0, n/st=1, rew=-876.70]\n",
      "Epoch #4: test_reward: -111.050946 ± 255.049246, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.93it/s, env_step=25000, len=1000, loss/actor=-226.631, loss/critic=40.799, n/ep=0, n/st=1, rew=-793.20]\n",
      "Epoch #5: test_reward: -32.131664 ± 28.032511, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.85s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1432.19 step/s',\n",
      " 'test_step': 20001,\n",
      " 'test_time': '13.97s',\n",
      " 'train_episode': 111,\n",
      " 'train_speed': '112.67 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.44s',\n",
      " 'train_time/model': '182.45s'}\n",
      "Final reward: -108.60097687936282, length: 170.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:19:54.608339: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 121.16it/s, env_step=5000, len=202, loss/actor=-30.812, loss/critic=3.969, n/ep=0, n/st=1, rew=70.61]\n",
      "Epoch #1: test_reward: -108.038801 ± 290.500204, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.82it/s, env_step=10000, len=49, loss/actor=-76.610, loss/critic=8.377, n/ep=0, n/st=1, rew=-19.95]\n",
      "Epoch #2: test_reward: -123.166379 ± 180.039786, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.98it/s, env_step=15000, len=193, loss/actor=-118.536, loss/critic=18.309, n/ep=0, n/st=1, rew=17.26]\n",
      "Epoch #3: test_reward: -242.092641 ± 411.453079, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.05it/s, env_step=20000, len=62, loss/actor=-150.433, loss/critic=19.413, n/ep=0, n/st=1, rew=-15.41]\n",
      "Epoch #4: test_reward: -113.645738 ± 183.762204, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.77it/s, env_step=25000, len=106, loss/actor=-174.313, loss/critic=28.270, n/ep=0, n/st=1, rew=-81.65]\n",
      "Epoch #5: test_reward: -208.051030 ± 227.625807, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.93s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1575.82 step/s',\n",
      " 'test_step': 27759,\n",
      " 'test_time': '17.62s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '116.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.09s',\n",
      " 'train_time/model': '175.22s'}\n",
      "Final reward: -368.9349919910324, length: 443.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:24:15.805486: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 110.49it/s, env_step=5000, len=35, loss/actor=-30.020, loss/critic=3.521, n/ep=0, n/st=1, rew=26.27]\n",
      "Epoch #1: test_reward: -184.155055 ± 336.982761, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.35it/s, env_step=10000, len=73, loss/actor=-69.130, loss/critic=6.463, n/ep=0, n/st=1, rew=48.22]\n",
      "Epoch #2: test_reward: -101.492582 ± 199.649825, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.03it/s, env_step=15000, len=16, loss/actor=-102.759, loss/critic=8.145, n/ep=0, n/st=1, rew=-10.49]\n",
      "Epoch #3: test_reward: -155.484905 ± 216.110763, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.49it/s, env_step=20000, len=1000, loss/actor=-130.714, loss/critic=13.263, n/ep=0, n/st=1, rew=-489.70]\n",
      "Epoch #4: test_reward: -194.057816 ± 338.994138, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.31it/s, env_step=25000, len=253, loss/actor=-156.327, loss/critic=26.115, n/ep=0, n/st=1, rew=-127.38]\n",
      "Epoch #5: test_reward: -123.484446 ± 197.076369, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.74s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1559.63 step/s',\n",
      " 'test_step': 25830,\n",
      " 'test_time': '16.56s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '113.03 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.59s',\n",
      " 'train_time/model': '181.59s'}\n",
      "Final reward: -318.3539304488215, length: 538.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:28:43.212113: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.21it/s, env_step=5000, len=15, loss/actor=-32.103, loss/critic=4.054, n/ep=0, n/st=1, rew=-35.86]\n",
      "Epoch #1: test_reward: -385.046375 ± 590.091811, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 111.02it/s, env_step=10000, len=1000, loss/actor=-71.724, loss/critic=6.222, n/ep=0, n/st=1, rew=-686.39]\n",
      "Epoch #2: test_reward: -126.674180 ± 224.840501, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:46, 107.04it/s, env_step=15000, len=21, loss/actor=-107.019, loss/critic=14.732, n/ep=0, n/st=1, rew=-31.25]\n",
      "Epoch #3: test_reward: -129.206662 ± 206.965517, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.73it/s, env_step=20000, len=42, loss/actor=-137.833, loss/critic=19.234, n/ep=0, n/st=1, rew=-18.44]\n",
      "Epoch #4: test_reward: -148.226761 ± 256.134387, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.53it/s, env_step=25000, len=32, loss/actor=-163.687, loss/critic=26.619, n/ep=0, n/st=1, rew=-5.39]\n",
      "Epoch #5: test_reward: -320.843458 ± 356.675016, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '237.88s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1524.71 step/s',\n",
      " 'test_step': 24612,\n",
      " 'test_time': '16.14s',\n",
      " 'train_episode': 64,\n",
      " 'train_speed': '112.75 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.20s',\n",
      " 'train_time/model': '182.54s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -293.15249076805446, length: 527.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:33:10.769326: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.11it/s, env_step=5000, len=348, loss/actor=-37.217, loss/critic=6.526, n/ep=0, n/st=1, rew=70.26]\n",
      "Epoch #1: test_reward: 44.396356 ± 88.579673, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 116.62it/s, env_step=10000, len=30, loss/actor=-87.124, loss/critic=11.697, n/ep=0, n/st=1, rew=-4.50]\n",
      "Epoch #2: test_reward: -74.774285 ± 236.988178, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.50it/s, env_step=15000, len=79, loss/actor=-127.113, loss/critic=18.046, n/ep=0, n/st=1, rew=18.30]\n",
      "Epoch #3: test_reward: -329.639053 ± 326.933011, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.47it/s, env_step=20000, len=57, loss/actor=-162.004, loss/critic=26.963, n/ep=0, n/st=1, rew=-6.32]\n",
      "Epoch #4: test_reward: -272.463290 ± 406.724992, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.44it/s, env_step=25000, len=170, loss/actor=-184.829, loss/critic=39.566, n/ep=0, n/st=1, rew=-22.73]\n",
      "Epoch #5: test_reward: -177.550065 ± 255.479426, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.60s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1543.63 step/s',\n",
      " 'test_step': 24545,\n",
      " 'test_time': '15.90s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '114.31 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.90s',\n",
      " 'train_time/model': '179.80s'}\n",
      "Final reward: -266.40548714778373, length: 525.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:37:35.190810: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.11it/s, env_step=5000, len=351, loss/actor=-32.268, loss/critic=4.578, n/ep=0, n/st=1, rew=-189.20]\n",
      "Epoch #1: test_reward: -369.803872 ± 485.371506, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.50it/s, env_step=10000, len=76, loss/actor=-84.311, loss/critic=11.207, n/ep=0, n/st=1, rew=-27.20]\n",
      "Epoch #2: test_reward: -4.538179 ± 27.975717, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.83it/s, env_step=15000, len=25, loss/actor=-133.914, loss/critic=18.816, n/ep=0, n/st=1, rew=-10.58]\n",
      "Epoch #3: test_reward: -104.242275 ± 253.433671, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 116.47it/s, env_step=20000, len=55, loss/actor=-198.012, loss/critic=54.746, n/ep=0, n/st=1, rew=-25.89]\n",
      "Epoch #4: test_reward: -304.010780 ± 428.093947, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 119.08it/s, env_step=25000, len=22, loss/actor=-281.960, loss/critic=103.125, n/ep=0, n/st=1, rew=-13.64]\n",
      "Epoch #5: test_reward: -185.581957 ± 378.474989, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.32s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1593.91 step/s',\n",
      " 'test_step': 23947,\n",
      " 'test_time': '15.02s',\n",
      " 'train_episode': 86,\n",
      " 'train_speed': '116.12 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.01s',\n",
      " 'train_time/model': '176.28s'}\n",
      "Final reward: -165.8361021694855, length: 141.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:41:53.948071: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.86it/s, env_step=5000, len=60, loss/actor=-34.008, loss/critic=4.816, n/ep=0, n/st=1, rew=7.38]\n",
      "Epoch #1: test_reward: -334.762860 ± 463.525524, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.41it/s, env_step=10000, len=23, loss/actor=-79.243, loss/critic=11.715, n/ep=0, n/st=1, rew=-2.68]\n",
      "Epoch #2: test_reward: -355.366095 ± 434.153935, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 108.99it/s, env_step=15000, len=31, loss/actor=-118.964, loss/critic=10.312, n/ep=0, n/st=1, rew=-6.25]\n",
      "Epoch #3: test_reward: -123.923821 ± 264.885536, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.74it/s, env_step=20000, len=110, loss/actor=-159.493, loss/critic=37.389, n/ep=0, n/st=1, rew=-10.05]\n",
      "Epoch #4: test_reward: -77.477815 ± 199.951676, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 113.59it/s, env_step=25000, len=78, loss/actor=-186.608, loss/critic=44.046, n/ep=0, n/st=1, rew=-8.65]\n",
      "Epoch #5: test_reward: -163.126966 ± 277.304333, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '239.41s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1533.70 step/s',\n",
      " 'test_step': 25526,\n",
      " 'test_time': '16.64s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '112.22 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.25s',\n",
      " 'train_time/model': '183.52s'}\n",
      "Final reward: -181.8698293306639, length: 281.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:46:22.355004: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.45it/s, env_step=5000, len=1000, loss/actor=-32.236, loss/critic=5.149, n/ep=0, n/st=1, rew=-248.55]\n",
      "Epoch #1: test_reward: -129.530036 ± 258.887082, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.04it/s, env_step=10000, len=38, loss/actor=-92.492, loss/critic=19.231, n/ep=0, n/st=1, rew=-8.04]\n",
      "Epoch #2: test_reward: -5.943989 ± 15.489778, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.09it/s, env_step=15000, len=23, loss/actor=-145.965, loss/critic=38.517, n/ep=0, n/st=1, rew=19.98]\n",
      "Epoch #3: test_reward: -400.326530 ± 640.307254, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.74it/s, env_step=20000, len=28, loss/actor=-186.767, loss/critic=40.382, n/ep=0, n/st=1, rew=-25.20]\n",
      "Epoch #4: test_reward: -383.036845 ± 433.630493, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 119.59it/s, env_step=25000, len=23, loss/actor=-222.392, loss/critic=63.983, n/ep=1, n/st=1, rew=-3.06]\n",
      "Epoch #5: test_reward: -398.308038 ± 604.212248, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.79s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1606.20 step/s',\n",
      " 'test_step': 23613,\n",
      " 'test_time': '14.70s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '115.69 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.48s',\n",
      " 'train_time/model': '177.61s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -32.81703644696539, length: 70.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:50:40.022960: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.54it/s, env_step=5000, len=68, loss/actor=-34.668, loss/critic=6.293, n/ep=0, n/st=1, rew=11.95]\n",
      "Epoch #1: test_reward: -147.009266 ± 437.749481, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.31it/s, env_step=10000, len=205, loss/actor=-86.858, loss/critic=10.740, n/ep=0, n/st=1, rew=-30.07]\n",
      "Epoch #2: test_reward: -97.616599 ± 220.866447, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.90it/s, env_step=15000, len=72, loss/actor=-138.479, loss/critic=19.786, n/ep=0, n/st=1, rew=6.07]\n",
      "Epoch #3: test_reward: -153.814061 ± 315.753455, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 108.97it/s, env_step=20000, len=18, loss/actor=-184.900, loss/critic=31.699, n/ep=0, n/st=1, rew=-6.24]\n",
      "Epoch #4: test_reward: -189.243659 ± 264.142766, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.99it/s, env_step=25000, len=126, loss/actor=-230.584, loss/critic=59.000, n/ep=0, n/st=1, rew=-52.87]\n",
      "Epoch #5: test_reward: -351.102037 ± 526.597673, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '242.11s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1693.50 step/s',\n",
      " 'test_step': 30790,\n",
      " 'test_time': '18.18s',\n",
      " 'train_episode': 107,\n",
      " 'train_speed': '111.65 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.26s',\n",
      " 'train_time/model': '184.67s'}\n",
      "Final reward: -134.92644634251207, length: 181.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:55:10.787605: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.25it/s, env_step=5000, len=295, loss/actor=-32.518, loss/critic=4.137, n/ep=0, n/st=1, rew=83.89]\n",
      "Epoch #1: test_reward: -72.423015 ± 290.876787, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 109.59it/s, env_step=10000, len=1000, loss/actor=-80.358, loss/critic=9.347, n/ep=0, n/st=1, rew=-777.34]\n",
      "Epoch #2: test_reward: -137.004326 ± 294.413721, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.93it/s, env_step=15000, len=58, loss/actor=-138.219, loss/critic=26.031, n/ep=0, n/st=1, rew=10.51]\n",
      "Epoch #3: test_reward: -249.297955 ± 441.596587, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.95it/s, env_step=20000, len=27, loss/actor=-183.617, loss/critic=27.978, n/ep=0, n/st=1, rew=-30.27]\n",
      "Epoch #4: test_reward: -110.291938 ± 252.965067, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.36it/s, env_step=25000, len=1000, loss/actor=-233.856, loss/critic=52.699, n/ep=0, n/st=1, rew=-994.59]\n",
      "Epoch #5: test_reward: -183.933804 ± 331.053337, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.40s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1366.84 step/s',\n",
      " 'test_step': 20188,\n",
      " 'test_time': '14.77s',\n",
      " 'train_episode': 107,\n",
      " 'train_speed': '114.87 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.62s',\n",
      " 'train_time/model': '179.01s'}\n",
      "Final reward: -414.50675965273024, length: 425.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 14:59:32.430761: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.38it/s, env_step=5000, len=27, loss/actor=-34.816, loss/critic=5.027, n/ep=0, n/st=1, rew=-4.95]\n",
      "Epoch #1: test_reward: -93.764700 ± 213.457030, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.50it/s, env_step=10000, len=24, loss/actor=-86.436, loss/critic=11.636, n/ep=0, n/st=1, rew=-3.05]\n",
      "Epoch #2: test_reward: -19.339887 ± 22.095228, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.98it/s, env_step=15000, len=21, loss/actor=-131.235, loss/critic=18.276, n/ep=0, n/st=1, rew=-16.38]\n",
      "Epoch #3: test_reward: -98.459562 ± 258.597958, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.24it/s, env_step=20000, len=31, loss/actor=-166.245, loss/critic=35.291, n/ep=0, n/st=1, rew=-2.27]\n",
      "Epoch #4: test_reward: -12.476428 ± 21.838692, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.72it/s, env_step=25000, len=164, loss/actor=-199.187, loss/critic=33.423, n/ep=0, n/st=1, rew=-33.12]\n",
      "Epoch #5: test_reward: -227.526269 ± 294.231179, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '228.95s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1621.89 step/s',\n",
      " 'test_step': 17717,\n",
      " 'test_time': '10.92s',\n",
      " 'train_episode': 104,\n",
      " 'train_speed': '114.66 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.79s',\n",
      " 'train_time/model': '179.24s'}\n",
      "Final reward: -93.05747386872204, length: 139.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:03:49.640364: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 119.69it/s, env_step=5000, len=27, loss/actor=-35.024, loss/critic=5.618, n/ep=0, n/st=1, rew=11.53]\n",
      "Epoch #1: test_reward: -118.183372 ± 517.509047, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.69it/s, env_step=10000, len=42, loss/actor=-94.343, loss/critic=14.752, n/ep=0, n/st=1, rew=9.05]\n",
      "Epoch #2: test_reward: -254.298609 ± 459.917000, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.53it/s, env_step=15000, len=1000, loss/actor=-154.922, loss/critic=23.979, n/ep=0, n/st=1, rew=-1067.51]\n",
      "Epoch #3: test_reward: -458.731962 ± 530.948581, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.02it/s, env_step=20000, len=67, loss/actor=-200.133, loss/critic=31.909, n/ep=0, n/st=1, rew=-47.06]\n",
      "Epoch #4: test_reward: -117.503764 ± 316.006940, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.42it/s, env_step=25000, len=14, loss/actor=-237.527, loss/critic=38.647, n/ep=0, n/st=1, rew=-4.24]\n",
      "Epoch #5: test_reward: -105.521705 ± 258.725294, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.65s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1500.05 step/s',\n",
      " 'test_step': 24981,\n",
      " 'test_time': '16.65s',\n",
      " 'train_episode': 87,\n",
      " 'train_speed': '115.74 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.37s',\n",
      " 'train_time/model': '177.63s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -183.6794230203565, length: 249.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:08:10.933843: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 118.10it/s, env_step=5000, len=43, loss/actor=-33.076, loss/critic=5.588, n/ep=0, n/st=1, rew=31.61]\n",
      "Epoch #1: test_reward: -190.422409 ± 376.631329, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.69it/s, env_step=10000, len=51, loss/actor=-80.091, loss/critic=9.783, n/ep=0, n/st=1, rew=-8.90]\n",
      "Epoch #2: test_reward: -132.128505 ± 227.458656, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.55it/s, env_step=15000, len=13, loss/actor=-118.663, loss/critic=13.961, n/ep=0, n/st=1, rew=-0.22]\n",
      "Epoch #3: test_reward: -160.444740 ± 245.035177, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.96it/s, env_step=20000, len=38, loss/actor=-146.657, loss/critic=19.832, n/ep=0, n/st=1, rew=-4.23]\n",
      "Epoch #4: test_reward: -170.544375 ± 219.467287, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.75it/s, env_step=25000, len=88, loss/actor=-168.671, loss/critic=26.867, n/ep=0, n/st=1, rew=5.59]\n",
      "Epoch #5: test_reward: -74.883333 ± 169.611146, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.21s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1500.70 step/s',\n",
      " 'test_step': 24686,\n",
      " 'test_time': '16.45s',\n",
      " 'train_episode': 101,\n",
      " 'train_speed': '114.28 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.05s',\n",
      " 'train_time/model': '179.72s'}\n",
      "Final reward: -154.40226154780862, length: 422.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:12:35.508204: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.39it/s, env_step=5000, len=22, loss/actor=-31.808, loss/critic=4.959, n/ep=0, n/st=1, rew=5.79]\n",
      "Epoch #1: test_reward: -152.219334 ± 401.464193, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.20it/s, env_step=10000, len=65, loss/actor=-75.808, loss/critic=7.824, n/ep=0, n/st=1, rew=28.82]\n",
      "Epoch #2: test_reward: -215.335836 ± 338.246065, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 113.35it/s, env_step=15000, len=39, loss/actor=-113.565, loss/critic=13.671, n/ep=0, n/st=1, rew=12.73]\n",
      "Epoch #3: test_reward: -106.865174 ± 201.862939, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 111.17it/s, env_step=20000, len=89, loss/actor=-144.104, loss/critic=17.316, n/ep=0, n/st=1, rew=27.39]\n",
      "Epoch #4: test_reward: -186.675717 ± 261.336848, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.09it/s, env_step=25000, len=590, loss/actor=-176.277, loss/critic=26.366, n/ep=0, n/st=1, rew=-150.09]\n",
      "Epoch #5: test_reward: -238.245443 ± 259.369076, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.06s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1649.81 step/s',\n",
      " 'test_step': 28945,\n",
      " 'test_time': '17.54s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '113.37 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.04s',\n",
      " 'train_time/model': '181.48s'}\n",
      "Final reward: -241.5158112741321, length: 351.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:17:02.747644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.37it/s, env_step=5000, len=31, loss/actor=-35.023, loss/critic=6.719, n/ep=0, n/st=1, rew=1.50]\n",
      "Epoch #1: test_reward: -217.102476 ± 507.207226, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.60it/s, env_step=10000, len=1000, loss/actor=-95.448, loss/critic=11.970, n/ep=0, n/st=1, rew=-922.49]\n",
      "Epoch #2: test_reward: -420.279539 ± 450.085599, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.59it/s, env_step=15000, len=32, loss/actor=-152.971, loss/critic=24.424, n/ep=0, n/st=1, rew=-22.60]\n",
      "Epoch #3: test_reward: -94.861102 ± 281.990497, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.44it/s, env_step=20000, len=65, loss/actor=-199.416, loss/critic=31.785, n/ep=0, n/st=1, rew=-26.90]\n",
      "Epoch #4: test_reward: -273.444574 ± 366.917717, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.65it/s, env_step=25000, len=50, loss/actor=-245.365, loss/critic=47.100, n/ep=0, n/st=1, rew=-20.49]\n",
      "Epoch #5: test_reward: -261.024892 ± 359.685606, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.58s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1639.28 step/s',\n",
      " 'test_step': 29325,\n",
      " 'test_time': '17.89s',\n",
      " 'train_episode': 93,\n",
      " 'train_speed': '114.84 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.45s',\n",
      " 'train_time/model': '179.24s'}\n",
      "Final reward: -283.32879837211283, length: 345.9\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:21:27.600614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.80it/s, env_step=5000, len=55, loss/actor=-34.788, loss/critic=5.687, n/ep=0, n/st=1, rew=19.90]\n",
      "Epoch #1: test_reward: -400.098817 ± 775.993921, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.13it/s, env_step=10000, len=200, loss/actor=-88.838, loss/critic=13.279, n/ep=0, n/st=1, rew=139.98]\n",
      "Epoch #2: test_reward: -248.041762 ± 446.229606, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 116.26it/s, env_step=15000, len=139, loss/actor=-132.200, loss/critic=13.866, n/ep=0, n/st=1, rew=-55.46]\n",
      "Epoch #3: test_reward: -109.536706 ± 311.192888, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:41, 121.96it/s, env_step=20000, len=203, loss/actor=-163.043, loss/critic=24.621, n/ep=0, n/st=1, rew=-17.10]\n",
      "Epoch #4: test_reward: -54.006385 ± 136.145165, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.32it/s, env_step=25000, len=30, loss/actor=-190.170, loss/critic=28.242, n/ep=0, n/st=1, rew=-24.41]\n",
      "Epoch #5: test_reward: -154.921374 ± 260.334669, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.21s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1471.97 step/s',\n",
      " 'test_step': 22028,\n",
      " 'test_time': '14.96s',\n",
      " 'train_episode': 77,\n",
      " 'train_speed': '116.15 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.72s',\n",
      " 'train_time/model': '176.53s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 3.894436390299164, length: 64.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:25:44.889526: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.17it/s, env_step=5000, len=50, loss/actor=-30.877, loss/critic=4.004, n/ep=0, n/st=1, rew=28.96]\n",
      "Epoch #1: test_reward: -38.765449 ± 365.961937, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 112.52it/s, env_step=10000, len=32, loss/actor=-72.952, loss/critic=6.162, n/ep=0, n/st=1, rew=-35.84]\n",
      "Epoch #2: test_reward: -153.312986 ± 322.393760, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 111.60it/s, env_step=15000, len=19, loss/actor=-104.971, loss/critic=12.893, n/ep=0, n/st=1, rew=8.58]\n",
      "Epoch #3: test_reward: -251.724818 ± 293.288775, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.05it/s, env_step=20000, len=26, loss/actor=-128.426, loss/critic=13.515, n/ep=0, n/st=1, rew=-4.26]\n",
      "Epoch #4: test_reward: -45.169773 ± 178.282336, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.36it/s, env_step=25000, len=127, loss/actor=-146.810, loss/critic=15.236, n/ep=0, n/st=1, rew=-21.22]\n",
      "Epoch #5: test_reward: -73.520991 ± 139.542324, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.15s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1568.25 step/s',\n",
      " 'test_step': 25893,\n",
      " 'test_time': '16.51s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '113.82 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.00s',\n",
      " 'train_time/model': '180.63s'}\n",
      "Final reward: -69.11756908611595, length: 170.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:30:09.648586: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 113.49it/s, env_step=5000, len=44, loss/actor=-36.473, loss/critic=7.650, n/ep=0, n/st=1, rew=-17.66]\n",
      "Epoch #1: test_reward: -298.865830 ± 466.927440, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.91it/s, env_step=10000, len=242, loss/actor=-109.097, loss/critic=17.126, n/ep=0, n/st=1, rew=-2.90]\n",
      "Epoch #2: test_reward: -134.561369 ± 323.788459, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.13it/s, env_step=15000, len=46, loss/actor=-171.138, loss/critic=26.005, n/ep=0, n/st=1, rew=-22.80]\n",
      "Epoch #3: test_reward: -117.035433 ± 274.967312, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 117.34it/s, env_step=20000, len=1000, loss/actor=-224.934, loss/critic=43.938, n/ep=0, n/st=1, rew=-911.47]\n",
      "Epoch #4: test_reward: -218.171424 ± 391.105696, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 116.18it/s, env_step=25000, len=1000, loss/actor=-279.428, loss/critic=85.216, n/ep=0, n/st=1, rew=-923.90]\n",
      "Epoch #5: test_reward: -1020.107619 ± 719.973620, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.62s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1524.64 step/s',\n",
      " 'test_step': 25877,\n",
      " 'test_time': '16.97s',\n",
      " 'train_episode': 77,\n",
      " 'train_speed': '115.93 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.71s',\n",
      " 'train_time/model': '176.94s'}\n",
      "Final reward: -443.26519397313086, length: 359.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:34:31.294038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:45, 109.29it/s, env_step=5000, len=1000, loss/actor=-28.336, loss/critic=3.276, n/ep=0, n/st=1, rew=12.07]\n",
      "Epoch #1: test_reward: -100.409913 ± 250.626455, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.05it/s, env_step=10000, len=271, loss/actor=-70.527, loss/critic=6.325, n/ep=0, n/st=1, rew=-83.15]\n",
      "Epoch #2: test_reward: 1.162199 ± 25.372555, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.34it/s, env_step=15000, len=46, loss/actor=-106.961, loss/critic=13.489, n/ep=0, n/st=1, rew=-23.10]\n",
      "Epoch #3: test_reward: -98.937877 ± 171.082091, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 115.53it/s, env_step=20000, len=222, loss/actor=-134.583, loss/critic=13.316, n/ep=0, n/st=1, rew=18.75]\n",
      "Epoch #4: test_reward: -134.511651 ± 276.663130, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 109.79it/s, env_step=25000, len=79, loss/actor=-158.220, loss/critic=18.106, n/ep=0, n/st=1, rew=-31.55]\n",
      "Epoch #5: test_reward: -125.909651 ± 285.631883, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '236.51s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1567.10 step/s',\n",
      " 'test_step': 22341,\n",
      " 'test_time': '14.26s',\n",
      " 'train_episode': 89,\n",
      " 'train_speed': '112.48 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.16s',\n",
      " 'train_time/model': '183.09s'}\n",
      "Final reward: -66.91689111965779, length: 152.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 15:38:56.425199: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.78it/s, env_step=5000, len=76, loss/actor=-33.099, loss/critic=4.938, n/ep=0, n/st=1, rew=3.82]\n",
      "Epoch #1: test_reward: -163.374824 ± 363.654866, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.92it/s, env_step=10000, len=90, loss/actor=-81.255, loss/critic=9.379, n/ep=0, n/st=1, rew=-21.67]\n",
      "Epoch #2: test_reward: -41.544916 ± 47.780864, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:44, 112.69it/s, env_step=15000, len=67, loss/actor=-128.302, loss/critic=21.326, n/ep=0, n/st=1, rew=53.06]\n",
      "Epoch #3: test_reward: -300.727556 ± 355.432750, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:42, 118.02it/s, env_step=20000, len=72, loss/actor=-168.580, loss/critic=29.161, n/ep=0, n/st=1, rew=-9.34]\n",
      "Epoch #4: test_reward: -414.894146 ± 400.963985, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.52it/s, env_step=25000, len=29, loss/actor=-201.257, loss/critic=30.155, n/ep=0, n/st=1, rew=4.63]\n",
      "Epoch #5: test_reward: -31.900807 ± 69.130272, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.76s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1693.29 step/s',\n",
      " 'test_step': 22550,\n",
      " 'test_time': '13.32s',\n",
      " 'train_episode': 118,\n",
      " 'train_speed': '115.51 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.66s',\n",
      " 'train_time/model': '177.77s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -66.13302450579485, length: 91.0\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "for _ in range(200):\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5aca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 16:57:28.868006: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:46, 107.54it/s, env_step=5000, len=83, loss/actor=-32.083, loss/critic=4.538, n/ep=0, n/st=1, rew=17.18]\n",
      "Epoch #1: test_reward: -365.450766 ± 497.442576, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.91it/s, env_step=10000, len=147, loss/actor=-73.590, loss/critic=8.599, n/ep=0, n/st=1, rew=-15.60]\n",
      "Epoch #2: test_reward: -285.011847 ± 362.910139, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.18it/s, env_step=15000, len=12, loss/actor=-105.743, loss/critic=9.953, n/ep=0, n/st=1, rew=-3.08]\n",
      "Epoch #3: test_reward: -157.798966 ± 204.271470, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.34it/s, env_step=20000, len=58, loss/actor=-131.215, loss/critic=14.923, n/ep=0, n/st=1, rew=-63.94]\n",
      "Epoch #4: test_reward: -372.513130 ± 611.559101, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:45, 110.59it/s, env_step=25000, len=190, loss/actor=-154.826, loss/critic=16.312, n/ep=0, n/st=1, rew=-16.97]\n",
      "Epoch #5: test_reward: -210.704610 ± 329.123819, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '243.62s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1634.89 step/s',\n",
      " 'test_step': 31398,\n",
      " 'test_time': '19.20s',\n",
      " 'train_episode': 94,\n",
      " 'train_speed': '111.40 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '40.08s',\n",
      " 'train_time/model': '184.33s'}\n",
      "Final reward: -257.5579492164287, length: 356.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:02:01.497200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 117.91it/s, env_step=5000, len=103, loss/actor=-31.896, loss/critic=5.307, n/ep=0, n/st=1, rew=27.73]\n",
      "Epoch #1: test_reward: -154.232146 ± 362.816479, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:45, 110.23it/s, env_step=10000, len=1000, loss/actor=-80.619, loss/critic=10.072, n/ep=0, n/st=1, rew=-943.67]\n",
      "Epoch #2: test_reward: -243.389231 ± 411.171495, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 118.20it/s, env_step=15000, len=1000, loss/actor=-121.634, loss/critic=13.543, n/ep=0, n/st=1, rew=-974.86]\n",
      "Epoch #3: test_reward: -161.477498 ± 272.047779, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.55it/s, env_step=20000, len=13, loss/actor=-157.278, loss/critic=21.936, n/ep=0, n/st=1, rew=-17.46]\n",
      "Epoch #4: test_reward: -28.193793 ± 37.260973, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 118.98it/s, env_step=25000, len=75, loss/actor=-195.374, loss/critic=33.599, n/ep=0, n/st=1, rew=-62.21]\n",
      "Epoch #5: test_reward: -228.855580 ± 355.922807, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '229.68s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1482.22 step/s',\n",
      " 'test_step': 20517,\n",
      " 'test_time': '13.84s',\n",
      " 'train_episode': 74,\n",
      " 'train_speed': '115.83 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.72s',\n",
      " 'train_time/model': '177.12s'}\n",
      "Final reward: -151.06183683239857, length: 145.5\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:06:19.880423: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 113.87it/s, env_step=5000, len=88, loss/actor=-30.014, loss/critic=3.749, n/ep=0, n/st=1, rew=18.87]\n",
      "Epoch #1: test_reward: -151.974476 ± 462.507956, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 117.15it/s, env_step=10000, len=48, loss/actor=-68.573, loss/critic=5.830, n/ep=0, n/st=1, rew=14.00]\n",
      "Epoch #2: test_reward: -146.496344 ± 205.265230, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.19it/s, env_step=15000, len=70, loss/actor=-100.417, loss/critic=8.613, n/ep=0, n/st=1, rew=-3.90]\n",
      "Epoch #3: test_reward: -182.108937 ± 243.742437, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.60it/s, env_step=20000, len=87, loss/actor=-127.207, loss/critic=13.335, n/ep=0, n/st=1, rew=-51.18]\n",
      "Epoch #4: test_reward: -119.256326 ± 224.447931, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.76it/s, env_step=25000, len=34, loss/actor=-151.889, loss/critic=22.694, n/ep=0, n/st=1, rew=-15.91]\n",
      "Epoch #5: test_reward: -79.841846 ± 152.439648, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.29s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1487.29 step/s',\n",
      " 'test_step': 24459,\n",
      " 'test_time': '16.45s',\n",
      " 'train_episode': 90,\n",
      " 'train_speed': '114.24 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.46s',\n",
      " 'train_time/model': '179.39s'}\n",
      "Final reward: -358.6055041582322, length: 550.2\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:10:44.922222: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 115.62it/s, env_step=5000, len=21, loss/actor=-30.985, loss/critic=4.917, n/ep=0, n/st=1, rew=1.28]\n",
      "Epoch #1: test_reward: -235.930619 ± 466.794379, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.02it/s, env_step=10000, len=70, loss/actor=-78.205, loss/critic=12.644, n/ep=0, n/st=1, rew=13.60]\n",
      "Epoch #2: test_reward: -314.430327 ± 342.177331, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.84it/s, env_step=15000, len=1000, loss/actor=-124.391, loss/critic=19.000, n/ep=0, n/st=1, rew=-894.38]\n",
      "Epoch #3: test_reward: -102.539694 ± 249.577024, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.56it/s, env_step=20000, len=1000, loss/actor=-166.325, loss/critic=28.776, n/ep=0, n/st=1, rew=-911.77]\n",
      "Epoch #4: test_reward: -285.997747 ± 400.116823, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 116.08it/s, env_step=25000, len=376, loss/actor=-206.261, loss/critic=45.519, n/ep=0, n/st=1, rew=-402.69]\n",
      "Epoch #5: test_reward: -245.840939 ± 420.891842, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '234.15s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1550.46 step/s',\n",
      " 'test_step': 26998,\n",
      " 'test_time': '17.41s',\n",
      " 'train_episode': 71,\n",
      " 'train_speed': '115.35 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.99s',\n",
      " 'train_time/model': '177.75s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -154.34167125150148, length: 174.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:15:07.437368: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.86it/s, env_step=5000, len=58, loss/actor=-34.020, loss/critic=5.643, n/ep=0, n/st=1, rew=12.10]\n",
      "Epoch #1: test_reward: -214.873986 ± 359.500823, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.83it/s, env_step=10000, len=1000, loss/actor=-91.862, loss/critic=14.655, n/ep=0, n/st=1, rew=-1116.98]\n",
      "Epoch #2: test_reward: -283.198824 ± 671.428447, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.48it/s, env_step=15000, len=1000, loss/actor=-144.423, loss/critic=22.978, n/ep=0, n/st=1, rew=-851.89]\n",
      "Epoch #3: test_reward: -83.025389 ± 217.308926, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.04it/s, env_step=20000, len=13, loss/actor=-192.363, loss/critic=39.852, n/ep=0, n/st=1, rew=-7.03]\n",
      "Epoch #4: test_reward: -152.072929 ± 306.897105, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 114.19it/s, env_step=25000, len=19, loss/actor=-238.908, loss/critic=62.784, n/ep=0, n/st=1, rew=-21.74]\n",
      "Epoch #5: test_reward: -374.216502 ± 339.624676, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.14s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1519.99 step/s',\n",
      " 'test_step': 24686,\n",
      " 'test_time': '16.24s',\n",
      " 'train_episode': 121,\n",
      " 'train_speed': '114.21 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.73s',\n",
      " 'train_time/model': '180.17s'}\n",
      "Final reward: -311.60335190249276, length: 426.8\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:19:31.901389: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:41, 119.11it/s, env_step=5000, len=183, loss/actor=-37.367, loss/critic=8.977, n/ep=0, n/st=1, rew=19.75]\n",
      "Epoch #1: test_reward: -269.999510 ± 561.334872, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.17it/s, env_step=10000, len=47, loss/actor=-124.488, loss/critic=31.610, n/ep=0, n/st=1, rew=-13.06]\n",
      "Epoch #2: test_reward: -579.949490 ± 667.740945, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 113.67it/s, env_step=15000, len=1000, loss/actor=-230.615, loss/critic=63.532, n/ep=0, n/st=1, rew=-1212.36]\n",
      "Epoch #3: test_reward: -415.587416 ± 569.030547, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.95it/s, env_step=20000, len=25, loss/actor=-321.571, loss/critic=123.756, n/ep=0, n/st=1, rew=-19.46]\n",
      "Epoch #4: test_reward: -134.888024 ± 334.220728, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 111.40it/s, env_step=25000, len=314, loss/actor=-405.057, loss/critic=196.639, n/ep=0, n/st=1, rew=-203.73]\n",
      "Epoch #5: test_reward: -160.999058 ± 369.536069, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.90s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1515.68 step/s',\n",
      " 'test_step': 25606,\n",
      " 'test_time': '16.89s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '114.15 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.10s',\n",
      " 'train_time/model': '179.91s'}\n",
      "Final reward: -345.1350179722408, length: 295.3\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:23:56.797233: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.82it/s, env_step=5000, len=503, loss/actor=-36.810, loss/critic=7.420, n/ep=0, n/st=1, rew=-42.56]\n",
      "Epoch #1: test_reward: -465.094353 ± 281.647231, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 113.46it/s, env_step=10000, len=60, loss/actor=-101.407, loss/critic=25.071, n/ep=0, n/st=1, rew=25.52]\n",
      "Epoch #2: test_reward: -25.720429 ± 30.512018, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 111.08it/s, env_step=15000, len=106, loss/actor=-159.369, loss/critic=26.698, n/ep=0, n/st=1, rew=-92.37]\n",
      "Epoch #3: test_reward: -122.263758 ± 282.495053, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 114.71it/s, env_step=20000, len=49, loss/actor=-203.102, loss/critic=63.180, n/ep=0, n/st=1, rew=-25.41]\n",
      "Epoch #4: test_reward: -171.130210 ± 312.531971, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 117.12it/s, env_step=25000, len=42, loss/actor=-235.815, loss/critic=55.306, n/ep=0, n/st=1, rew=-14.76]\n",
      "Epoch #5: test_reward: -222.271323 ± 367.853454, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.82s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1692.43 step/s',\n",
      " 'test_step': 26477,\n",
      " 'test_time': '15.64s',\n",
      " 'train_episode': 107,\n",
      " 'train_speed': '113.55 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.84s',\n",
      " 'train_time/model': '181.33s'}\n",
      "Final reward: -189.498911363765, length: 231.4\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:28:21.476045: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:43, 114.06it/s, env_step=5000, len=30, loss/actor=-28.423, loss/critic=3.483, n/ep=0, n/st=1, rew=22.15]\n",
      "Epoch #1: test_reward: 193.759816 ± 307.892825, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:42, 118.88it/s, env_step=10000, len=74, loss/actor=-68.152, loss/critic=5.662, n/ep=0, n/st=1, rew=34.06]\n",
      "Epoch #2: test_reward: -127.006221 ± 197.307144, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 110.17it/s, env_step=15000, len=12, loss/actor=-104.900, loss/critic=13.492, n/ep=0, n/st=1, rew=-15.91]\n",
      "Epoch #3: test_reward: -120.371626 ± 218.254549, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:45, 110.20it/s, env_step=20000, len=147, loss/actor=-139.919, loss/critic=19.945, n/ep=0, n/st=1, rew=-54.83]\n",
      "Epoch #4: test_reward: -70.975086 ± 216.690216, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.62it/s, env_step=25000, len=61, loss/actor=-170.126, loss/critic=37.357, n/ep=0, n/st=1, rew=8.68]\n",
      "Epoch #5: test_reward: -154.120539 ± 325.534419, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '235.20s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1414.42 step/s',\n",
      " 'test_step': 21509,\n",
      " 'test_time': '15.21s',\n",
      " 'train_episode': 98,\n",
      " 'train_speed': '113.64 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.14s',\n",
      " 'train_time/model': '180.86s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -427.0540180039784, length: 450.0\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:32:46.217735: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.95it/s, env_step=5000, len=1000, loss/actor=-32.894, loss/critic=4.747, n/ep=0, n/st=1, rew=-845.50]\n",
      "Epoch #1: test_reward: -149.200460 ± 332.656552, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.59it/s, env_step=10000, len=40, loss/actor=-81.149, loss/critic=14.495, n/ep=0, n/st=1, rew=-22.59]\n",
      "Epoch #2: test_reward: -13.559635 ± 34.726788, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:42, 116.90it/s, env_step=15000, len=51, loss/actor=-122.466, loss/critic=19.602, n/ep=0, n/st=1, rew=-13.81]\n",
      "Epoch #3: test_reward: -92.547906 ± 200.735825, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 113.20it/s, env_step=20000, len=127, loss/actor=-159.416, loss/critic=27.505, n/ep=0, n/st=1, rew=-90.81]\n",
      "Epoch #4: test_reward: -253.978119 ± 354.630178, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:42, 116.64it/s, env_step=25000, len=32, loss/actor=-200.036, loss/critic=58.053, n/ep=0, n/st=1, rew=-20.44]\n",
      "Epoch #5: test_reward: -348.656388 ± 491.035068, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '230.35s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1480.56 step/s',\n",
      " 'test_step': 21354,\n",
      " 'test_time': '14.42s',\n",
      " 'train_episode': 92,\n",
      " 'train_speed': '115.78 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.81s',\n",
      " 'train_time/model': '177.11s'}\n",
      "Final reward: -41.34597812601677, length: 76.1\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:37:04.114161: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 112.83it/s, env_step=5000, len=1000, loss/actor=-34.847, loss/critic=6.004, n/ep=0, n/st=1, rew=-642.50]\n",
      "Epoch #1: test_reward: -215.312182 ± 380.111349, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:44, 111.71it/s, env_step=10000, len=177, loss/actor=-96.333, loss/critic=14.714, n/ep=0, n/st=1, rew=-35.79]\n",
      "Epoch #2: test_reward: -5.074201 ± 20.140212, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:45, 109.40it/s, env_step=15000, len=21, loss/actor=-145.670, loss/critic=29.931, n/ep=0, n/st=1, rew=-10.40]\n",
      "Epoch #3: test_reward: -113.574915 ± 196.855499, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:44, 112.49it/s, env_step=20000, len=45, loss/actor=-201.314, loss/critic=79.821, n/ep=0, n/st=1, rew=-51.72]\n",
      "Epoch #4: test_reward: -245.282716 ± 407.201952, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:44, 112.02it/s, env_step=25000, len=29, loss/actor=-268.150, loss/critic=123.163, n/ep=0, n/st=1, rew=-12.80]\n",
      "Epoch #5: test_reward: -549.688929 ± 770.124491, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '238.67s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1533.02 step/s',\n",
      " 'test_step': 22547,\n",
      " 'test_time': '14.71s',\n",
      " 'train_episode': 81,\n",
      " 'train_speed': '111.63 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.94s',\n",
      " 'train_time/model': '184.02s'}\n",
      "Final reward: -406.27783013030495, length: 286.6\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:41:31.609564: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:44, 111.96it/s, env_step=5000, len=26, loss/actor=-28.088, loss/critic=2.840, n/ep=0, n/st=1, rew=-4.71]\n",
      "Epoch #1: test_reward: 10.663600 ± 55.188016, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 114.99it/s, env_step=10000, len=1000, loss/actor=-65.535, loss/critic=5.582, n/ep=0, n/st=1, rew=-669.23]\n",
      "Epoch #2: test_reward: -129.367445 ± 253.782261, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 115.42it/s, env_step=15000, len=84, loss/actor=-100.208, loss/critic=10.976, n/ep=0, n/st=1, rew=21.84]\n",
      "Epoch #3: test_reward: 45.735736 ± 129.527655, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 116.02it/s, env_step=20000, len=19, loss/actor=-130.920, loss/critic=17.489, n/ep=0, n/st=1, rew=-18.04]\n",
      "Epoch #4: test_reward: -39.250096 ± 76.124791, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:41, 119.63it/s, env_step=25000, len=1000, loss/actor=-154.943, loss/critic=19.424, n/ep=0, n/st=1, rew=-687.52]\n",
      "Epoch #5: test_reward: -64.173114 ± 96.654396, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '232.28s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1436.11 step/s',\n",
      " 'test_step': 22730,\n",
      " 'test_time': '15.83s',\n",
      " 'train_episode': 73,\n",
      " 'train_speed': '115.50 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '38.77s',\n",
      " 'train_time/model': '177.68s'}\n",
      "Final reward: -144.71155147764097, length: 301.7\n",
      "\u001b[0m\n",
      "Observations shape: (111,)\n",
      "Actions shape: (8,)\n",
      "Action range: -1.0 1.0\n",
      "Loaded agent from:  /home/jaewon/MyWork/RL-tutorial/Ant_v3/tianshou-master/examples/mujoco/history_ddpg//Ant-v3/ddpg/seed_0_0320_140644-Ant_v3_ddpg/policy.pth\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/tianshou/data/collector.py:66: UserWarning: Single environment detected, wrap to DummyVectorEnv.\n",
      "  warnings.warn(\"Single environment detected, wrap to DummyVectorEnv.\")\n",
      "2022-03-20 17:45:52.973048: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 5001it [00:42, 116.46it/s, env_step=5000, len=161, loss/actor=-34.410, loss/critic=5.832, n/ep=0, n/st=1, rew=-89.20]\n",
      "Epoch #1: test_reward: -11.022350 ± 16.139439, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #2: 5001it [00:43, 115.49it/s, env_step=10000, len=1000, loss/actor=-86.470, loss/critic=10.950, n/ep=0, n/st=1, rew=-751.52]\n",
      "Epoch #2: test_reward: -121.840139 ± 241.754409, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #3: 5001it [00:43, 114.64it/s, env_step=15000, len=38, loss/actor=-128.496, loss/critic=18.294, n/ep=0, n/st=1, rew=12.50]\n",
      "Epoch #3: test_reward: -217.506588 ± 313.741756, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #4: 5001it [00:43, 113.78it/s, env_step=20000, len=39, loss/actor=-163.998, loss/critic=26.573, n/ep=0, n/st=1, rew=18.56]\n",
      "Epoch #4: test_reward: -153.419642 ± 292.002273, best_reward: 982.568459 ± 4.229930 in #0\n",
      "Epoch #5: 5001it [00:43, 115.32it/s, env_step=25000, len=42, loss/actor=-202.858, loss/critic=42.869, n/ep=0, n/st=1, rew=-67.49]\n",
      "Epoch #5: test_reward: -139.973908 ± 251.497347, best_reward: 982.568459 ± 4.229930 in #0\n",
      "{'best_result': '982.57 ± 4.23',\n",
      " 'best_reward': 982.5684588949738,\n",
      " 'duration': '231.03s',\n",
      " 'test_episode': 60,\n",
      " 'test_speed': '1509.31 step/s',\n",
      " 'test_step': 20797,\n",
      " 'test_time': '13.78s',\n",
      " 'train_episode': 71,\n",
      " 'train_speed': '115.08 step/s',\n",
      " 'train_step': 25000,\n",
      " 'train_time/collector': '39.01s',\n",
      " 'train_time/model': '178.24s'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: -133.4195822837696, length: 193.0\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "for _ in range(12):\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a162bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range():\n",
    "    latest_file = os.listdir(history_path+'/Ant-v3/ddpg/')[-1]\n",
    "    resume = history_path+'/Ant-v3/ddpg/' + latest_file + '/policy.pth'\n",
    "    !python mujoco_ddpg.py --task $task --epoch $epoch --logdir $history_path  --resume-path $resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee13bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
