{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a441ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jaewon/MyWork/RL-tutorial/CartPole/result\"\n",
    "task = 'CartPole'\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e169902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/gym/envs/registration.py:511: UserWarning: \u001b[33mWARN: Using the latest versioned environment `CartPole-v1` instead of the unversioned environment `CartPole`\u001b[0m\n",
      "  logger.warn(\n",
      "2022-04-14 14:37:30.214855: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 2001it [00:01, 1420.62it/s, env_step=2000, len=14, loss=0.086, n/ep=0, n/st=10, rew=14.50]\n",
      "Epoch #1: test_reward: 9.620000 ± 0.967264, best_reward: 9.620000 ± 0.967264 in #1\n",
      "Epoch #2: 2001it [00:01, 1441.50it/s, env_step=4000, len=15, loss=0.224, n/ep=1, n/st=10, rew=15.00]\n",
      "Epoch #2: test_reward: 10.200000 ± 0.948683, best_reward: 10.200000 ± 0.948683 in #2\n",
      "Epoch #3: 2001it [00:01, 1532.26it/s, env_step=6000, len=56, loss=0.134, n/ep=0, n/st=10, rew=56.00]\n",
      "Epoch #3: test_reward: 113.940000 ± 72.029275, best_reward: 113.940000 ± 72.029275 in #3\n",
      "Epoch #4: 2001it [00:01, 1432.64it/s, env_step=8000, len=109, loss=0.219, n/ep=0, n/st=10, rew=109.00]\n",
      "Epoch #4: test_reward: 251.410000 ± 93.721726, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #5: 2001it [00:01, 1593.71it/s, env_step=10000, len=188, loss=0.283, n/ep=0, n/st=10, rew=188.00]\n",
      "Epoch #5: test_reward: 130.170000 ± 7.853732, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #6: 2001it [00:01, 1456.65it/s, env_step=12000, len=149, loss=0.256, n/ep=0, n/st=10, rew=149.00]\n",
      "Epoch #6: test_reward: 145.260000 ± 9.093536, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #7: 2001it [00:01, 1455.52it/s, env_step=14000, len=178, loss=0.336, n/ep=0, n/st=10, rew=178.00]\n",
      "Epoch #7: test_reward: 281.440000 ± 75.817718, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #8: 2001it [00:01, 1359.77it/s, env_step=16000, len=195, loss=0.261, n/ep=0, n/st=10, rew=195.00]\n",
      "Epoch #8: test_reward: 178.040000 ± 18.779201, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #9: 2001it [00:01, 1530.34it/s, env_step=18000, len=185, loss=0.400, n/ep=0, n/st=10, rew=185.00]\n",
      "Epoch #9: test_reward: 147.620000 ± 10.744096, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #10: 2001it [00:01, 1976.14it/s, env_step=20000, len=246, loss=0.352, n/ep=0, n/st=10, rew=246.00]\n",
      "Epoch #10: test_reward: 190.450000 ± 16.809744, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Traceback (most recent call last):\n",
      "  File \"test_dqn.py\", line 176, in <module>\n",
      "    test_dqn(get_args())\n",
      "  File \"test_dqn.py\", line 154, in test_dqn\n",
      "    assert stop_fn(result['best_reward'])\n",
      "AssertionError\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python test_dqn.py --task $task --reward-threshold $1000 --epoch $epoch --logdir $path --step-per-epoch $2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c327d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/jaewon/anaconda3/lib/python3.8/site-packages/gym/envs/registration.py:511: UserWarning: \u001b[33mWARN: Using the latest versioned environment `CartPole-v1` instead of the unversioned environment `CartPole`\u001b[0m\n",
      "  logger.warn(\n",
      "2022-04-14 14:44:34.676911: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Epoch #1: 2001it [00:01, 1481.65it/s, env_step=2000, len=14, loss=0.086, n/ep=0, n/st=10, rew=14.50]\n",
      "Epoch #1: test_reward: 9.620000 ± 0.967264, best_reward: 9.620000 ± 0.967264 in #1\n",
      "Epoch #2: 2001it [00:01, 1491.15it/s, env_step=4000, len=15, loss=0.224, n/ep=1, n/st=10, rew=15.00]\n",
      "Epoch #2: test_reward: 10.200000 ± 0.948683, best_reward: 10.200000 ± 0.948683 in #2\n",
      "Epoch #3: 2001it [00:01, 1540.56it/s, env_step=6000, len=56, loss=0.134, n/ep=0, n/st=10, rew=56.00]\n",
      "Epoch #3: test_reward: 113.940000 ± 72.029275, best_reward: 113.940000 ± 72.029275 in #3\n",
      "Epoch #4: 2001it [00:01, 1527.01it/s, env_step=8000, len=109, loss=0.219, n/ep=0, n/st=10, rew=109.00]\n",
      "Epoch #4: test_reward: 251.410000 ± 93.721726, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #5: 2001it [00:01, 1500.00it/s, env_step=10000, len=188, loss=0.283, n/ep=0, n/st=10, rew=188.00]\n",
      "Epoch #5: test_reward: 130.170000 ± 7.853732, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #6: 2001it [00:01, 1440.70it/s, env_step=12000, len=149, loss=0.256, n/ep=0, n/st=10, rew=149.00]\n",
      "Epoch #6: test_reward: 145.260000 ± 9.093536, best_reward: 251.410000 ± 93.721726 in #4\n",
      "Epoch #7: 2001it [00:01, 1427.51it/s, env_step=14000, len=178, loss=0.336, n/ep=0, n/st=10, rew=178.00]\n",
      "Epoch #7: test_reward: 281.440000 ± 75.817718, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #8: 2001it [00:01, 1830.26it/s, env_step=16000, len=195, loss=0.261, n/ep=0, n/st=10, rew=195.00]\n",
      "Epoch #8: test_reward: 178.040000 ± 18.779201, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #9: 2001it [00:01, 1755.51it/s, env_step=18000, len=185, loss=0.400, n/ep=0, n/st=10, rew=185.00]\n",
      "Epoch #9: test_reward: 147.620000 ± 10.744096, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Epoch #10: 2001it [00:01, 1379.21it/s, env_step=20000, len=246, loss=0.352, n/ep=0, n/st=10, rew=246.00]\n",
      "Epoch #10: test_reward: 190.450000 ± 16.809744, best_reward: 281.440000 ± 75.817718 in #7\n",
      "Traceback (most recent call last):\n",
      "  File \"test_dqn.py\", line 176, in <module>\n",
      "    test_dqn(get_args())\n",
      "  File \"test_dqn.py\", line 154, in test_dqn\n",
      "    assert stop_fn(result['best_reward'])\n",
      "AssertionError\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python test_dqn.py --task $task --reward-threshold $1000 --epoch $epoch --logdir $path --step-per-epoch $2000 --render $1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
